{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning with Tree-Based Models in Python - Part 3\n",
    "- Voting Classifier\n",
    "    - Same training set, different algorithms\n",
    "    - Hard voting - majority voting\n",
    "    - Soft voting - averaging probabilities\n",
    "- Bagging (Bootstrap Aggregation)\n",
    "    - One algorithm, different subset of training set\n",
    "    - All features used for training and prediction\n",
    "    - Base estimators: Decision Tree, Logistic Regression, Neural Network, ...\n",
    "    - In classification aggregates predictions by majority voting\n",
    "    - In regression aggregates predictions through averaging\n",
    "    - Bagging - random sampling with replacement\n",
    "    - Pasting - random sampling without replacement (losowanie bez zwracania)\n",
    "- Out of Bag Evaluation\n",
    "    - In Bagging some samples can be used several times for one model (on average 63% training samples are used)\n",
    "    - Other samples may not be used at all (ramaining 37% are Out-of-bag samples)\n",
    "    - OOB samples can be used to evaluate each model\n",
    "    - OOB score is average of all OOB scores for each model\n",
    "- Random Forest\n",
    "    - One algorithm, different subset of training set\n",
    "    - Not all features used for training and prediction one model (without replacement)\n",
    "    - Base estimator: Decision Tree\n",
    "    - In classification aggregates predictions by majority voting\n",
    "    - In regression aggregates predictions through averaging\n",
    "    - Random sampling with replacement\n",
    "    - Out of Bag samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "SEED = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indian Liver Patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_indian_liver = pd.read_csv('../datasets/indian_liver_patient.csv')\n",
    "df_indian_liver = df_indian_liver.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_indian_liver = pd.get_dummies(df_indian_liver, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bike Sharing Demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_bike = pd.read_csv('../datasets/bike-sharing-demand.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging and Random Forests\n",
    "Bagging is an ensemble method involving training the same algorithm many times using different subsets sampled from the training data. In this chapter, you'll understand how bagging can be used to create a tree ensemble. You'll also learn how the random forests algorithm can lead to further ensemble diversity through randomization at the level of each split in the trees forming the ensemble."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Define the bagging classifier\n",
    "In the following exercises you'll work with the Indian Liver Patient dataset from the UCI machine learning repository. Your task is to predict whether a patient suffers from a liver disease using 10 features including Albumin, age and gender. You'll do so using a Bagging Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = df_indian_liver.iloc[:,:-1], df_indian_liver.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Instantiate dt\n",
    "dt = DecisionTreeClassifier(random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate bc\n",
    "bc = BaggingClassifier(base_estimator=dt, n_estimators=50, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Bagging performance\n",
    "Now that you instantiated the bagging classifier, it's time to train it and evaluate its test set accuracy.\n",
    "\n",
    "The Indian Liver Patient dataset is processed for you and split into 80% train and 20% test. The feature matrices X_train and X_test, as well as the arrays of labels y_train and y_test are available in your workspace. In addition, we have also loaded the bagging classifier bc that you instantiated in the previous exercise and the function accuracy_score() from sklearn.metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(ccp_alpha=0.0,\n",
       "                                                        class_weight=None,\n",
       "                                                        criterion='gini',\n",
       "                                                        max_depth=None,\n",
       "                                                        max_features=None,\n",
       "                                                        max_leaf_nodes=None,\n",
       "                                                        min_impurity_decrease=0.0,\n",
       "                                                        min_impurity_split=None,\n",
       "                                                        min_samples_leaf=1,\n",
       "                                                        min_samples_split=2,\n",
       "                                                        min_weight_fraction_leaf=0.0,\n",
       "                                                        presort='deprecated',\n",
       "                                                        random_state=1,\n",
       "                                                        splitter='best'),\n",
       "                  bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "                  max_samples=1.0, n_estimators=50, n_jobs=None,\n",
       "                  oob_score=False, random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit bc to the training set\n",
    "bc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict test set labels\n",
    "y_pred = bc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy of bc: 0.74\n"
     ]
    }
   ],
   "source": [
    "# Evaluate acc_test\n",
    "acc_test = accuracy_score(y_test, y_pred)\n",
    "print('Test set accuracy of bc: {:.2f}'.format(acc_test)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Prepare the ground\n",
    "In the following exercises, you'll compare the OOB accuracy to the test set accuracy of a bagging classifier trained on the Indian Liver Patient dataset.\n",
    "\n",
    "In sklearn, you can evaluate the OOB accuracy of an ensemble classifier by setting the parameter oob_score to True during instantiation. After training the classifier, the OOB accuracy can be obtained by accessing the .oob_score_ attribute from the corresponding instance.\n",
    "\n",
    "In your environment, we have made available the class DecisionTreeClassifier from sklearn.tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Instantiate dt\n",
    "dt = DecisionTreeClassifier(min_samples_leaf=8, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Instantiate bc\n",
    "bc = BaggingClassifier(base_estimator=dt, n_estimators=50, oob_score=True, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OOB Score vs Test Set Score\n",
    "Now that you instantiated bc, you will fit it to the training set and evaluate its test set and OOB accuracies.\n",
    "\n",
    "The dataset is processed for you and split into 80% train and 20% test. The feature matrices X_train and X_test, as well as the arrays of labels y_train and y_test are available in your workspace. In addition, we have also loaded the classifier bc instantiated in the previous exercise and the function accuracy_score() from sklearn.metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(ccp_alpha=0.0,\n",
       "                                                        class_weight=None,\n",
       "                                                        criterion='gini',\n",
       "                                                        max_depth=None,\n",
       "                                                        max_features=None,\n",
       "                                                        max_leaf_nodes=None,\n",
       "                                                        min_impurity_decrease=0.0,\n",
       "                                                        min_impurity_split=None,\n",
       "                                                        min_samples_leaf=8,\n",
       "                                                        min_samples_split=2,\n",
       "                                                        min_weight_fraction_leaf=0.0,\n",
       "                                                        presort='deprecated',\n",
       "                                                        random_state=1,\n",
       "                                                        splitter='best'),\n",
       "                  bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "                  max_samples=1.0, n_estimators=50, n_jobs=None, oob_score=True,\n",
       "                  random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit bc to the training set \n",
    "bc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict test set labels\n",
    "y_pred = bc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluate test set accuracy\n",
    "acc_test = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluate OOB accuracy\n",
    "acc_oob = bc.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.747, OOB accuracy: 0.756\n"
     ]
    }
   ],
   "source": [
    "# Print acc_test and acc_oob\n",
    "print('Test set accuracy: {:.3f}, OOB accuracy: {:.3f}'.format(acc_test, acc_oob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train an RF regressor\n",
    "In the following exercises you'll predict bike rental demand in the Capital Bikeshare program in Washington, D.C using historical weather data from the Bike Sharing Demand dataset available through Kaggle. For this purpose, you will be using the random forests algorithm. As a first step, you'll define a random forests regressor and fit it to the training set.\n",
    "\n",
    "The dataset is processed for you and split into 80% train and 20% test. The features matrix X_train and the array y_train are available in your workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = df_bike.iloc[:, :-1], df_bike.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Instantiate rf\n",
    "rf = RandomForestRegressor(n_estimators=25, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=25, n_jobs=None, oob_score=False,\n",
       "                      random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit rf to the training set    \n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the RF regressor\n",
    "You'll now evaluate the test set RMSE of the random forests regressor rf that you trained in the previous exercise.\n",
    "\n",
    "The dataset is processed for you and split into 80% train and 20% test. The features matrix X_test, as well as the array y_test are available in your workspace. In addition, we have also loaded the model rf that you trained in the previous exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict the test set labels\n",
    "y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluate the test set RMSE\n",
    "rmse_test = MSE(y_test, y_pred) ** (1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set RMSE of rf: 0.00\n"
     ]
    }
   ],
   "source": [
    "# Print rmse_test\n",
    "print('Test set RMSE of rf: {:.2f}'.format(rmse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing features importances\n",
    "In this exercise, you'll determine which features were the most predictive according to the random forests regressor rf that you trained in a previous exercise.\n",
    "\n",
    "For this purpose, you'll draw a horizontal barplot of the feature importance as assessed by rf. Fortunately, this can be done easily thanks to plotting capabilities of pandas.\n",
    "\n",
    "We have created a pandas.Series object called importances containing the feature names as index and their importances as values. In addition, matplotlib.pyplot is available as plt and pandas as pd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a pd.Series of features importances\n",
    "importances = pd.Series(data=rf.feature_importances_, index= X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sort importances\n",
    "importances_sorted = importances.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Draw a horizontal barplot of importances_sorted\n",
    "importances_sorted.plot(kind='barh', color='lightgreen')\n",
    "plt.title('Features Importances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (data-camp)",
   "language": "python",
   "name": "data-camp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
