{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Introduction to Deep Learning in Python - Part 3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Datasets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Hourly Wages"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [],
   "source": [
    "hourly_wages_dataset = pd.read_csv('../datasets/hourly_wages.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Titanic dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [],
   "source": [
    "titanic_train_dataset = pd.read_csv('../datasets/titanic_train.csv')\n",
    "titanic_train_dataset['male'] = (titanic_train_dataset.Sex == 'male') * 1\n",
    "titanic_train_dataset['age_was_missing'] = titanic_train_dataset['Age'].isnull() * 1\n",
    "titanic_train_dataset.Age.fillna(titanic_train_dataset.Age.mean(), inplace=True)\n",
    "titanic_train_dataset = pd.get_dummies(titanic_train_dataset, columns=['Embarked'])\n",
    "titanic_train_dataset = titanic_train_dataset.drop(columns=['PassengerId', 'Sex', 'Cabin', 'Ticket', 'Sex'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "titanic_test_dataset = pd.read_csv('../datasets/titanic_test.csv')\n",
    "titanic_test_dataset['male'] = (titanic_test_dataset.Sex == 'male') * 1\n",
    "titanic_test_dataset['age_was_missing'] = titanic_test_dataset['Age'].isnull() * 1\n",
    "titanic_test_dataset.Age.fillna(titanic_test_dataset.Age.mean(), inplace=True)\n",
    "titanic_test_dataset = pd.get_dummies(titanic_test_dataset, columns=['Embarked'])\n",
    "titanic_test_dataset = titanic_test_dataset.drop(columns=['PassengerId', 'Sex', 'Cabin', 'Ticket', 'Sex', 'Name'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Building deep learning models with keras"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating a keras model\n",
    "- Sequential model: each layer has connection to one layes directly after it\n",
    "- Dense layer: all nodes in previous layer connect to all nodes in current layer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding your data\n",
    "You will soon start building models in Keras to predict wages based on various professional and demographic factors. Before you start building a model, it's good to understand your data by performing some exploratory analysis.\n",
    "\n",
    "The data is pre-loaded into a pandas DataFrame called df. Use the .head() and .describe() methods in the IPython Shell for a quick overview of the DataFrame.\n",
    "\n",
    "The target variable you'll be predicting is wage_per_hour. Some of the predictor variables are binary indicators, where a value of 1 represents True, and 0 represents False.\n",
    "\n",
    "Of the 9 predictor variables in the DataFrame, how many are binary indicators? The min and max values as shown by .describe() will be informative here. How many binary indicator predictors are there?\n",
    "\n",
    "**Answer: 6**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       wage_per_hour       union  education_yrs  experience_yrs         age  \\\ncount     534.000000  534.000000     534.000000      534.000000  534.000000   \nmean        9.024064    0.179775      13.018727       17.822097   36.833333   \nstd         5.139097    0.384360       2.615373       12.379710   11.726573   \nmin         1.000000    0.000000       2.000000        0.000000   18.000000   \n25%         5.250000    0.000000      12.000000        8.000000   28.000000   \n50%         7.780000    0.000000      12.000000       15.000000   35.000000   \n75%        11.250000    0.000000      15.000000       26.000000   44.000000   \nmax        44.500000    1.000000      18.000000       55.000000   64.000000   \n\n           female        marr       south  manufacturing  construction  \ncount  534.000000  534.000000  534.000000     534.000000    534.000000  \nmean     0.458801    0.655431    0.292135       0.185393      0.044944  \nstd      0.498767    0.475673    0.455170       0.388981      0.207375  \nmin      0.000000    0.000000    0.000000       0.000000      0.000000  \n25%      0.000000    0.000000    0.000000       0.000000      0.000000  \n50%      0.000000    1.000000    0.000000       0.000000      0.000000  \n75%      1.000000    1.000000    1.000000       0.000000      0.000000  \nmax      1.000000    1.000000    1.000000       1.000000      1.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>wage_per_hour</th>\n      <th>union</th>\n      <th>education_yrs</th>\n      <th>experience_yrs</th>\n      <th>age</th>\n      <th>female</th>\n      <th>marr</th>\n      <th>south</th>\n      <th>manufacturing</th>\n      <th>construction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>534.000000</td>\n      <td>534.000000</td>\n      <td>534.000000</td>\n      <td>534.000000</td>\n      <td>534.000000</td>\n      <td>534.000000</td>\n      <td>534.000000</td>\n      <td>534.000000</td>\n      <td>534.000000</td>\n      <td>534.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>9.024064</td>\n      <td>0.179775</td>\n      <td>13.018727</td>\n      <td>17.822097</td>\n      <td>36.833333</td>\n      <td>0.458801</td>\n      <td>0.655431</td>\n      <td>0.292135</td>\n      <td>0.185393</td>\n      <td>0.044944</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>5.139097</td>\n      <td>0.384360</td>\n      <td>2.615373</td>\n      <td>12.379710</td>\n      <td>11.726573</td>\n      <td>0.498767</td>\n      <td>0.475673</td>\n      <td>0.455170</td>\n      <td>0.388981</td>\n      <td>0.207375</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>18.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>5.250000</td>\n      <td>0.000000</td>\n      <td>12.000000</td>\n      <td>8.000000</td>\n      <td>28.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>7.780000</td>\n      <td>0.000000</td>\n      <td>12.000000</td>\n      <td>15.000000</td>\n      <td>35.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>11.250000</td>\n      <td>0.000000</td>\n      <td>15.000000</td>\n      <td>26.000000</td>\n      <td>44.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>44.500000</td>\n      <td>1.000000</td>\n      <td>18.000000</td>\n      <td>55.000000</td>\n      <td>64.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = hourly_wages_dataset.copy()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specifying a model\n",
    "Now you'll get to work with your first model in Keras, and will immediately be able to run more complex neural network models on larger datasets compared to the first two chapters.\n",
    "\n",
    "To start, you'll take the skeleton of a neural network and add a hidden layer and an output layer. You'll then fit that model and see Keras do the optimization so your model continually gets better.\n",
    "\n",
    "As a start, you'll predict workers wages based on characteristics like their industry, education and level of experience. You can find the dataset in a pandas dataframe called df. For convenience, everything in df except for the target has been converted to a NumPy matrix called predictors. The target, wage_per_hour, is available as a NumPy matrix called target.\n",
    "\n",
    "For all exercises in this chapter, we've imported the Sequential model constructor, the Dense layer constructor, and pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = df.drop(columns=['wage_per_hour']).values\n",
    "target = df['wage_per_hour'].values\n",
    "\n",
    "# Save the number of columns in predictors: n_cols\n",
    "n_cols = predictors.shape[1]\n",
    "\n",
    "# Set up the model: model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first layer\n",
    "model.add(Dense(50, activation='relu', input_shape=(n_cols,)))\n",
    "\n",
    "# Add the second layer\n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Compiling the model\n",
    "You're now going to compile the model you specified earlier. To compile the model, you need to specify the optimizer and loss function to use. In the video, Dan mentioned that the Adam optimizer is an excellent choice. You can read more about it as well as other Keras optimizers [here](https://keras.io/optimizers/#adam), and if you are really curious to learn more, you can read the [original paper](https://arxiv.org/abs/1412.6980v8) that introduced the Adam optimizer.\n",
    "\n",
    "In this exercise, you'll use the Adam optimizer and the mean squared error loss function. Go for it!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss function: mean_squared_error\n"
     ]
    }
   ],
   "source": [
    "# Specify the model\n",
    "n_cols = predictors.shape[1]\n",
    "model = Sequential()\n",
    "model.add(Dense(50, activation='relu', input_shape = (n_cols,)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Verify that model contains information from compiling\n",
    "print(\"Loss function: \" + model.loss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Fitting the model\n",
    "You're at the most fun part. You'll now fit the model. Recall that the data to be used as predictive features is loaded in a NumPy matrix called predictors and the data to be predicted is stored in a NumPy matrix called target. Your model is pre-written and it has been compiled with the code from the previous exercise."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 687us/step - loss: 64.2768\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x17fbaae50>"
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the model\n",
    "n_cols = predictors.shape[1]\n",
    "model = Sequential()\n",
    "model.add(Dense(50, activation='relu', input_shape = (n_cols,)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Fit the model\n",
    "model.fit(predictors, target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Understanding your classification data\n",
    "Now you will start modeling with a new dataset for a classification problem. This data includes information about passengers on the Titanic. You will use predictors such as age, fare and where each passenger embarked from to predict who will survive. This data is from [a tutorial on data science competitions](https://www.kaggle.com/c/titanic). Look [here](https://www.kaggle.com/c/titanic/data) for descriptions of the features.\n",
    "\n",
    "The data is pre-loaded in a pandas DataFrame called df.\n",
    "\n",
    "It's smart to review the maximum and minimum values of each variable to ensure the data isn't misformatted or corrupted. What was the maximum age of passengers on the Titanic? Use the .describe() method in the IPython Shell to answer this question.\n",
    "\n",
    "**Answer: 80**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "data": {
      "text/plain": "         Survived      Pclass         Age       SibSp       Parch        Fare  \\\ncount  891.000000  891.000000  891.000000  891.000000  891.000000  891.000000   \nmean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208   \nstd      0.486592    0.836071   13.002015    1.102743    0.806057   49.693429   \nmin      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000   \n25%      0.000000    2.000000   22.000000    0.000000    0.000000    7.910400   \n50%      0.000000    3.000000   29.699118    0.000000    0.000000   14.454200   \n75%      1.000000    3.000000   35.000000    1.000000    0.000000   31.000000   \nmax      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200   \n\n             male  age_was_missing  Embarked_C  Embarked_Q  Embarked_S  \ncount  891.000000       891.000000  891.000000  891.000000  891.000000  \nmean     0.647587         0.198653    0.188552    0.086420    0.722783  \nstd      0.477990         0.399210    0.391372    0.281141    0.447876  \nmin      0.000000         0.000000    0.000000    0.000000    0.000000  \n25%      0.000000         0.000000    0.000000    0.000000    0.000000  \n50%      1.000000         0.000000    0.000000    0.000000    1.000000  \n75%      1.000000         0.000000    0.000000    0.000000    1.000000  \nmax      1.000000         1.000000    1.000000    1.000000    1.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>male</th>\n      <th>age_was_missing</th>\n      <th>Embarked_C</th>\n      <th>Embarked_Q</th>\n      <th>Embarked_S</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.383838</td>\n      <td>2.308642</td>\n      <td>29.699118</td>\n      <td>0.523008</td>\n      <td>0.381594</td>\n      <td>32.204208</td>\n      <td>0.647587</td>\n      <td>0.198653</td>\n      <td>0.188552</td>\n      <td>0.086420</td>\n      <td>0.722783</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.486592</td>\n      <td>0.836071</td>\n      <td>13.002015</td>\n      <td>1.102743</td>\n      <td>0.806057</td>\n      <td>49.693429</td>\n      <td>0.477990</td>\n      <td>0.399210</td>\n      <td>0.391372</td>\n      <td>0.281141</td>\n      <td>0.447876</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.420000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>22.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>7.910400</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.000000</td>\n      <td>3.000000</td>\n      <td>29.699118</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>14.454200</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>35.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>31.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>80.000000</td>\n      <td>8.000000</td>\n      <td>6.000000</td>\n      <td>512.329200</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = titanic_train_dataset.copy()\n",
    "df.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Last steps in classification models\n",
    "You'll now create a classification model using the titanic dataset, which has been pre-loaded into a DataFrame called df. You'll take information about the passengers and predict which ones survived.\n",
    "\n",
    "The predictive variables are stored in a NumPy array predictors. The target to predict is in df.survived, though you'll have to manipulate it for Keras. The number of predictive features is stored in n_cols.\n",
    "\n",
    "Here, you'll use the 'sgd' optimizer, which stands for [Stochastic Gradient Descent](https://en.wikipedia.org/wiki/Stochastic_gradient_descent). You'll learn more about this in the next chapter!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 531us/step - loss: 1.9591 - accuracy: 0.5937\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x17fc88430>"
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors = df.drop(columns=['Survived']).values\n",
    "n_cols = predictors.shape[1]\n",
    "\n",
    "# Convert the target to categorical: target\n",
    "target = to_categorical(df.Survived)\n",
    "\n",
    "# Set up the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first layer\n",
    "model.add(Dense(32, activation='relu', input_shape=(n_cols,)))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(predictors, target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Making predictions\n",
    "The trained network from your previous coding exercise is now stored as model. New data to make predictions is stored in a NumPy array as pred_data. Use model to make predictions on your new data.\n",
    "\n",
    "In this exercise, your predictions will be probabilities, which is the most common way for data scientists to communicate their predictions to colleagues."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 531us/step - loss: 1.8303 - accuracy: 0.5668\n",
      "[0.632411   0.56648326 0.7071001  0.612461   0.71608484 0.6627423\n",
      " 0.6305056  0.91324437 0.5913416  0.8639076  0.59422576 0.90635407\n",
      " 0.99973196 0.85957396 0.99434716 0.9070342  0.7292311  0.5611994\n",
      " 0.56742567 0.58522713 0.99201185 0.51667416 0.92320365 0.9987239\n",
      " 1.         0.69188136 0.9988372  0.5623874  0.94604594 0.8148543\n",
      " 0.87976384 0.9262884  0.8578456  0.8822402  0.9966001  0.56767106\n",
      " 0.6020126  0.6348465  0.62550086 0.99606776 0.67702764 0.91168267\n",
      " 0.6089308  0.7258492  0.9860951  0.59793705 0.9359719  0.62079227\n",
      " 0.9986022  0.7787571  0.99693954 0.7596654  0.8587041  1.\n",
      " 0.7405453  0.93543637 0.6051318  0.59305465 0.7293489  1.\n",
      " 0.61224675 0.7200862  0.6025358  0.6261446  1.         0.86092925\n",
      " 0.6470355  0.9759162  0.9241262  1.         0.62808    0.5943209\n",
      " 0.6060589  0.90991014 1.         1.         0.5969631  0.8657784\n",
      " 0.7113208  0.62808    0.8797676  1.         0.9005366  0.59422576\n",
      " 0.6951552  0.67113864 0.63254774 0.63194436 0.6257302  0.9209565\n",
      " 0.74405354 0.5920771  0.9941969  0.5969631  0.89682245 0.5956455\n",
      " 0.99818915 0.6010265  0.61579216 0.60630953 0.99118984 0.89690316\n",
      " 0.62079227 0.59605104 0.6245052  0.87611824 0.6221128  0.62079227\n",
      " 0.60871565 0.7541874  0.7310865  0.6262343  0.9466941  0.6269032\n",
      " 1.         0.73648864 0.54676133 0.87513167 0.99952185 0.9048247\n",
      " 0.79334337 0.5841727  0.996332   0.5882598  0.62079227 0.81125385\n",
      " 0.59331906 0.8530787  0.7188887  0.59937775 0.6055414  0.9144719\n",
      " 0.92360914 0.5086513  0.61126405 0.59590745 0.5655517  0.7266839\n",
      " 0.6061109  0.9840211  0.9903252  0.9999999  1.         0.9028386\n",
      " 0.91787267 0.7434741  0.9913215  0.5978318  0.91168267 0.9120659\n",
      " 0.99987733 0.573239          nan 0.6864666  0.9476856  0.59049696\n",
      " 1.         0.60018975 0.91787267 0.76961356 0.6254421  0.8730193\n",
      " 0.7549513  0.57821184 0.7182383  0.8712238  0.9847232  0.9661591\n",
      " 0.91639966 0.63864183 0.5880657  0.5659467  0.7243335  0.56117845\n",
      " 0.95529276 0.98643273 0.97365    0.9885118  0.96618205 0.99928755\n",
      " 0.7113208  0.99980265 0.99442637 0.62079227 1.         0.76033276\n",
      " 0.85888344 0.55688596 0.9981306  0.7175867  0.90317595 0.9097873\n",
      " 0.76969296 0.7454261  0.97540253 0.6028596  0.99999976 0.62373644\n",
      " 0.67327255 0.60311586 0.7698529  0.8804512  1.         0.9364085\n",
      " 0.6683824  0.90473276 0.63630795 0.6683623  0.9306819  0.59741956\n",
      " 0.8756542  0.57911026 0.99950993 0.86448073 0.44928038 0.96857566\n",
      " 0.6279579  1.         1.         0.5969631  0.70955694 0.5970582\n",
      " 0.6962754  0.5925426  0.910255   0.75603646 0.59409493 0.6257302\n",
      " 0.72622985 0.71497166 0.9988386  0.9025097  0.5313796  0.62303144\n",
      " 0.9990151  0.59520465 0.99799806 0.5604071  0.75664544 0.9999796\n",
      " 0.9095087  0.94838    0.99999917 0.59407824 0.8769608  0.9867301\n",
      " 0.85349655 0.94892895 0.9048247  0.6892312  0.9600593  0.5973818\n",
      " 0.9999994  0.62171817 0.63113534 0.5880657  0.62079227 0.60246366\n",
      " 0.76546186 0.5921723  0.75390273 0.5935814  0.90702784 0.8111729\n",
      " 0.6890637  0.59422576 0.5065415  0.5880657  0.6020126  0.6353825\n",
      " 0.99930334 0.62079227 0.9999995  0.74717593 0.56110233 0.8940433\n",
      " 0.67032486 0.8998713  0.85412836 0.678145   0.6246275  0.83347124\n",
      " 0.6257302  0.8618248  0.90955085 0.5944788  0.58269894 0.99971884\n",
      " 0.56117845 0.5969631  0.96409667 0.6187688  0.56117845 0.99940157\n",
      " 0.6337525  0.59819305 0.9936359  0.8148543  0.9827352  0.59977466\n",
      " 0.60068953 0.72714764 0.84305626 0.6101678  0.6257302  0.8775753\n",
      " 0.9999999  0.78162897 0.99982953 0.6867578  0.6302157  0.56199145\n",
      " 0.588512   0.6377955  0.9999993  0.6477836  0.99999976 0.69252896\n",
      " 0.5982292  0.9317421  0.59605104 0.5644417  0.7266839  0.92268527\n",
      " 1.         0.58077383 0.979684   0.99956113 0.9052676  0.74628687\n",
      " 0.97295547 0.9399642  0.56110233 0.78034925 0.598966   0.91346025\n",
      " 0.71250844 0.56560385 0.93456763 0.56117845 0.6963454  0.59722304\n",
      " 0.9997459  1.         0.69801843 0.6302523  0.7266839  0.57982606\n",
      " 0.7477494  0.87474287 0.99657464 0.6683824  0.9995004  0.9962179\n",
      " 0.9269804  0.898527   0.98855376 0.59393066 0.62079227 0.7524636\n",
      " 0.99855095 0.9747385  0.87474287 0.612461   0.9967025  0.9997695\n",
      " 0.671255   0.98210204 0.99453664 0.7221691  0.6835366  0.9999994\n",
      " 0.54465574 0.72018707 0.9993987  1.         0.5703807  0.71015054\n",
      " 0.9870489  0.95950097 0.62079227 0.62689394 0.7299592  0.7813446\n",
      " 0.70405376 0.99889696 0.594501   0.7285365  0.62088513 0.8794137\n",
      " 0.99992824 0.97857136 0.8941265  0.6836887  0.8449027  0.9973055\n",
      " 0.61446136 0.9995763  0.59294903 0.6281401  1.         0.8339571\n",
      " 0.9984731  0.99068767 0.9137294  0.7579339  0.6451148  1.\n",
      " 0.62522626 0.8308107  0.6257302  0.99986446 0.602646   0.5969631\n",
      " 0.9999889  0.5964162  0.5969631  0.8504705 ]\n"
     ]
    }
   ],
   "source": [
    "pred_data = titanic_test_dataset.copy().values\n",
    "\n",
    "# Specify, compile, and fit the model\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_shape = (n_cols,)))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(predictors, target)\n",
    "\n",
    "# Calculate predictions: predictions\n",
    "predictions = model.predict(pred_data)\n",
    "\n",
    "# Calculate predicted probability of survival: predicted_prob_true\n",
    "predicted_prob_true = predictions[:,1]\n",
    "\n",
    "# print predicted_prob_true\n",
    "print(predicted_prob_true)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}