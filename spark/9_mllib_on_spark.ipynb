{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/kodolamaczlogo.png)\n",
    "\n",
    "# Przetwarzanie Big Data z użyciem Apache Spark\n",
    "\n",
    "Autor notebooka: Jakub Nowacki.\n",
    "\n",
    "## Uczenie Maszynowe (Machine Learning) na Spark\n",
    "\n",
    "Spark ML zawiera wiele algorytmów uczenia maszynowego, które się dobrze działają w sposób rozproszony i się skalują, w tym:\n",
    "\n",
    "* regresja liniowa,\n",
    "* regresja logistyczna,\n",
    "* algorytm random forest,\n",
    "* algorytm centroidów (k-means).\n",
    "\n",
    "To API wykorzystuje RDD i wymaga nieco pracy z przydotowaniem danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "spark = pyspark.sql.SparkSession.builder \\\n",
    "    .appName(\"SparkMLlib\") \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint, LinearRegressionWithSGD\n",
    "from operator import add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ładujemy dane z pliku CSV.\n",
    "# Szczegółowy opis danych jest dostępny w pliku README\n",
    "rdd = sc.textFile(\"data/Bike-Sharing-Dataset/day.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'instant,dteday,season,yr,mnth,holiday,weekday,workingday,weathersit,temp,atemp,hum,windspeed,casual,registered,cnt'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['instant',\n",
       " 'dteday',\n",
       " 'season',\n",
       " 'yr',\n",
       " 'mnth',\n",
       " 'holiday',\n",
       " 'weekday',\n",
       " 'workingday',\n",
       " 'weathersit',\n",
       " 'temp',\n",
       " 'atemp',\n",
       " 'hum',\n",
       " 'windspeed',\n",
       " 'casual',\n",
       " 'registered',\n",
       " 'cnt']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_columns = rdd.first().split(\",\")\n",
    "all_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cols = ['yr', 'workingday', 'weathersit', 'temp', 'hum', 'windspeed']\n",
    "y_col = 'casual'\n",
    "x_inds = [i for i, col in enumerate(all_columns) if col in x_cols]\n",
    "y_ind = all_columns.index(y_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lps = rdd \\\n",
    "  .filter(lambda line: not line.startswith(\"instant\")) \\\n",
    "  .map(lambda line: line.split(\",\")) \\\n",
    "  .map(lambda values: LabeledPoint(float(values[y_ind]), [float(values[i]) for i in x_inds])) \\\n",
    "  .cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(331.0, [0.0,0.0,2.0,0.344167,0.805833,0.160446]),\n",
       " LabeledPoint(131.0, [0.0,0.0,2.0,0.363478,0.696087,0.248539]),\n",
       " LabeledPoint(120.0, [0.0,1.0,1.0,0.196364,0.437273,0.248309]),\n",
       " LabeledPoint(108.0, [0.0,1.0,1.0,0.2,0.590435,0.160296]),\n",
       " LabeledPoint(82.0, [0.0,1.0,1.0,0.226957,0.436957,0.1869])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lps.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# zobaczmy co znajduje się w LabelPoint\n",
    "p = lps.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "331.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([0.0, 0.0, 2.0, 0.3442, 0.8058, 0.1604])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/bin/spark/python/pyspark/mllib/regression.py:281: UserWarning: Deprecated in 2.0.0. Use ml.regression.LinearRegression.\n",
      "  warnings.warn(\"Deprecated in 2.0.0. Use ml.regression.LinearRegression.\")\n"
     ]
    }
   ],
   "source": [
    "# tworzenie regresora i uczenie na danych\n",
    "lrspark = LinearRegressionWithSGD.train(lps, iterations=100, intercept=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "912.51987276275258"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predykcja\n",
    "lrspark.predict([0.0,0.0,2.0,0.344167,0.805833,0.160446])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prawdziwe odpowiedzi i predykcja\n",
    "y_ypred = lps.map(lambda x: (x.label, lrspark.predict(x.features))).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(331.0, 912.51987276275258),\n",
       " (131.0, 903.77283936573997),\n",
       " (120.0, 128.93655592371169),\n",
       " (108.0, 176.71036069759646),\n",
       " (82.0, 163.78715609278061)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ypred.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 848.1764705882356, Variance: 470805.5023738634, Residual Variance: 186216.51706338648\n",
      "R^2 is: 0.604\n"
     ]
    }
   ],
   "source": [
    "# policzmy R^2 ręcznie\n",
    "\n",
    "mean_y = y_ypred.map(lambda x: x[0]).mean()\n",
    "\n",
    "variance_y = y_ypred.map(lambda x: x[0]).variance()\n",
    "\n",
    "residual_variance_y = y_ypred \\\n",
    "  .map(lambda x: (x[0] - x[1])**2) \\\n",
    "  .reduce(add) / y_ypred.count()\n",
    "\n",
    "R2 = 1 - residual_variance_y/variance_y\n",
    "\n",
    "print(\"Mean: {}, Variance: {}, Residual Variance: {}\".format(mean_y, variance_y, residual_variance_y))\n",
    "print(\"R^2 is: {:.3f}\".format(R2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie\n",
    "\n",
    "* Użyj skali logarytmicznej dla `casual`.\n",
    "* ★ Przeprowadź kroswalidację (podpowiedź: `lps.randomSplit([0.75, 0.25])`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lps = rdd \\\n",
    "  .filter(lambda line: not line.startswith(\"instant\")) \\\n",
    "  .map(lambda line: line.split(\",\")) \\\n",
    "  .map(lambda values: LabeledPoint(math.log10(float(values[y_ind])), [float(values[i]) for i in x_inds])) \\\n",
    "  .cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(2.519827993775719, [0.0,0.0,2.0,0.344167,0.805833,0.160446]),\n",
       " LabeledPoint(2.1172712956557644, [0.0,0.0,2.0,0.363478,0.696087,0.248539]),\n",
       " LabeledPoint(2.0791812460476247, [0.0,1.0,1.0,0.196364,0.437273,0.248309]),\n",
       " LabeledPoint(2.03342375548695, [0.0,1.0,1.0,0.2,0.590435,0.160296]),\n",
       " LabeledPoint(1.9138138523837167, [0.0,1.0,1.0,0.226957,0.436957,0.1869])]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lps.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = lps.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/bin/spark/python/pyspark/mllib/regression.py:281: UserWarning: Deprecated in 2.0.0. Use ml.regression.LinearRegression.\n",
      "  warnings.warn(\"Deprecated in 2.0.0. Use ml.regression.LinearRegression.\")\n"
     ]
    }
   ],
   "source": [
    "lrspark = LinearRegressionWithSGD.train(lps, iterations=100, intercept=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6218774814630832"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrspark.predict([0.0,0.0,2.0,0.344167,0.805833,0.160446])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(331.0000000000001, 418.67543619808464),\n",
       " (131.00000000000006, 402.72396349808065),\n",
       " (119.99999999999996, 154.7767938411198),\n",
       " (108.00000000000004, 178.52028580106682),\n",
       " (82.0, 164.12663209690226)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ypred = lps.map(lambda x: (x.label, lrspark.predict(x.features))).cache()\n",
    "[(10**p[0], 10**p[1]) for p in y_ypred.take(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
