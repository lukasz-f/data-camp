{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/kodolamaczlogo.png)\n",
    "\n",
    "# Przetwarzanie Big Data z użyciem Apache Spark\n",
    "\n",
    "Autor notebooka: Jakub Nowacki.\n",
    "\n",
    "## Uczenie Maszynowe (Machine Learning) na Spark\n",
    "\n",
    "Spark ML zawiera wiele algorytmów uczenia maszynowego, które się dobrze działają w sposób rozproszony i się skalują, w tym:\n",
    "\n",
    "* regresja liniowa,\n",
    "* regresja logistyczna,\n",
    "* algorytm random forest,\n",
    "* algorytm centroidów (k-means).\n",
    "\n",
    "To API wykorzystuje RDD i wymaga nieco pracy z przydotowaniem danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "spark = pyspark.sql.SparkSession.builder \\\n",
    "    .appName(\"SparkMLlib\") \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint, LinearRegressionWithSGD\n",
    "from operator import add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ładujemy dane z pliku CSV.\n",
    "# Szczegółowy opis danych jest dostępny w pliku README\n",
    "rdd = sc.textFile(\"data/Bike-Sharing-Dataset/day.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'instant,dteday,season,yr,mnth,holiday,weekday,workingday,weathersit,temp,atemp,hum,windspeed,casual,registered,cnt'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['instant',\n",
       " 'dteday',\n",
       " 'season',\n",
       " 'yr',\n",
       " 'mnth',\n",
       " 'holiday',\n",
       " 'weekday',\n",
       " 'workingday',\n",
       " 'weathersit',\n",
       " 'temp',\n",
       " 'atemp',\n",
       " 'hum',\n",
       " 'windspeed',\n",
       " 'casual',\n",
       " 'registered',\n",
       " 'cnt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_columns = rdd.first().split(\",\")\n",
    "all_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['yr', 'workingday', 'weathersit', 'temp', 'hum', 'windspeed'],\n",
       " [3, 7, 8, 9, 11, 12],\n",
       " 'casual',\n",
       " 13)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_cols = ['yr', 'workingday', 'weathersit', 'temp', 'hum', 'windspeed']\n",
    "y_col = 'casual'\n",
    "x_inds = [i for i, col in enumerate(all_columns) if col in x_cols]\n",
    "y_ind = all_columns.index(y_col)\n",
    "x_cols, x_inds, y_col, y_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lps = rdd \\\n",
    "  .filter(lambda line: not line.startswith(\"instant\")) \\\n",
    "  .map(lambda line: line.split(\",\")) \\\n",
    "  .map(lambda values: LabeledPoint(math.log10(float(values[y_ind])), [float(values[i]) for i in x_inds])) \\\n",
    "  .cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(2.519827993775719, [0.0,0.0,2.0,0.344167,0.805833,0.160446]),\n",
       " LabeledPoint(2.1172712956557644, [0.0,0.0,2.0,0.363478,0.696087,0.248539]),\n",
       " LabeledPoint(2.0791812460476247, [0.0,1.0,1.0,0.196364,0.437273,0.248309]),\n",
       " LabeledPoint(2.03342375548695, [0.0,1.0,1.0,0.2,0.590435,0.160296]),\n",
       " LabeledPoint(1.9138138523837167, [0.0,1.0,1.0,0.226957,0.436957,0.1869])]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lps.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# zobaczmy co znajduje się w LabelPoint\n",
    "p = lps.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.519827993775719"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([0.0, 0.0, 2.0, 0.3442, 0.8058, 0.1604])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kodolamacz/spark/python/pyspark/mllib/regression.py:281: UserWarning: Deprecated in 2.0.0. Use ml.regression.LinearRegression.\n",
      "  warnings.warn(\"Deprecated in 2.0.0. Use ml.regression.LinearRegression.\")\n"
     ]
    }
   ],
   "source": [
    "# tworzenie regresora i uczenie na danych\n",
    "lrspark = LinearRegressionWithSGD.train(lps, iterations=100, intercept=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6218774814630832"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predykcja\n",
    "lrspark.predict([0.0,0.0,2.0,0.344167,0.805833,0.160446])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prawdziwe odpowiedzi i predykcja\n",
    "y_ypred = lps.map(lambda x: (x.label, lrspark.predict(x.features))).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2.519827993775719, 2.6218774814630832),\n",
       " (2.1172712956557644, 2.6050074724317289),\n",
       " (2.0791812460476247, 2.1897058461256482),\n",
       " (2.03342375548695, 2.2516875734504036),\n",
       " (1.9138138523837167, 2.2151790578006851)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ypred.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 2.7568155886472994, Variance: 0.19532857807621223, Residual Variance: 0.07397992619410722\n",
      "R^2 is: 0.621\n"
     ]
    }
   ],
   "source": [
    "# policzmy R^2 ręcznie\n",
    "\n",
    "mean_y = y_ypred.map(lambda x: x[0]).mean()\n",
    "\n",
    "variance_y = y_ypred.map(lambda x: x[0]).variance()\n",
    "\n",
    "residual_variance_y = y_ypred \\\n",
    "  .map(lambda x: (x[0] - x[1])**2) \\\n",
    "  .reduce(add) / y_ypred.count()\n",
    "\n",
    "R2 = 1 - residual_variance_y/variance_y\n",
    "\n",
    "print(\"Mean: {}, Variance: {}, Residual Variance: {}\".format(mean_y, variance_y, residual_variance_y))\n",
    "print(\"R^2 is: {:.3f}\".format(R2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[418.67543619808464,\n",
       " 402.72396349808105,\n",
       " 154.77679384111997,\n",
       " 178.52028580106682,\n",
       " 164.12663209690243,\n",
       " 163.77026089420562,\n",
       " 109.40290057904967,\n",
       " 206.6729364757542,\n",
       " 263.29389727318977,\n",
       " 143.49716676341191]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[10**p[1] for p in y_ypred.take(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie\n",
    "\n",
    "* Użyj skali logarytmicznej dla `casual`.\n",
    "* ★ Przeprowadź kroswalidację (podpowiedź: `lps.randomSplit([0.75, 0.25])`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train, validate, test = lps.randomSplit([0.6, 0.2, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
