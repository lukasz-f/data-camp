{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Developing LLM Applications with LangChain - Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to LangChain & Chatbot Mechanics\n",
    "\n",
    "Welcome to the LangChain framework for building applications on LLMs! You'll learn about the main components of LangChain, including models, chains, agents, prompts, and parsers. You'll create chatbots using both open-source models from Hugging Face and proprietary models from OpenAI, create prompt templates, and integrate different chatbot memory strategies to manage context and resources during conversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set your Hugging Face API token \n",
    "huggingfacehub_api_token = os.environ['HUGGING_FACE_TOKEN']\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai_api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hugging Face models in LangChain!\n",
    "There are thousands of language models freely available to use on Hugging Face. Hugging Face integrates really nicely into LangChain, so in this exercise, you'll use LangChain to load and predict using a model from Hugging Face.\n",
    "\n",
    "To complete this exercise, you'll need first need to create a free Hugging Face API token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "With the arrival of a new season, we have a new in-store collection for you to explore.\n",
      "For all the busy fashionistas and trend-setters, we're rolling out our new #FallFashion #IWD and #TBT collections at the beginning of September.\n",
      "From fun and fabulous to statement and stylish, we've got everything you need to make your wardrobe look on-trend this autumn.\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "\n",
    "# Define the LLM\n",
    "llm = HuggingFaceEndpoint(repo_id='tiiuae/falcon-7b-instruct', \n",
    "                          huggingfacehub_api_token=huggingfacehub_api_token)\n",
    "\n",
    "# Predict the words following the text in question\n",
    "question = 'Whatever you do, take care of your shoes'\n",
    "output = llm.invoke(question)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI models in LangChain!\n",
    "OpenAI's models are particularly well-regarded in the AI/LLM community; their high performance is largely part to the use of their proprietary technology and carefully selected training data. In contrast to the open-source models on Hugging Face, OpenAI's models do have costs associated with their use.\n",
    "\n",
    "Due to LangChain's unified syntax, swapping one model for another only requires changing a small amount of code. In this exercise, you'll do just that!\n",
    "\n",
    "You do not need to create or provide an OpenAI API key for this course. The \"<OPENAI_API_TOKEN>\" placeholder will send valid requests to the API. If you encounter a RateLimitError, pause for a moment and try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\n",
      "\n",
      "Your shoes are an important part of your wardrobe and can greatly impact your overall look. To ensure they last as long as possible and always look their best, here are some tips to take care of your shoes:\n",
      "\n",
      "1. Store them properly: When you're not wearing your shoes, make sure to store them in a cool, dry place. Avoid leaving them near direct sunlight or heat sources as this can cause the material to crack or fade.\n",
      "\n",
      "2. Clean them regularly: Wipe your shoes down with a damp cloth after each wear to remove any dirt or debris. For more stubborn stains, use a specialized cleaner or spot treatment.\n",
      "\n",
      "3. Protect them from the elements: If you're wearing leather or suede shoes in wet weather, make sure to treat them with a waterproofing spray beforehand. This will help prevent any damage or discoloration.\n",
      "\n",
      "4. Rotate your shoes: Wearing the same pair of shoes every day can cause them to wear out quickly. Rotate your shoes and give them a break in between wears to prolong their lifespan.\n",
      "\n",
      "5. Use shoe trees: Shoe trees are an excellent investment to help maintain the shape of your shoes and prevent creases. They also absorb moisture and odors, keeping your shoes fresh.\n",
      "\n",
      "6. Avoid wearing them for strenuous\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAI\n",
    "\n",
    "# Define the LLM\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\", \n",
    "             api_key=openai_api_key)\n",
    "\n",
    "# Predict the words following the text in question\n",
    "question = 'Whatever you do, take care of your shoes'\n",
    "output = llm.invoke(question)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt templates and chaining\n",
    "In this exercise, you'll begin using two of the core components in LangChain: prompt templates and chains!\n",
    "\n",
    "Prompt templates are used for creating prompts in a more modular way, so they can be reused and built on. Chains act as the glue in LangChain; bringing the other components together into workflows that pass inputs and outputs between the different components.\n",
    "\n",
    "The classes necessary for completing this exercise, including HuggingFaceEndpoint, have been pre-loaded for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LangChain makes LLM application development easier by providing a comprehensive suite of tools and services for building legal tech applications. LangChain offers a powerful code editor with auto-complete and syntax highlighting to streamline the development process, as well as a range of templates and libraries to help LLM developers build efficient and user-friendly applications. Additionally, LangChain offers a range of integration options, including with popular document management and communication platforms, to help LLM developers save time and streamline their workflows.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "\n",
    "# Create a prompt template from the template string\n",
    "template = \"You are an artificial intelligence assistant, answer the question. {question}\"\n",
    "prompt = PromptTemplate(template=template, \n",
    "                        input_variables=['question'])\n",
    "\n",
    "# Create a chain to integrate the prompt template and LLM\n",
    "llm = HuggingFaceEndpoint(repo_id='tiiuae/falcon-7b-instruct', \n",
    "                          huggingfacehub_api_token=huggingfacehub_api_token)\n",
    "llm_chain = prompt | llm\n",
    "\n",
    "question = \"How does LangChain make LLM application development easier?\"\n",
    "print(llm_chain.invoke(\n",
    "    {\n",
    "        \"question\": question\n",
    "    }\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat prompt templates\n",
    "Given the importance of chat models in many different LLM applications, LangChain provides functionality for accessing chat-specific models and chat prompt templates.\n",
    "\n",
    "In this exercise, you'll define a chat model from OpenAI, and create a prompt template for it to begin sending it user input questions.\n",
    "\n",
    "All of the LangChain classes necessary for completing this exercise have been pre-loaded for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retaining learning effectively involves a combination of strategies that enhance understanding and memory. Here are some techniques you can use:\n",
      "\n",
      "1. **Active Engagement**: Instead of passively reading or listening, engage with the material. Take notes, summarize information in your own words, or teach the concepts to someone else.\n",
      "\n",
      "2. **Spaced Repetition**: Use spaced repetition techniques to review material over increasing intervals of time. This helps reinforce memory and combat forgetting.\n",
      "\n",
      "3. **Practice Retrieval**: Test yourself regularly on the material you’ve learned. This could be through flashcards, quizzes, or practice exams. Retrieval practice strengthens memory.\n",
      "\n",
      "4. **Connect New Information**: Relate new information to what you already know. Creating associations helps deepen understanding and makes recall easier.\n",
      "\n",
      "5. **Use Multiple Modalities**: Engage with the material through different formats—read, watch videos, listen to podcasts, and participate in discussions. This variety can enhance retention.\n",
      "\n",
      "6. **Stay Organized**: Keep your notes and materials organized. Use outlines, mind maps, or concept maps to visualize relationships between concepts.\n",
      "\n",
      "7. **Set Goals**: Establish clear, achievable learning goals. This can help you stay focused and motivated, making it easier to retain information.\n",
      "\n",
      "8. **Take Breaks**: Incorporate breaks into your study sessions. Short breaks can help prevent burnout and improve concentration when you return to studying.\n",
      "\n",
      "9. **Healthy Lifestyle**: Maintain a healthy lifestyle with proper nutrition, regular exercise, and adequate sleep. These factors significantly impact cognitive function and memory.\n",
      "\n",
      "10. **Reflect and Review**: After learning something new, take time to reflect on it. Review your notes and think about how the new information fits into your existing knowledge.\n",
      "\n",
      "By incorporating these strategies into your learning routine, you can improve your retention and understanding of the material.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Define an OpenAI chat model\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", \n",
    "                 temperature=0, \n",
    "                 api_key=openai_api_key)\n",
    "\n",
    "# Create a chat prompt template\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant.\"),\n",
    "        (\"human\", \"Respond to question: {question}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Chain the prompt template and model, and invoke the chain\n",
    "llm_chain = prompt_template | llm\n",
    "response = llm_chain.invoke({\"question\": \"How can I retain learning?\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrating a chatbot message history\n",
    "A key feature of chatbot applications is the ability to have a conversation, where context from the conversation history is stored and available for the model to access.\n",
    "\n",
    "In this exercise, you'll create a conversation history that will be passed to the model. This history will contain every message in the conversation, including the user inputs and model responses.\n",
    "\n",
    "All of the LangChain classes necessary for completing this exercise have been pre-loaded for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A list comprehension is a concise way to create lists in Python using a single line of code, typically involving an expression and a loop.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.memory import ChatMessageHistory\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", \n",
    "                 temperature=0, \n",
    "                 api_key=openai_api_key)\n",
    "\n",
    "# Create the conversation history and add the first AI message\n",
    "history = ChatMessageHistory()\n",
    "history.add_ai_message(\"Hello! Ask me anything about Python programming!\")\n",
    "\n",
    "# Add the user message to the history\n",
    "history.add_user_message(\"What is a list comprehension?\")\n",
    "\n",
    "# Add another user message and call the model\n",
    "history.add_user_message(\"Describe the same in fewer words\")\n",
    "\n",
    "response = llm.invoke(history.messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a memory buffer\n",
    "For many applications, storing and accessing the entire conversation history isn't technically feasible. In these cases, the messages must be condensed while retaining as much relevant context as possible. One common way of doing this is with a memory buffer, which stores only the most recent messages.\n",
    "\n",
    "In this exercise, you'll integrate a memory buffer into an OpenAI chat model using an LCEL chain.\n",
    "\n",
    "All of the LangChain classes necessary for completing this exercise have been pre-loaded for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7q/7zxlvd7j5c7_lt1w5dlntj780000gn/T/ipykernel_41658/635780711.py:8: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(size=4)\n",
      "/var/folders/7q/7zxlvd7j5c7_lt1w5dlntj780000gn/T/ipykernel_41658/635780711.py:11: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
      "  buffer_chain = ConversationChain(llm=llm, memory=memory)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Use the Seaborn library.',\n",
       " 'history': \"Human: Write Python code to draw a scatter plot.\\nAI: Sure! To draw a scatter plot in Python, you can use the popular library called Matplotlib. Here's a simple example of how to create a scatter plot:\\n\\n```python\\nimport matplotlib.pyplot as plt\\n\\n# Sample data\\nx = [1, 2, 3, 4, 5]\\ny = [2, 3, 5, 7, 11]\\n\\n# Create a scatter plot\\nplt.scatter(x, y, color='blue', marker='o')\\n\\n# Add titles and labels\\nplt.title('Sample Scatter Plot')\\nplt.xlabel('X-axis Label')\\nplt.ylabel('Y-axis Label')\\n\\n# Show the plot\\nplt.grid(True)\\nplt.show()\\n```\\n\\nIn this code:\\n- We import the `matplotlib.pyplot` module, which provides a MATLAB-like interface for plotting.\\n- We define two lists, `x` and `y`, which contain the coordinates of the points we want to plot.\\n- The `plt.scatter()` function is used to create the scatter plot, where you can customize the color and marker style.\\n- We add a title and labels for the axes using `plt.title()`, `plt.xlabel()`, and `plt.ylabel()`.\\n- Finally, `plt.show()` displays the plot.\\n\\nYou can customize the data and appearance further based on your needs! If you have any specific requirements or questions, feel free to ask!\",\n",
       " 'response': \"Absolutely! Seaborn is a great library for creating attractive and informative statistical graphics. It works well with Matplotlib and provides a high-level interface for drawing various types of plots, including scatter plots. Here's how you can create a scatter plot using Seaborn:\\n\\n```python\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\n\\n# Sample data\\ndata = {\\n    'x': [1, 2, 3, 4, 5],\\n    'y': [2, 3, 5, 7, 11]\\n}\\n\\n# Create a scatter plot using Seaborn\\nsns.scatterplot(data=data, x='x', y='y', color='blue', marker='o')\\n\\n# Add titles and labels\\nplt.title('Sample Scatter Plot with Seaborn')\\nplt.xlabel('X-axis Label')\\nplt.ylabel('Y-axis Label')\\n\\n# Show the plot\\nplt.grid(True)\\nplt.show()\\n```\\n\\nIn this code:\\n- We import the `seaborn` library as `sns` and `matplotlib.pyplot` as `plt`.\\n- We create a dictionary called `data` to hold our sample data for the x and y coordinates.\\n- The `sns.scatterplot()` function is used to create the scatter plot. You can specify the data, the x and y variables, and customize the color and marker style.\\n- We add a title and labels for the axes using Matplotlib's `plt.title()`, `plt.xlabel()`, and `plt.ylabel()`.\\n- Finally, we display the plot with `plt.show()`.\\n\\nSeaborn also allows for additional customization, such as adding a regression line or changing the aesthetics. If you have any specific features in mind or further questions, just let me know!\"}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", \n",
    "                 temperature=0, \n",
    "                 api_key=openai_api_key)\n",
    "\n",
    "# Define a buffer memory\n",
    "memory = ConversationBufferMemory(size=4)\n",
    "\n",
    "# Define the chain for integrating the memory with the model\n",
    "buffer_chain = ConversationChain(llm=llm, \n",
    "                                 memory=memory)\n",
    "\n",
    "# Invoke the chain with the inputs provided\n",
    "buffer_chain.invoke(\"Write Python code to draw a scatter plot.\")\n",
    "buffer_chain.invoke(\"Use the Seaborn library.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing a summary memory\n",
    "For longer conversations, storing the entire memory, or even a long buffer memory, may not be technically feasible. In these cases, a summary memory implementation can be a good option. Summary memories summarize the conversation at each step to retain only the key context for the model to use. This works by using another LLM for generating the summaries, alongside the LLM used for generating the responses.\n",
    "\n",
    "In this exercise, you'll implement a chatbot summary memory, using an OpenAI chat model for generating the summaries.\n",
    "\n",
    "All of the LangChain classes necessary for completing this exercise have been pre-loaded for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7q/7zxlvd7j5c7_lt1w5dlntj780000gn/T/ipykernel_41658/4215490703.py:10: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationSummaryMemory(llm=llm)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Describe the relationship of the human mind with the keyboard when taking a great online class.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "The human asks the AI to describe the relationship between the human mind and the keyboard during an online class. The AI explains that this relationship is fascinating, as the keyboard serves as a vital tool for interaction, expression, and learning. It allows students to communicate thoughts in real-time, enhancing memory retention through the act of typing. The keyboard also facilitates immediate feedback during discussions and quizzes, keeping students engaged. Additionally, it provides access to resources and collaboration opportunities, enriching the learning experience. However, the AI notes that distractions and multitasking can hinder effective learning, emphasizing the importance of balancing productive engagement with minimizing distractions for a successful online class experience.\n",
      "Human: Use an analogy to describe it.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Use an analogy to describe it.',\n",
       " 'history': 'The human asks the AI to describe the relationship between the human mind and the keyboard during an online class. The AI explains that this relationship is fascinating, as the keyboard serves as a vital tool for interaction, expression, and learning. It allows students to communicate thoughts in real-time, enhancing memory retention through the act of typing. The keyboard also facilitates immediate feedback during discussions and quizzes, keeping students engaged. Additionally, it provides access to resources and collaboration opportunities, enriching the learning experience. However, the AI notes that distractions and multitasking can hinder effective learning, emphasizing the importance of balancing productive engagement with minimizing distractions for a successful online class experience.',\n",
       " 'response': 'Sure! You can think of the relationship between the human mind and the keyboard during an online class like that of a painter and their canvas. Just as a painter uses a canvas to express their creativity, ideas, and emotions through brushstrokes, a student uses the keyboard to articulate their thoughts, questions, and insights during the class. \\n\\nThe keyboard acts as the canvas where the student’s knowledge and understanding come to life, allowing them to create a vivid picture of their learning journey. Each keystroke is like a brushstroke, contributing to a larger masterpiece of understanding. \\n\\nHowever, just as a painter can be distracted by noise or interruptions in their environment, a student can also face distractions while typing. If the painter is not focused, their artwork may not turn out as intended. Similarly, if a student is multitasking or distracted, their learning experience may suffer. \\n\\nUltimately, both the painter and the student need to find a balance—immersing themselves in their work while minimizing distractions to create something beautiful and meaningful.'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", \n",
    "                 temperature=0, \n",
    "                 api_key=openai_api_key)\n",
    "\n",
    "# Define a summary memory that uses an OpenAI chat model\n",
    "memory = ConversationSummaryMemory(llm=llm)\n",
    "\n",
    "# Define the chain for integrating the memory with the model\n",
    "summary_chain = ConversationChain(llm=llm, \n",
    "                                  memory=memory, \n",
    "                                  verbose=True)\n",
    "\n",
    "# Invoke the chain with the inputs provided\n",
    "summary_chain.invoke(\"Describe the relationship of the human mind with the keyboard when taking a great online class.\")\n",
    "summary_chain.invoke(\"Use an analogy to describe it.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
