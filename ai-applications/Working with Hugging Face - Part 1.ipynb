{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Hugging Face - Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started with Hugging Face\n",
    "\n",
    "Start your journey with the Hugging Face platform by understanding what Hugging Face is and common use cases. Then, you'll learn about the Hugging Face Hub including models and datasets available, how to search for them, navigate model, or dataset, cards, and download. Lastly, you'll learn about the high-level components of transformers and LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching the Hub with Python\n",
    "The Hugging Face Hub provides a nice user interface for searching for models and learning more about them. At times, you may find it convenient to be able to do the same thing without leaving the development environment. Fortunately, Hugging Face also provides a Python package which allows you to find models through code.\n",
    "\n",
    "Use the huggingface_hub package to find the most downloaded model for text classification.\n",
    "\n",
    "HfApi and ModelFilter from the huggingface_hub package is already loaded for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1231czx/llama3_it_ultra_list_and_bold500\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "\n",
    "api = HfApi()\n",
    "\n",
    "# Return the filtered list from the Hub\n",
    "models = api.list_models(\n",
    "    task=\"text-classification\",\n",
    "    sort=\"downloads\",\n",
    "    direction=-1,\n",
    "  \tlimit=1\n",
    ")\n",
    "\n",
    "# Store as a list\n",
    "modelList = list(models)\n",
    "\n",
    "print(modelList[0].modelId)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving a model\n",
    "There may be situations where downloading and storing a model locally (i.e. a directory on your computer) is desired. For example, if working offline.\n",
    "\n",
    "Practice downloading and saving here. An instance of AutoModel is already loaded for you under the same name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "modelId = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "\n",
    "# Instantiate the AutoModel class\n",
    "model = AutoModel.from_pretrained(modelId)\n",
    "\n",
    "# Save the model\n",
    "model.save_pretrained(save_directory=f\"models/{modelId}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting datasets\n",
    "The datasets on Hugging Face range in terms of size, information, and features. Therefore it's beneficial to inspect it before committing to loading a dataset into your environment.\n",
    "\n",
    "Let's inspect the \"derenrich/wikidata-en-descriptions-small\" dataset.\n",
    "\n",
    "Note: this exercise may take a minute due to the dataset size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b958a36336c140c9b583897cb85e813a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/615 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'output': Value(dtype='string', id=None), 'qid': Value(dtype='string', id=None), 'name': Value(dtype='string', id=None), 'input': Value(dtype='string', id=None), 'instruction': Value(dtype='string', id=None), 'text': Value(dtype='string', id=None)}\n"
     ]
    }
   ],
   "source": [
    "# Load the module\n",
    "from datasets import load_dataset_builder\n",
    "\n",
    "# Create the dataset builder\n",
    "reviews_builder = load_dataset_builder(\"derenrich/wikidata-en-descriptions-small\")\n",
    "\n",
    "# Print the features\n",
    "print(reviews_builder.info.features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading datasets\n",
    "Hugging Face built the dataset package for interacting with datasets. There are a lot of convenient functions, including load_dataset_builder which we just used. After inspecting a dataset to ensure its the right one for your project, it's time to load the dataset! For this, we can leverage input parameters for load_dataset to specify which parts of a dataset to load, i.e. the \"train\" dataset for English wikipedia articles.\n",
    "\n",
    "The load_dataset module from the datasets package is already loaded for you. Note: the load_dataset function was modified for the purpose of this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the dataset is 1587721\n"
     ]
    }
   ],
   "source": [
    "# Load the module\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load the train portion of the dataset\n",
    "wikipedia = load_dataset(\"wikimedia/wikipedia\", name=\"20231101.pl\", split=\"train\")\n",
    "\n",
    "print(f\"The length of the dataset is {len(wikipedia)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating datasets\n",
    "There will likely be many occasions when you will need to manipulate a dataset before using it within a ML task. Two common manipulations are filtering and selecting (or slicing). Given the size of these datasets, Hugging Face leverages arrow file types.\n",
    "\n",
    "This means performing manipulations are slightly different than what you might be used to. Fortunately, there's already methods to help with this!\n",
    "\n",
    "The dataset is already loaded for you under wikipedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bobo – nadprzyrodzona istota z polskiego folkloru, prawdopodobnie demon z wierzeń słowiańskich. Innymi nazwami tej istoty są: bobok (Wielkopolska, Małopolska), babok (Kujawy), bebok (Śląsk), bobek, bobik (Kraj morawsko-śląski). \n",
      "\n",
      "W polskich wierzeniach ludowych bobo był małą, brzydką i złośliwą istotą, którą straszono dzieci w celu ich zdyscyplinowania. Wzmianka o bobie znajduje się w pochodzącej z początku XVII wieku Peregrynacji dziadowskiej – według niej bobo miał bić dzieci i czynić w domu różne szkody. Można go było przebłagać ofiarą z żywności. \n",
      "\n",
      "Relikty tych wierzeń zachowały się jeszcze w XIX wieku (odnotował je m.in. Oskar Kolberg); w Wielkopolsce i Małopolsce straszono dzieci powiedzeniem: „cicho bądź, bo cię bobok weźmie”, albo „jak nie bydzies jád, to cie bebák zjé”. Bohdan Baranowski cytuje dwa utwory ludowe traktujące o bobie; w Puszczy Sandomierskiej znana była kołysanka:\n",
      "\n",
      "zaś w okolicach Olkusza:\n",
      "\n",
      "We współczesnej kulturze do postaci boba nawiązuje zespół Formacja Nieżywych Schabuff w piosence pt. Baboki.\n",
      "\n",
      "Przypisy \n",
      "\n",
      "Demony słowiańskie\n",
      "Potwory\n"
     ]
    }
   ],
   "source": [
    "# Filter the documents\n",
    "filtered = wikipedia.filter(lambda row: \"bebok\" in row[\"text\"])\n",
    "\n",
    "# Create a sample dataset\n",
    "example = filtered.select(range(1))\n",
    "\n",
    "print(example[0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-applications-NUqIfS-d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
