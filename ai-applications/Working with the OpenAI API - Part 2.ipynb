{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with the OpenAI API - Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI's Text and Chat Capabilities\n",
    "OpenAI's GPT series of language models have created headlines the world over. In this chapter, you'll use these models for generating and transforming text content, for classification tasks like categorization and sentiment analysis, and finally, to create your very own AI-powered chatbot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Create the OpenAI client\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find and replace\n",
    "Text completion models can be used for much more than answering questions. In this exercise, you'll explore the model's ability to transform a text prompt.\n",
    "\n",
    "Find-and-replace tools have been around for decades, but they are often limited to identifying and replacing exact words or phrases. You've been provided with a block of text discussing cars, and you'll use a completion model to update the text to discuss planes instead, updating the text appropriately.\n",
    "\n",
    "Warning: if you send many requests or use lots of tokens in a short period, you may hit your rate limit and see an openai.error.RateLimitError. If you see this error, please wait a minute for your quota to reset and you should be able to begin sending more requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A plane is a vehicle that is typically powered by jet engines or propellers. It is designed to carry passengers and/or cargo through the air. Planes have become a ubiquitous part of modern society and are used for a wide variety of purposes, such as commuting, travel, and transportation of goods. Planes are often associated with freedom, independence, and mobility.\n"
     ]
    }
   ],
   "source": [
    "prompt=\"\"\"Replace car with plane and adjust phrase:\n",
    "A car is a vehicle that is typically powered by an internal combustion engine or an electric motor. It has four wheels, and is designed to carry passengers and/or cargo on roads or highways. Cars have become a ubiquitous part of modern society, and are used for a wide variety of purposes, such as commuting, travel, and transportation of goods. Cars are often associated with freedom, independence, and mobility.\"\"\"\n",
    "\n",
    "# Create a request to the Chat Completions endpoint\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[{\"role\": \"user\", \n",
    "             \"content\": prompt}],\n",
    "  max_tokens=100\n",
    ")\n",
    "\n",
    "# Extract and print the response text\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text summarization\n",
    "One really common use case for using OpenAI's models is summarizing text. This has a ton of applications in business settings, including summarizing reports into concise one-pagers or a handful of bullet points, or extracting the next steps and timelines for different stakeholders.\n",
    "\n",
    "In this exercise, you'll summarize a passage of text on financial investment into two concise bullet points using a text completion model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Investment involves committing capital to various options (e.g., stocks, bonds, real estate) with the expectation of generating income or profit, requiring careful analysis of risks and rewards.  \n",
      "- Diversifying investment portfolios can minimize risk, making informed investment decisions crucial for building wealth and achieving financial security.\n"
     ]
    }
   ],
   "source": [
    "prompt=\"\"\"Summarize the following text into two concise bullet points:\n",
    "Investment refers to the act of committing money or capital to an enterprise with the expectation of obtaining an added income or profit in return. There are a variety of investment options available, including stocks, bonds, mutual funds, real estate, precious metals, and currencies. Making an investment decision requires careful analysis, assessment of risk, and evaluation of potential rewards. Good investments have the ability to produce high returns over the long term while minimizing risk. Diversification of investment portfolios reduces risk exposure. Investment can be a valuable tool for building wealth, generating income, and achieving financial security. It is important to be diligent and informed when investing to avoid losses.\"\"\"\n",
    "\n",
    "# Create a request to the Chat Completions endpoint\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[{\"role\": \"user\", \n",
    "             \"content\": prompt}],\n",
    "  max_tokens=400,\n",
    "  temperature=0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content generation\n",
    "AI is playing a much greater role in content generation, from creating marketing content such as blog post titles to creating outreach email templates for sales teams.\n",
    "\n",
    "In this exercise, you'll harness AI through the Chat Completions endpoint to generate a catchy slogan for a new restaurant. Feel free to test out different prompts, such as varying the type of cuisine (e.g., Italian, Chinese) or the type of restaurant (e.g., fine-dining, fast-food), to see how the response changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Indulge in the Essence of Italy: Where Every Bite is a Masterpiece!\"\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Create a catchy slogan for a new Italian fine-dining restaurant.\"\"\"\n",
    "\n",
    "# Create a request to the Chat Completions endpoint\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[{\"role\": \"user\", \n",
    "             \"content\": prompt}],\n",
    "  max_tokens=100\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying text sentiment\n",
    "As well as answering questions, transforming text, and generating new text, OpenAI's models can also be used for classification tasks, such as categorization and sentiment classification. This sort of task requires not only knowledge of the words but also a deeper understanding of their meaning.\n",
    "\n",
    "In this exercise, you'll explore using Chat Completions models for sentiment classification using reviews from an online shoe store called Toe-Tally Comfortable:\n",
    "\n",
    "1. Unbelievably good!\n",
    "2. Shoes fell apart on the second use.\n",
    "3. The shoes look nice, but they aren't very comfortable.\n",
    "4. Can't wait to show them off!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the sentiment classifications for each statement:\n",
      "\n",
      "1. Unbelievably good! - Positive\n",
      "2. Shoes fell apart on the second use. - Negative\n",
      "3. The shoes look nice, but they aren't very comfortable. - Neutral\n",
      "4. Can't wait to show them off! - Positive\n"
     ]
    }
   ],
   "source": [
    "# Define a multi-line prompt to classify sentiment\n",
    "prompt = \"\"\"Classify the sentiment as either negative, positive, or neutral of the following statements:\n",
    "1. Unbelievably good!\n",
    "2. Shoes fell apart on the second use.\n",
    "3. The shoes look nice, but they aren't very comfortable.\n",
    "4. Can't wait to show them off!\n",
    "\"\"\"\n",
    "\n",
    "# Create a request to the Chat Completions endpoint\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[{\"role\": \"user\", \n",
    "             \"content\": prompt}],\n",
    "  max_tokens=100\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorizing companies\n",
    "In this exercise, you'll use a Chat Completions model to categorize different companies. At first, you won't specify the categories to see how the model categorizes them. Then, you'll specify the categories in the prompt to ensure they are categorized in a desirable and predictable way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here’s a categorization of the companies you listed based on their primary industry sectors:\n",
      "\n",
      "### Technology\n",
      "- **Apple**: Consumer Electronics, Software\n",
      "- **Microsoft**: Software, Cloud Computing\n",
      "- **Alphabet**: Internet Services, Technology\n",
      "- **Amazon**: E-commerce, Cloud Computing\n",
      "- **NVIDIA**: Semiconductors, Artificial Intelligence\n",
      "- **Meta**: Social Media, Technology\n",
      "- **Tesla**: Automotive, Energy Solutions\n",
      "\n",
      "### Energy\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "# Define a prompt for the categorization\n",
    "prompt = \"Categorize the following companies: Apple, Microsoft, Saudi Aramco, Alphabet, Amazon, Berkshire Hathaway, NVIDIA, Meta, Tesla, LVMH\"\n",
    "\n",
    "# Create a request to the Chat Completions endpoint\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[{\"role\": \"user\", \n",
    "             \"content\": prompt}],\n",
    "  max_tokens=100,\n",
    "  temperature=0.5\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here’s the categorization of the companies you provided:\n",
      "\n",
      "**Tech:**\n",
      "- Apple\n",
      "- Microsoft\n",
      "- Alphabet\n",
      "- Amazon\n",
      "- NVIDIA\n",
      "- Meta\n",
      "- Tesla\n",
      "\n",
      "**Energy:**\n",
      "- Saudi Aramco\n",
      "\n",
      "**Luxury Goods:**\n",
      "- LVMH\n",
      "\n",
      "**Investment:**\n",
      "- Berkshire Hathaway\n"
     ]
    }
   ],
   "source": [
    "# Define a prompt for the categorization\n",
    "prompt = \"Categorize the following companies into categories Tech, Energy, Luxury Goods, Investment: Apple, Microsoft, Saudi Aramco, Alphabet, Amazon, Berkshire Hathaway, NVIDIA, Meta, Tesla, LVMH\"\n",
    "\n",
    "# Create a request to the Chat Completions endpoint\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[{\"role\": \"user\", \n",
    "             \"content\": prompt}],\n",
    "  max_tokens=100,\n",
    "  temperature=0.5\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat Completions roles\n",
    "The Chat Completions endpoint supports three different roles to shape the messages sent to the model:\n",
    "\n",
    "- System: controls assistant's behavior\n",
    "- User: instruct the assistant\n",
    "- Assistant: response to user instruction\n",
    "\n",
    "In this exercise, you'll make a request to the Chat Completions endpoint, including a system messages, to answer the following question:\n",
    "\n",
    "What is the difference between a for loop and a while loop?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The main differences between a `for` loop and a `while` loop lie in their structure, usage, and the way they control iteration:\n",
      "\n",
      "### For Loop\n",
      "1. **Structure**: A `for` loop often includes initialization, a condition, and an increment/decrement statement in a single line. It's commonly used for iterating over a sequence (like a list or range).\n",
      "   \n",
      "   **Example in Python**:\n",
      "   ```python\n",
      "   for i in range(5):\n",
      "       print(i)\n",
      "   ```\n",
      "   This loop will print the numbers 0 to 4.\n",
      "\n",
      "2. **Use Case**: It's best suited for situations where the number of iterations is known ahead of time or when iterating over elements of a collection. It\n"
     ]
    }
   ],
   "source": [
    "# Create a request to the Chat Completions endpoint\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  max_tokens=150,\n",
    "  messages=[\n",
    "    {\"role\": \"system\",\n",
    "     \"content\": \"You are a helpful data science tutor.\"},\n",
    "    {\"role\": \"user\",\n",
    "     \"content\": \"What is the difference between a for loop and a while loop?\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "# Extract and print the assistant's text response\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code explanation\n",
    "One of the most popular use cases for using OpenAI models is for explaining complex content, such as technical jargon and code. This is a task that data practitioners, software engineers, and many others must tackle in their day-to-day as they review and utilize code written by others.\n",
    "\n",
    "In this exercise, you'll use the OpenAI API to explain a block of Python code to understand what it is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Python code calculates and prints the average height of the individuals listed in the `heights_dict` dictionary using NumPy's `mean` function.\n"
     ]
    }
   ],
   "source": [
    "instruction = \"\"\"Explain what this Python code does in one sentence:\n",
    "import numpy as np\n",
    "\n",
    "heights_dict = {\"Mark\": 1.76, \"Steve\": 1.88, \"Adnan\": 1.73}\n",
    "heights = heights_dict.values()\n",
    "print(np.mean(heights))\n",
    "\"\"\"\n",
    "\n",
    "# Create a request to the Chat Completions endpoint\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\"role\": \"user\",\n",
    "     \"content\": instruction}\n",
    "  ],\n",
    "  max_tokens=100\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-context learning\n",
    "For more complex use cases, the models lack the understanding or context of the problem to provide a suitable response from a prompt. In these cases, you need to provide examples to the model for it to learn from, so-called in-context learning.\n",
    "\n",
    "In this exercise, you'll improve on a Python programming tutor built on the OpenAI API by providing an example that the model can learn from.\n",
    "\n",
    "Here is an example of a user and assistant message you can use, but feel free to try out your own:\n",
    "\n",
    "- User → Explain what the min() Python function does.\n",
    "- Assistant → The min() function returns the smallest item from an iterable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The `type()` function in Python is used to determine the type of an object. When you pass an object to `type()`, it returns the type of that object. This can be helpful for debugging or for making decisions based on the type of data you are working with.\n",
      "\n",
      "### Syntax\n",
      "```python\n",
      "type(object)\n",
      "```\n",
      "\n",
      "### Parameters\n",
      "- **object**: The object whose type you want to determine.\n",
      "\n",
      "### Return Value\n",
      "- `type()` returns a type object that represents the type of the given object.\n",
      "\n",
      "### Examples\n",
      "1. Basic usage:\n",
      "   ```python\n",
      "   print(type(42))               # Output: <class 'int'>\n",
      "   print(type(3.14))             # Output: <class 'float'>\n",
      "   print(type(\"Hello, World!\"))  # Output: <class 'str'>\n",
      "   print(type([1, 2, 3]))        # Output: <class 'list'>\n",
      "   print(type((1, 2, 3)))        # Output: <class 'tuple'>\n",
      "   print(type({}))               # Output: <class 'dict'>\n",
      "   ```\n",
      "\n",
      "2. Checking types:\n",
      "   ```python\n",
      "   x = [1, 2, 3]\n",
      "   if type(x) is list:\n",
      "       print(\"x is a list\")\n",
      "   ```\n",
      "\n",
      "3. Finding the type of a user-defined class:\n",
      "   ```python\n",
      "   class MyClass:\n",
      "       pass\n",
      "\n",
      "   obj = MyClass()\n",
      "   print(type(obj))  # Output: <class '__main__.MyClass'>\n",
      "   ```\n",
      "\n",
      "### Note\n",
      "To check whether an object is of a specific type more flexibly, you can also use `isinstance()` function, which allows checking against different types, including subclasses. \n",
      "\n",
      "In summary, `type()` is a built-in function in Python that helps you identify the type of an object, which can be useful for type checking and debugging.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "   model=\"gpt-4o-mini\",\n",
    "   # Add a user and assistant message for in-context learning\n",
    "   messages=[\n",
    "     {\"role\": \"system\", \"content\": \"You are a helpful Python programming tutor.\"},\n",
    "     {\"role\": \"user\", \"content\": \"Explain what the min() Python function does.\"},\n",
    "     {\"role\": \"assistant\", \"content\": \"The min() function returns the smallest item from an iterable.\"},\n",
    "     {\"role\": \"user\", \"content\": \"Explain what the type() function does.\"}\n",
    "   ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an AI chatbot\n",
    "An online learning platform called Easy as Pi that specializes in teaching math skills has contracted you to help develop an AI tutor. You immediately see that you can build this feature on top of the OpenAI API, and start to design a simple proof-of-concept (POC) for the major stakeholders at the company. This POC will demonstrate the core functionality required to build the final feature and the power of the OpenAI's GPT models.\n",
    "\n",
    "Example system and user messages have been provided for you, but feel free to play around with these to change the model's behavior or design a completely different chatbot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  Explain what pi is.\n",
      "Assistant:  Pi, denoted by the symbol \\( \\pi \\), is a mathematical constant that represents the ratio of the circumference of a circle to its diameter. This ratio is the same for all circles, regardless of their size. Mathematically, this can be expressed as:\n",
      "\n",
      "\\[\n",
      "\\pi = \\frac{\\text{Circumference}}{\\text{Diameter}}\n",
      "\\]\n",
      "\n",
      "The value of \\( \\pi \\) is approximately 3.14159, but it is an irrational number, meaning it \n",
      "\n",
      "User:  Summarize this in two bullet points.\n",
      "Assistant:  - Pi (\\( \\pi \\)) is the ratio of the circumference of a circle to its diameter, constant for all circles.\n",
      "- Its approximate value is 3.14159, and it is an irrational number, meaning it cannot be expressed as a simple fraction. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": \"You are a helpful math tutor.\"}]\n",
    "user_msgs = [\"Explain what pi is.\", \"Summarize this in two bullet points.\"]\n",
    "\n",
    "for q in user_msgs:\n",
    "    print(\"User: \", q)\n",
    "    \n",
    "    # Create a dictionary for the user message from q and append to messages\n",
    "    user_dict = {\"role\": \"user\", \"content\": q}\n",
    "    messages.append(user_dict)\n",
    "    \n",
    "    # Create the API request\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        max_tokens=100\n",
    "    )\n",
    "    \n",
    "    # Convert the assistant's message to a dict and append to messages\n",
    "    assistant_dict = {\"role\": \"assistant\", \"content\": response.choices[0].message.content}\n",
    "    messages.append(assistant_dict)\n",
    "    print(\"Assistant: \", response.choices[0].message.content, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
