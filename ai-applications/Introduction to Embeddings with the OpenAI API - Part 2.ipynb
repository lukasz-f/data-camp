{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Embeddings with the OpenAI API - Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings for AI Applications\n",
    "\n",
    "Embeddings enable powerful AI applications, including semantic search engines, recommendation engines, and classification tasks like sentiment analysis. Learn how to use OpenAI's embeddings model to enable these exciting applications!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai_api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enriching embeddings\n",
    "Previously, when you embedded product information, you were limited to only embedding the product 'short_description', which captured some, but not all of the relevant product information available. In this exercise, you'll embed 'title', 'short_description', 'category', and 'features' to capture much more information.\n",
    "\n",
    "Here's a reminder of the products list of dictionaries:\n",
    "```\n",
    "products = [\n",
    "    {\n",
    "        \"title\": \"Smartphone X1\",\n",
    "        \"short_description\": \"The latest flagship smartphone with AI-powered features and 5G connectivity.\",\n",
    "        \"price\": 799.99,\n",
    "        \"category\": \"Electronics\",\n",
    "        \"features\": [\n",
    "            \"6.5-inch AMOLED display\",\n",
    "            \"Quad-camera system with 48MP main sensor\",\n",
    "            \"Face recognition and fingerprint sensor\",\n",
    "            \"Fast wireless charging\"\n",
    "        ]\n",
    "    },\n",
    "    ...\n",
    "]\n",
    "```\n",
    "When combining the features into a single string, it should have the following structure:\n",
    "```\n",
    "Title: <product title>\n",
    "Description: <product description>\n",
    "Category: <product category>\n",
    "Features: <feature 1>; <feature 2>; <feature 3>; ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "# Define a function to combine the relevant features into a single string\n",
    "def create_product_text(product):\n",
    "  return f\"\"\"Title: {product['title']}\n",
    "Description: {product['short_description']}\n",
    "Category: {product['category']}\n",
    "Features: {', '.join(product['features'])}\"\"\"\n",
    "\n",
    "def create_embeddings(texts):\n",
    "  response = client.embeddings.create(model=\"text-embedding-3-small\",\n",
    "                                      input=texts)\n",
    "  response_dict = response.model_dump()\n",
    "\n",
    "  return [data['embedding'] for data in response_dict['data']]\n",
    "\n",
    "\n",
    "client = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "with open('resources/products.json', 'r') as f:\n",
    "    products = json.load(f)\n",
    "\n",
    "# Combine the features for each product\n",
    "product_texts = [create_product_text(product) for product in products]\n",
    "\n",
    "# Create the embeddings from product_texts\n",
    "product_embeddings = create_embeddings(product_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting by similarity\n",
    "Now that you've embedded all of your features, the next step is to compute the similarities. In this exercise, you'll define a function called find_n_closest(), which computes the cosine distances between a query vector and a list of embeddings and returns the n smallest distances and their indexes.\n",
    "\n",
    "In the next exercise, you'll use this function to enable your semantic product search application.\n",
    "\n",
    "distance has been imported from scipy.spatial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "\n",
    "def find_n_closest(query_vector, embeddings, n=3):\n",
    "  distances = []\n",
    "  for index, embedding in enumerate(embeddings):\n",
    "    # Calculate the cosine distance between the query vector and embedding\n",
    "    dist = distance.cosine(query_vector, embedding)\n",
    "    # Append the distance and index to distances\n",
    "    distances.append({\"distance\": dist, \"index\": index})\n",
    "  # Sort distances by the distance key\n",
    "  distances_sorted = sorted(distances, key=lambda x: x[\"distance\"])\n",
    "  # Return the first n elements in distances_sorted\n",
    "  return distances_sorted[0:n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic search for products\n",
    "Time to put your find_n_closest() function to use! You'll test out your semantic product search on a test query, computing a sorted list of the five most semantically similar products, based on the enriched data you gave the model.\n",
    "\n",
    "Here's a reminder of the find_n_closest() function you created in the previous exercise:\n",
    "```\n",
    "def find_n_closest(query_vector, embeddings, n=3):\n",
    "    distances = []\n",
    "    for index, embedding in enumerate(embeddings):\n",
    "        distance = spatial.distance.cosine(query_vector, embedding)\n",
    "        distances.append({\"distance\": distance, \"index\": index})\n",
    "    distances_sorted = sorted(distances, key=lambda x: x[\"distance\"])\n",
    "    return distances_sorted[0:n]\n",
    "```\n",
    "The create_embeddings() function you created earlier is also available. Recall that it takes some text, and returns a list of lists containing the embeddings for each text. The products dictionary and the product_embeddings you created previously have also been loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search results for \"computer\"\n",
      "High-Performance Gaming Laptop\n",
      "Robot Building Kit\n",
      "Smartphone X1\n",
      "Smart Thermostat\n",
      "Interactive Robot Pet\n"
     ]
    }
   ],
   "source": [
    "# Create the query vector from query_text\n",
    "query_text = \"computer\"\n",
    "query_vector = create_embeddings(query_text)[0]\n",
    "\n",
    "# Find the five closest distances\n",
    "hits = find_n_closest(query_vector, product_embeddings, n=5)\n",
    "\n",
    "print(f'Search results for \"{query_text}\"')\n",
    "for hit in hits:\n",
    "  # Extract the product at each index in hits\n",
    "  product = products[hit[\"index\"]]\n",
    "  print(product[\"title\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Product recommendation system\n",
    "In this exercise, you'll make a recommendation system for an online retailer that sells a variety of products. This system recommends three similar products to users who visit a product page but don't purchase, based on the last product they visited.\n",
    "\n",
    "You've been provided with a list of dictionaries of products available on the site,\n",
    "```\n",
    "products = [\n",
    "    {\n",
    "        \"title\": \"Smartphone X1\",\n",
    "        \"short_description\": \"The latest flagship smartphone with AI-powered features and 5G connectivity.\",\n",
    "        \"price\": 799.99,\n",
    "        \"category\": \"Electronics\",\n",
    "        \"features\": [\n",
    "            \"6.5-inch AMOLED display\",\n",
    "            ...\n",
    "            \"Fast wireless charging\"\n",
    "        ]\n",
    "    },\n",
    "    ...\n",
    "]\n",
    "```\n",
    "and a dictionary for the last product the user visited, stored in last_product.\n",
    "\n",
    "The following custom functions defined earlier in the course are also available for you to use:\n",
    "\n",
    "- create_embeddings(texts) → returns a list of embeddings for each text in texts.\n",
    "- create_product_text(product) → combines the product features into a single string for embedding.\n",
    "- find_n_closest(query_vector, embeddings, n=3) → returns the n closest distances and their indexes between the query_vector and embeddings, based on cosine distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robot Building Kit\n",
      "LEGO Space Shuttle\n",
      "Designer Makeup Brush Set\n"
     ]
    }
   ],
   "source": [
    "last_product = {\n",
    "    'title': 'Building Blocks Deluxe Set',\n",
    "    'short_description': 'Unleash your creativity with this deluxe set of building blocks for endless fun.',\n",
    "    'price': 34.99,\n",
    "    'category': 'Toys',\n",
    "    'features': ['Includes 500+ colorful building blocks',\n",
    "                 'Promotes STEM learning and creativity',\n",
    "                 'Compatible with other major brick brands',\n",
    "                 'Comes with a durable storage container',\n",
    "                 'Ideal for children ages 3 and up']\n",
    "}\n",
    "\n",
    "# Combine the features for last_product and each product in products\n",
    "last_product_text = create_product_text(last_product)\n",
    "product_texts = [create_product_text(product) for product in products]\n",
    "\n",
    "# Embed last_product_text and product_texts\n",
    "last_product_embeddings = create_embeddings(last_product_text)[0]\n",
    "product_embeddings = create_embeddings(product_texts)\n",
    "\n",
    "# Find the three smallest cosine distances and their indexes\n",
    "hits = find_n_closest(last_product_embeddings, product_embeddings)\n",
    "\n",
    "for hit in hits:\n",
    "  product = products[hit['index']]\n",
    "  print(product['title'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding user history to the recommendation engine\n",
    "For many recommendation cases, such as film or purchase recommendation, basing the next recommendation on one data point will be insufficient. In these cases, you'll need to embed all or some of the user's history for more accurate and relevant recommendations.\n",
    "\n",
    "In this exercise, you'll extend your product recommendation system to consider all of the products the user has previously visited, which are stored in a list of dictionaries called user_history.\n",
    "\n",
    "The following custom functions are available for you to use: create_embeddings(texts), create_product_text(product), and find_n_closest(query_vector, embeddings, n=3). numpy has also been imported as np."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robot Building Kit\n",
      "Interactive Robot Pet\n",
      "LEGO Space Shuttle\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "user_history = [\n",
    "    {\n",
    "        'title': 'Remote-Controlled Dinosaur Toy',\n",
    "        'short_description': 'Roar into action with this remote-controlled dinosaur toy with lifelike movements.',\n",
    "        'price': 49.99,\n",
    "        'category': 'Toys',\n",
    "        'features': ['Realistic dinosaur sound effects',\n",
    "                     'Walks and roars like a real dinosaur',\n",
    "                     'Remote control included',\n",
    "                     'Educational and entertaining']\n",
    "    },\n",
    "    {\n",
    "        'title': 'Building Blocks Deluxe Set',\n",
    "        'short_description': 'Unleash your creativity with this deluxe set of building blocks for endless fun.',\n",
    "        'price': 34.99,\n",
    "        'category': 'Toys',\n",
    "        'features': ['Includes 500+ colorful building blocks',\n",
    "                     'Promotes STEM learning and creativity',\n",
    "                     'Compatible with other major brick brands',\n",
    "                     'Comes with a durable storage container',\n",
    "                     'Ideal for children ages 3 and up']\n",
    "    }\n",
    "]\n",
    "\n",
    "# Prepare and embed the user_history, and calculate the mean embeddings\n",
    "history_texts = [create_product_text(product) for product in user_history]\n",
    "history_embeddings = create_embeddings(history_texts)\n",
    "mean_history_embeddings = np.mean(history_embeddings, axis=0)\n",
    "\n",
    "# Filter products to remove any in user_history\n",
    "products_filtered = [product for product in products if product not in user_history]\n",
    "\n",
    "# Combine product features and embed the resulting texts\n",
    "product_texts = [create_product_text(product) for product in products_filtered]\n",
    "product_embeddings = create_embeddings(product_texts)\n",
    "\n",
    "hits = find_n_closest(mean_history_embeddings, product_embeddings)\n",
    "\n",
    "for hit in hits:\n",
    "  product = products_filtered[hit['index']]\n",
    "  print(product['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding restaurant reviews\n",
    "One common classification task that embeddings are great for is sentiment analysis. In this and the following exercises, you'll navigate through the workflow of performing sentiment analysis using embeddings.\n",
    "\n",
    "You've been provided with a small sample of restaurant reviews, stored in reviews, and sentiment labels stored in sentiments:\n",
    "```\n",
    "sentiments = [{'label': 'Positive'},\n",
    "              {'label': 'Neutral'},\n",
    "              {'label': 'Negative'}]\n",
    "\n",
    "reviews = [\"The food was delicious!\",\n",
    "           \"The service was a bit slow but the food was good\",\n",
    "           \"The food was cold, really disappointing!\"]\n",
    "```\n",
    "You'll use zero-shot classification to classify the sentiment of these reviews by embedding the reviews and class labels.\n",
    "\n",
    "The create_embeddings() function you created previously is also available to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments = [{'label': 'Positive'},\n",
    "              {'label': 'Neutral'},\n",
    "              {'label': 'Negative'}]\n",
    "\n",
    "reviews = [\"The food was delicious!\",\n",
    "           \"The service was a bit slow but the food was good\",\n",
    "           \"The food was cold, really disappointing!\"]\n",
    "\n",
    "# Create a list of class descriptions from the sentiment labels\n",
    "class_descriptions = [sentiment['label'] for sentiment in sentiments]\n",
    "\n",
    "# Embed the class_descriptions and reviews\n",
    "class_embeddings = create_embeddings(class_descriptions)\n",
    "review_embeddings = create_embeddings(reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying review sentiment\n",
    "Now that you've calculated the embeddings, it's time to compute the cosine distances and extract the most similar label.\n",
    "\n",
    "You'll do this by defining a function called find_closest(), which can be used to compare the embeddings between one vector and multiple others, and return the nearest distance and its index. You'll then loop over the reviews and and use find_closest() to find the closest distance for each review, extracting the classified label using the index.\n",
    "\n",
    "The class_embeddings and review_embeddings objects you created in the last exercise are available for you to use, as well as the reviews and sentiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"The food was delicious!\" was classified as Positive\n",
      "\"The service was a bit slow but the food was good\" was classified as Negative\n",
      "\"The food was cold, really disappointing!\" was classified as Negative\n"
     ]
    }
   ],
   "source": [
    "# Define a function to return the minimum distance and its index\n",
    "def find_closest(query_vector, embeddings):\n",
    "  distances = []\n",
    "  for index, embedding in enumerate(embeddings):\n",
    "    dist = distance.cosine(query_vector, embedding)\n",
    "    distances.append({\"distance\": dist, \"index\": index})\n",
    "  return min(distances, key=lambda x: x[\"distance\"])\n",
    "\n",
    "\n",
    "for index, review in enumerate(reviews):\n",
    "  # Find the closest distance and its index using find_closest()\n",
    "  closest = find_closest(review_embeddings[index], class_embeddings)\n",
    "  # Subset sentiments using the index from closest\n",
    "  label = sentiments[closest['index']]['label']\n",
    "  print(f'\"{review}\" was classified as {label}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding more detailed descriptions\n",
    "One of the last predicted labels didn't seem representative of the review; this was probably down to the lack of information being captured when we're only embedding the class labels. This time, descriptions of each class will be embedded instead, so the model better \"understands\" that you're classifying restaurant reviews.\n",
    "\n",
    "The following objects are available for you to use:\n",
    "```\n",
    "sentiments = [{'label': 'Positive',\n",
    "               'description': 'A positive restaurant review'},\n",
    "              {'label': 'Neutral',\n",
    "               'description':'A neutral restaurant review'},\n",
    "              {'label': 'Negative',\n",
    "               'description': 'A negative restaurant review'}]\n",
    "\n",
    "reviews = [\"The food was delicious!\",\n",
    "           \"The service was a bit slow but the food was good\",\n",
    "           \"The food was cold, really disappointing!\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"The food was delicious!\" was classified as Positive\n",
      "\"The service was a bit slow but the food was good\" was classified as Neutral\n",
      "\"The food was cold, really disappointing!\" was classified as Negative\n"
     ]
    }
   ],
   "source": [
    "sentiments = [{'label': 'Positive',\n",
    "               'description': 'A positive restaurant review'},\n",
    "              {'label': 'Neutral',\n",
    "               'description':'A neutral restaurant review'},\n",
    "              {'label': 'Negative',\n",
    "               'description': 'A negative restaurant review'}]\n",
    "\n",
    "reviews = [\"The food was delicious!\",\n",
    "           \"The service was a bit slow but the food was good\",\n",
    "           \"The food was cold, really disappointing!\"]\n",
    "\n",
    "# Extract and embed the descriptions from sentiments\n",
    "class_descriptions = [sentiment['description'] for sentiment in sentiments]\n",
    "class_embeddings = create_embeddings(class_descriptions)\n",
    "review_embeddings = create_embeddings(reviews)\n",
    "\n",
    "def find_closest(query_vector, embeddings):\n",
    "  distances = []\n",
    "  for index, embedding in enumerate(embeddings):\n",
    "    dist = distance.cosine(query_vector, embedding)\n",
    "    distances.append({\"distance\": dist, \"index\": index})\n",
    "  return min(distances, key=lambda x: x[\"distance\"])\n",
    "\n",
    "for index, review in enumerate(reviews):\n",
    "  closest = find_closest(review_embeddings[index], class_embeddings)\n",
    "  label = sentiments[closest['index']]['label']\n",
    "  print(f'\"{review}\" was classified as {label}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
