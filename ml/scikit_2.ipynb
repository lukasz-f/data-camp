{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit learn\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Przeszukiwanie przestrzeni parametrów\n",
    "\n",
    "Metody, z których korzystamy, można w jakimś stopniu poprawić, szukając optymalnej kombinacji parametrów.\n",
    "\n",
    "Przykładem implementacji takiego przeszukiwania jest GridSearchCV.\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "\n",
    "Poniżej pełny przykład wykorzystania (UWAGA! może być bardzo czasochłonny obliczeniowo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  88 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=2)]: Done 388 tasks      | elapsed:   34.4s\n",
      "[Parallel(n_jobs=2)]: Done 864 out of 864 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wyniki najlepszego modelu: 0.941\n",
      "clf__C 1\n",
      "clf__class_weight balanced\n",
      "sel__percentile 30\n",
      "vect__max_df 0.25\n",
      "vect__ngram_range (1, 1)\n",
      "vect__use_idf True\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative      0.957     0.960     0.958      2163\n",
      "   positive      0.766     0.754     0.760       378\n",
      "\n",
      "avg / total      0.929     0.929     0.929      2541\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "df = pd.read_csv('Tweets.csv')\n",
    "df = df[df['airline_sentiment'] != 'neutral']\n",
    "\n",
    "len(df)\n",
    "X = df['text']\n",
    "y = df['airline_sentiment']\n",
    "\n",
    "X_train = X[:7000]\n",
    "X_validate = X[7000:9000]\n",
    "X_test = X[9000:]\n",
    "\n",
    "\n",
    "y_train = y[:7000]\n",
    "y_validate = y[7000:9000]\n",
    "y_test = y[9000:]\n",
    "\n",
    "pipeline = Pipeline([\n",
    "       ('vect', TfidfVectorizer(stop_words='english')),\n",
    "       ('sel', SelectPercentile()),\n",
    "       ('clf', LinearSVC())\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "   'vect__max_df': (0.25, 0.5),\n",
    "   'vect__ngram_range': ((1, 1), (1, 2), (1,3)),\n",
    "   'vect__use_idf': (True, False),\n",
    "   'sel__percentile': (10,30,50,100),\n",
    "   'clf__C': (0.01, 1, 10),\n",
    "   'clf__class_weight': ('balanced',None),\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=2, verbose=1, \n",
    "                           scoring='accuracy')\n",
    "\n",
    "\n",
    "grid_search.fit(X_validate, y_validate)\n",
    "print('Wyniki najlepszego modelu: %0.3f' % grid_search.best_score_)\n",
    "\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(param_name, best_parameters[param_name])\n",
    "    \n",
    "pipeline.set_params(**best_parameters)\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Można też przetestować konkretną kombinację parametrów podając ją jako argument do pipeline. Robimy to tak:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('cleantxt', TextCleaner()),\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    # ('clf', DecisionTreeClassifier()),#Score:0.12345\n",
    "    ('clf', ExtraTreesClassifier(n_jobs=-1, n_estimators=50)),  # Score:0.2345\n",
    "    # ('dense', DenseTransformer()),\n",
    "    # ('clf', GaussianNB())#Score:0.62\n",
    "])\n",
    "\n",
    "pipe_params = {\n",
    "    'clf__class_weight': 'balanced'\n",
    "    , 'clf__random_state': 42\n",
    "    , 'tfidf__norm': 'l2'\n",
    "    , 'tfidf__use_idf': True\n",
    "    , 'vect__max_df': .7\n",
    "    , 'vect__max_features': 10000\n",
    "    , 'vect__ngram_range': (1, 2)\n",
    "    , 'vect__strip_accents': 'unicode'\n",
    "    , 'vect__stop_words': stops\n",
    "}\n",
    "\n",
    "pipeline.set_params(**pipe_params)\n",
    "\n",
    "# przepisac parametry pipe_params z wynikow GridSearchCV\n",
    "\n",
    "pipeline.fit(X_train, Y_train)  # dzialamy na 70% danych zeby wytrenowac ostateczny model\n",
    "\n",
    "Y_predicted = pipeline.predict(X_test) # przewidujemy etykiety na 10% zbiorze testowym\n",
    "\n",
    "# TODO policzyc jakosc tego modelu (patrz scikit_1)\n",
    "\n",
    "# nieliniowy SVM:\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.svm.NuSVC.html\n",
    "import sklearn.svm.NuSVC\n",
    "clf = NuSVC(nu=0.5, kernel='rbf', class_weight='balanced')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zadania\n",
    "\n",
    "1) oprócz train i test, wprowadź jeszcze validate - (jako train - 70%, validate - 20%, test - 10%). Zmodyfikuj powyższy kod, aby dane do  GridSearchCV pochodziły z podziału X_validate i Y_validate.\n",
    "Uruchom grid search i najlepszą kombinację parametrów przetestuj na Y_test, trenując tym razem model na 80% zbiorze X_train.\n",
    "\n",
    "2) Wypróbuj klasyfikatory: RandomForest, LogisticRegression, SVM\n",
    "\n",
    "3) Spróbuj dodać do pipeline normalizację danych, przetestuj wyniki\n",
    "\n",
    "4) Oceń wybrany klasyfikator z najlepszą kombinacją parametrów używając metody 10-krotnej walidacji krzyżowej. Policz średnią precyzję, recall i F1 dla foldów. Jak różnią się otrzymane wyniki od uzyskanych poprzednio?\n",
    "http://scikit-learn.org/stable/modules/cross_validation.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}