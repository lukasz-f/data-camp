{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Źródła:\n",
    "\n",
    "https://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/\n",
    "\n",
    "https://github.com/kjw0612/awesome-rnn\n",
    "\n",
    "https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/\n",
    "\n",
    "https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/\n",
    "\n",
    "http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-2-implementing-a-language-model-rnn-with-python-numpy-and-theano/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Wprowadzenie - prezentacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import itertools\n",
    "import nltk\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocabulary_size = 75\n",
    "\n",
    "with open(\"Dane/kod.txt\") as f:\n",
    "    sentences = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = [s for s in sentences if s.strip() != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenized_sentences = [list(sent) for sent in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenized_sentences[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = np.unique([item for sublist in tokenized_sentences for item in sublist]) \n",
    "index_to_word = [x[0] for x in vocab]\n",
    "\n",
    "word_to_index = dict([(w,i) for i,w in enumerate(index_to_word)])\n",
    " \n",
    "print( \"Using vocabulary size %d.\" % len(vocab))\n",
    "\n",
    "# Create the training data\n",
    "X_train = np.asarray([[word_to_index[w] for w in sent[:-1]] for sent in tokenized_sentences])\n",
    "y_train = np.asarray([[word_to_index[w] for w in sent[1:]] for sent in tokenized_sentences])\n",
    "\n",
    "\n",
    "print( \"\\nExample sentence: '%s'\" % sentences[0])\n",
    "print( \"\\nExample sentence after Pre-processing: '%s'\" % tokenized_sentences[0])\n",
    "print( X_train[0])\n",
    "print( y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RNNNumpy:\n",
    "     \n",
    "    def __init__(self, word_dim, hidden_dim=100, bptt_truncate=4):\n",
    "        # Assign instance variables\n",
    "        self.word_dim = word_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.bptt_truncate = bptt_truncate\n",
    "        # Randomly initialize the network parameters\n",
    "        self.U = np.random.uniform(-np.sqrt(1./word_dim), np.sqrt(1./word_dim), (hidden_dim, word_dim))\n",
    "        self.V = np.random.uniform(-np.sqrt(1./hidden_dim), np.sqrt(1./hidden_dim), (word_dim, hidden_dim))\n",
    "        self.W = np.random.uniform(-np.sqrt(1./hidden_dim), np.sqrt(1./hidden_dim), (hidden_dim, hidden_dim))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_propagation(self, x):\n",
    "    # The total number of time steps\n",
    "    T = len(x)\n",
    "    # During forward propagation we save all hidden states in s because need them later.\n",
    "    # We add one additional element for the initial hidden, which we set to 0\n",
    "    h = np.zeros((T + 1, self.hidden_dim))\n",
    "    h[-1] = np.zeros(self.hidden_dim)\n",
    "    # The outputs at each time step. Again, we save them for later.\n",
    "    o = np.zeros((T, self.word_dim))\n",
    "    # For each time step...\n",
    "    for t in np.arange(T):\n",
    "        # Note that we are indxing U by x[t]. This is the same as multiplying U with a one-hot vector.\n",
    "         \n",
    "        x_t =  np.eye(len(vocab))[x[t]] #Kodowanie one-hot\n",
    "        \n",
    "        h[t] = np.tanh(np.dot(self.U, x_t) + np.dot(self.W, h[t-1]))\n",
    "        o[t] = softmax(np.dot(self.V, h[t])) \n",
    "        \n",
    "        # PODKRESLIC ZE W ZALEZNOSCI OD PROBLEMU CHCEMY MIEC OUTPUTY DLA KAZDEGO X LUB TYLKO NA KONCU\n",
    "    \n",
    "    return [o, h]\n",
    " \n",
    "RNNNumpy.forward_propagation = forward_propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(self, x):\n",
    "    # Perform forward propagation and return index of the highest score\n",
    "    o, s = self.forward_propagation(x)\n",
    "    return np.argmax(o, axis=1)\n",
    " \n",
    "RNNNumpy.predict = predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test:\n",
    "\n",
    "np.random.seed(10)\n",
    "model = RNNNumpy(vocabulary_size)\n",
    "o, s = model.forward_propagation(X_train[10])\n",
    "print(o.shape)\n",
    "print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(X_train[10])\n",
    "print(predictions.shape)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_total_loss(self, x, y):\n",
    "    L = 0\n",
    "    # For each sentence...\n",
    "    for i in np.arange(len(y)):\n",
    "        o, s = self.forward_propagation(x[i])\n",
    "        # We only care about our prediction of the \"correct\" words\n",
    "        correct_word_predictions = o[np.arange(len(y[i])), y[i]]\n",
    "        # Add to the loss based on how off we were\n",
    "        L += -1 * np.sum(np.log(correct_word_predictions))\n",
    "    return L\n",
    " \n",
    "def calculate_loss(self, x, y):\n",
    "    # Divide the total loss by the number of training examples\n",
    "    N = np.sum((len(y_i) for y_i in y))\n",
    "    return self.calculate_total_loss(x,y)/N\n",
    "\n",
    "RNNNumpy.calculate_total_loss = calculate_total_loss\n",
    "RNNNumpy.calculate_loss = calculate_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Limit to 1000 examples to save time\n",
    "print(\"Loss for random predictions: %f\" % np.log(vocabulary_size))\n",
    "print(\"Actual loss: %f\" % model.calculate_loss(X_train[:1000], y_train[:1000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bptt(self, x, y):\n",
    "    T = len(y)\n",
    "    # Perform forward propagation\n",
    "    o, s = self.forward_propagation(x)\n",
    "    \n",
    "    # We accumulate the gradients in these variables\n",
    "    dLdU = np.zeros(self.U.shape)\n",
    "    dLdV = np.zeros(self.V.shape)\n",
    "    dLdW = np.zeros(self.W.shape)\n",
    "    delta_o = o\n",
    "    delta_o[np.arange(len(y)), y] -= 1.\n",
    "    \n",
    "    # For each output backwards...\n",
    "    for t in np.arange(T)[::-1]:\n",
    "        dLdV += np.outer(delta_o[t], s[t].T)\n",
    "        # Initial delta calculation\n",
    "        delta_t = self.V.T.dot(delta_o[t]) * (1 - (s[t] ** 2))\n",
    "        # Backpropagation through time (for at most self.bptt_truncate steps)\n",
    "        for bptt_step in np.arange(max(0, t-self.bptt_truncate), t+1)[::-1]:\n",
    "            # print \"Backpropagation step t=%d bptt step=%d \" % (t, bptt_step)\n",
    "            dLdW += np.outer(delta_t, s[bptt_step-1])              \n",
    "            dLdU[:,x[bptt_step]] += delta_t\n",
    "            # Update delta for next step\n",
    "            delta_t = self.W.T.dot(delta_t) * (1 - s[bptt_step-1] ** 2)\n",
    "    return [dLdU, dLdV, dLdW]\n",
    " \n",
    "RNNNumpy.bptt = bptt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "\n",
    "# Performs one step of SGD.\n",
    "def numpy_sdg_step(self, x, y, learning_rate):\n",
    "    # Calculate the gradients\n",
    "    dLdU, dLdV, dLdW = self.bptt(x, y)\n",
    "    # Change parameters according to gradients and learning rate\n",
    "    self.U -= learning_rate * dLdU\n",
    "    self.V -= learning_rate * dLdV\n",
    "    self.W -= learning_rate * dLdW\n",
    " \n",
    "RNNNumpy.sgd_step = numpy_sdg_step\n",
    "# Outer SGD Loop\n",
    "# - model: The RNN model instance\n",
    "# - X_train: The training data set\n",
    "# - y_train: The training data labels\n",
    "# - learning_rate: Initial learning rate for SGD\n",
    "# - nepoch: Number of times to iterate through the complete dataset\n",
    "# - evaluate_loss_after: Evaluate the loss after this many epochs\n",
    "def train_with_sgd(self, X_train, y_train, learning_rate=0.005, nepoch=100, evaluate_loss_after=5):\n",
    "    # We keep track of the losses so we can plot them later\n",
    "    losses = []\n",
    "    num_examples_seen = 0\n",
    "    for epoch in range(nepoch):\n",
    "        # Optionally evaluate the loss\n",
    "        if (epoch % evaluate_loss_after == 0):\n",
    "            loss = model.calculate_loss(X_train, y_train)\n",
    "            losses.append((num_examples_seen, loss))\n",
    "            \n",
    "            # Adjust the learning rate if loss increases\n",
    "            if (len(losses) > 1 and losses[-1][1] > losses[-2][1]):\n",
    "                learning_rate = learning_rate * 0.5 \n",
    "                print(\"Setting learning rate to %f\" % learning_rate)\n",
    "            sys.stdout.flush()\n",
    "        # For each training example...\n",
    "        for i in range(len(y_train)):\n",
    "            # One SGD step\n",
    "            self.sgd_step(X_train[i], y_train[i], learning_rate)\n",
    "            num_examples_seen += 1\n",
    "    return(losses)\n",
    "\n",
    "RNNNumpy.train_with_sgd = train_with_sgd\n",
    "            \n",
    "np.random.seed(10)\n",
    "model = RNNNumpy(vocabulary_size)\n",
    "%timeit model.sgd_step(X_train[10], y_train[10], 0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "# Train on a small subset of the data to see what happens\n",
    "model = RNNNumpy(vocabulary_size)\n",
    "losses = model.train_with_sgd(X_train, y_train, nepoch=100, evaluate_loss_after=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_text(s,n=3):\n",
    "    \n",
    "    s = list(s)\n",
    "    \n",
    "    X_new = np.asarray([[word_to_index[w] for w in sent] for sent in s])[:,0]\n",
    "    \n",
    "    pred = np.zeros(n,dtype=\"int\")\n",
    "    for i in range(n):\n",
    "        pred[i] = model.predict(np.concatenate([X_new, pred[:i]]))[-1]\n",
    "    print(\"original: \", ''.join([x[0] for x in s]) )\n",
    "    print(\"prediction: \", ''.join([x[0] for x in s])+''.join([[index_to_word[w] for w in sent] for sent in [pred]][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generate_text(\"clas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generate_text(\"in n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generate_text(\"for i in n\",20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytanie, czy sieć tylko potrafi odtworzyć to co było w danych, czy nauczyła sie zależności?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generate_text(\"for z in\",20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generate_text(\"for x in n\",10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generate_text(\"se\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generate_text(\"ri\",10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generate_text(\"pri\",4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generate_text(\"np.ar\",10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generate_text(\"train\",50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generate_text(\".calculate\",50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generate_text(\" calculate\",50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case study: IMBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, SimpleRNN, LSTM, Bidirectional\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_features = 5000\n",
    "maxlen = 400\n",
    "batch_size = 32\n",
    "embedding_dims = 50\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "print(x_train[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zwróćmy uwagę w powyższym, że ciągi zaczynają się zawsze od \"1\" - jest to oznaczenie początku zdania. Czyli \"początek zdania\" będzie mial swój embedding. Dzięki temu sieć lepiej nauczy się uwzględniać, podczas \"analizy\" pierwszego słow fakt, że to słowo jest pierwsze.\n",
    "\n",
    "Standaryzacja długości sekwencji (znalezienie najdłuższej, wypełnienie zerami pozostałych w taki sposób, aby wszystkie były jednakowej długości)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "print(x_train[0])\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_train = 5000\n",
    "n_test = 2000\n",
    "x_train = x_train[:n_train]\n",
    "y_train = y_train[:n_train]\n",
    "x_test = x_test[:n_test]\n",
    "y_test = y_test[:n_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddingi\n",
    "\n",
    "Przeanalizujmy co się dzieje w RNN, gdy podajemy słowa w reprezentacji one hot.\n",
    "\n",
    "## $$ h_t = f( W^h * h_{t-1} + W^x * x_t + b)$$\n",
    "\n",
    "Zatem jeśli x to \"one-hot\" z 1 na pozycji $i$ to:\n",
    "\n",
    "## $$ W^x * x_t = W^x[:,i],  $$\n",
    "\n",
    "Czyli wkład informacji embeddinga sprowadza się do wzięcia odpowieniej kolumny macierzy wag.\n",
    "\n",
    "Czyli i-ta kolumna macierzy wag jest w pewnym sensie reprezentacją słowa i.\n",
    "\n",
    "Zatem pójdźmy krok dalej: stwórzmy sobie dodatkową warstwę w sieci, zawierającą reprezentacje słów, które będą przekazywane do wyliczenia stanu ukrytego.\n",
    "\n",
    "\n",
    "Wówczas sieć z warstwą \"embeddingów\" ma postać:\n",
    "\n",
    "$x_t$ - id słowa wejściowego w momencie $t$.\n",
    "\n",
    "$EMB$ - macierz embeddingów\n",
    "\n",
    "<br>\n",
    "\n",
    "$$emb_t = EMB[x_t]$$\n",
    "$$ h_t = f( W^h * h_{t-1} + W^x * emb_t + b)$$\n",
    "\n",
    "<br>\n",
    "\n",
    "Ta warstwa nazywa się EMBEDDING'ami (embedding layer).\n",
    "\n",
    "\n",
    "<img src=\"https://image.slidesharecdn.com/translatefrombadenglishtogoodone-2-160606105036/95/aibigdata-lab-2016-11-638.jpg?cb=1465210454\" width=\"700\">\n",
    "Źródło: https://www.slideshare.net/Geeks_Lab/aibigdata-lab-2016-62764857\n",
    "\n",
    "\n",
    "\n",
    "### Zauważmy, że embeddingi są parametrami sieci, ale jednocześnie reprezentacją słów. Oznacza to, że trenując sieć, uczymy embeddingi, czyli uczymy się reprezentacji słów.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadania"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zwykład sieć rekurencyjna ( z embeddingami)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features,\n",
    "                    embedding_dims,\n",
    "                    input_length=maxlen))\n",
    "\n",
    "model.add(SimpleRNN(100))\n",
    "\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "early_stopping = EarlyStopping(patience=5,monitor=\"val_loss\")\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs = 100,\n",
    "          callbacks=[early_stopping],\n",
    "          validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test, verbose=0)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple RNN + dense pomiędzy zwracanym stanem ukrytym a outputem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features,\n",
    "                    embedding_dims,\n",
    "                    input_length=maxlen))\n",
    "\n",
    "model.add(SimpleRNN(100))\n",
    "\n",
    "model.add(Dense(100,activation=\"sigmoid\"))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "early_stopping = EarlyStopping(patience=5,monitor=\"val_loss\")\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs = 100,\n",
    "          callbacks=[early_stopping],\n",
    "          validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test, verbose=0)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dwuwarstwowa sieć rekurencyjna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features,\n",
    "                    embedding_dims,\n",
    "                    input_length=maxlen))\n",
    "\n",
    "model.add(SimpleRNN(100,return_sequences=True))\n",
    "model.add(SimpleRNN(100))\n",
    "\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "early_stopping = EarlyStopping(patience=5,monitor=\"val_loss\")\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs = 100,\n",
    "          callbacks=[early_stopping],\n",
    "          validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test, verbose=0)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dwukierunkowa sieć rekurencyjna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features,\n",
    "                    embedding_dims,\n",
    "                    input_length=maxlen))\n",
    "\n",
    "model.add(Bidirectional(SimpleRNN(100)))\n",
    "\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "early_stopping = EarlyStopping(patience=5,monitor=\"val_loss\")\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs = 100,\n",
    "          callbacks=[early_stopping],\n",
    "          validation_split=0.25)\n",
    "\n",
    "model.evaluate(x_test, y_test, verbose=0)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM\n",
    "\n",
    "Prezentacja.\n",
    "\n",
    "### Zadanie. Powtórz powyższe modele z komórką LSTM\n",
    "\n",
    "Przyjąć patience = 1 w early stoppingu!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features,\n",
    "                    embedding_dims,\n",
    "                    input_length=maxlen))\n",
    "\n",
    "model.add(LSTM(100))\n",
    "\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "early_stopping = EarlyStopping(patience=1,monitor=\"val_loss\")\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs = 100,\n",
    "          callbacks=[early_stopping],\n",
    "          validation_split=0.25)\n",
    "\n",
    "model.evaluate(x_test, y_test, verbose=0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features,\n",
    "                    embedding_dims,\n",
    "                    input_length=maxlen))\n",
    "\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(100,activation=\"sigmoid\"))\n",
    "\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "early_stopping = EarlyStopping(patience=1,monitor=\"val_loss\")\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs = 100,\n",
    "          callbacks=[early_stopping],\n",
    "          validation_split=0.25)\n",
    "\n",
    "model.evaluate(x_test, y_test, verbose=0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features,\n",
    "                    embedding_dims,\n",
    "                    input_length=maxlen))\n",
    "\n",
    "model.add(LSTM(100,return_sequences=True))\n",
    "model.add(LSTM(100))\n",
    "\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "early_stopping = EarlyStopping(patience=1,monitor=\"val_loss\")\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs = 100,\n",
    "          callbacks=[early_stopping],\n",
    "          validation_split=0.25)\n",
    "\n",
    "model.evaluate(x_test, y_test, verbose=0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features,\n",
    "                    embedding_dims,\n",
    "                    input_length=maxlen))\n",
    "\n",
    "model.add(Bidirectional(LSTM(100)))\n",
    "\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "early_stopping = EarlyStopping(patience=1,monitor=\"val_loss\")\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs = 100,\n",
    "          callbacks=[early_stopping],\n",
    "          validation_split=0.25)\n",
    "\n",
    "model.evaluate(x_test, y_test, verbose=0)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case study: Analiza sentymentu\n",
    "\n",
    "Przestestować:\n",
    "\n",
    "1. Simple RNN\n",
    "2. LSTM - porównaj na zbiorze testowym jakość działania modelu wziętego z najlepszej iteracji oraz modelu po zatrzymaniu uczenia\n",
    "3. LSTM + warstwa dense na końcu\n",
    "4. BiLSTM\n",
    "5. dwuwarstwowy LSTM\n",
    "6. CNN + LSTM - przepuścić dane przez warstwę konwolucyjną (conv1d) + max pooling, a następnie przejechać LSTM'em po tym wyszło."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 300)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "file_with_filtered_embeddings = \"Dane/data_poleval/embeddings.txt\"\n",
    "\n",
    "words2ids = {}\n",
    "embeddings = []\n",
    "\n",
    "embeddings.append(np.zeros(300)) # rezerwujemy embeddingi na paddin i nieznane slowa\n",
    "embeddings.append(np.zeros(300))\n",
    "\n",
    "i = 0\n",
    "with open(file_with_filtered_embeddings,\"r\") as f:\n",
    "    for line in f:\n",
    "        toks = line.split(\" \")\n",
    "        word = toks[0]\n",
    "        embeddings.append(np.array([float(x) for x in toks[1:]]))\n",
    "        words2ids[word] = i+2 # +3 - przesuniecie po to zeby specjalne embeddingi byly na pozycji 0 i 1\n",
    "        i = i + 1\n",
    "\n",
    "\n",
    "embeddings = np.array(embeddings)\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sponsorom': 1337,\n",
       " 'całemu': 773,\n",
       " 'demokracja': 2893,\n",
       " 'strojem': 2401,\n",
       " 'słyszy': 4930,\n",
       " 'głową': 1239,\n",
       " 'wysyłka': 1551,\n",
       " 'wystąpienie': 722,\n",
       " 'ściekają': 1369,\n",
       " 'zarzutów': 3847,\n",
       " 'konkurować': 1728,\n",
       " 'gustownie': 79,\n",
       " 'czterech': 3102,\n",
       " 'rząd': 882,\n",
       " 'odnoszę': 260,\n",
       " 'Mają': 2698,\n",
       " 'wydajny': 1776,\n",
       " 'spokojna': 2363,\n",
       " 'gwarem': 206,\n",
       " 'nią': 4047,\n",
       " 'wnuczki': 4804,\n",
       " 'zamierzam': 3688,\n",
       " 'drzewno': 477,\n",
       " 'internetowych': 2724,\n",
       " 'perfum': 935,\n",
       " 'życzenia': 2278,\n",
       " 'dniu': 4716,\n",
       " 'musi': 1826,\n",
       " 'pociągający': 2079,\n",
       " 'zmysłowych': 4983,\n",
       " 'Madziu': 4746,\n",
       " 'winduje': 2590,\n",
       " 'długie': 2000,\n",
       " 'białe': 2883,\n",
       " 'zgodnego': 4887,\n",
       " 'powoduje': 3265,\n",
       " 'pierwsze': 2540,\n",
       " 'Kuźnik': 4550,\n",
       " 'bardziej': 1830,\n",
       " 'dostajemy': 4166,\n",
       " 'Kodaku': 2012,\n",
       " 'niepraktyczne': 4468,\n",
       " 'idealnie': 1642,\n",
       " 'ginie': 164,\n",
       " 'faktycznie': 3919,\n",
       " 'markowych': 184,\n",
       " 'odznacza': 2064,\n",
       " 'wyrafinowany': 308,\n",
       " 'urokliwy': 2334,\n",
       " 'znawca': 3361,\n",
       " 'kąpać': 3608,\n",
       " 'zachęcających': 3275,\n",
       " 'Doskonale': 3692,\n",
       " 'użyte': 1663,\n",
       " 'rześki': 2948,\n",
       " 'niszcząc': 806,\n",
       " 'idźcie': 3674,\n",
       " 'rześkie': 1018,\n",
       " 'kurs': 2217,\n",
       " 'rokowała': 437,\n",
       " 'swą': 4598,\n",
       " 'uwaga': 3136,\n",
       " 'dobrej': 4960,\n",
       " 'naniesieniu': 3448,\n",
       " 'swoja': 4115,\n",
       " 'siły': 1084,\n",
       " 'szkół': 2876,\n",
       " 'boją': 1861,\n",
       " 'zakładać': 4542,\n",
       " 'Niepowtarzalny': 87,\n",
       " 'rozpoznawalnych': 2364,\n",
       " 'zakupów': 729,\n",
       " 'napełniający': 3239,\n",
       " 'róży': 885,\n",
       " 'osobom': 2310,\n",
       " 'Szybko': 2219,\n",
       " 'Podkreśla': 1590,\n",
       " 'długo': 915,\n",
       " 'ofiarą': 4219,\n",
       " 'Wygląda': 3177,\n",
       " 'rozwydrzoną': 1897,\n",
       " 'Gorsenia': 1626,\n",
       " 'Wyraźnie': 632,\n",
       " 'pożyteczne': 3713,\n",
       " 'Kompletnie': 592,\n",
       " 'rzucając': 1177,\n",
       " 'skutku': 3521,\n",
       " 'Tragiczny': 1520,\n",
       " 'usunięto': 2058,\n",
       " 'nieporęczna': 2016,\n",
       " 'żeby': 4463,\n",
       " 'klasycznego': 2836,\n",
       " 'urzędzie': 878,\n",
       " 'wanilia': 3970,\n",
       " 'Uniwersytetu': 544,\n",
       " 'używają': 3920,\n",
       " 'Stanowią': 4272,\n",
       " 'problemy': 94,\n",
       " 'upiekli': 674,\n",
       " 'razie': 1442,\n",
       " 'osiłkami': 1786,\n",
       " 'pierwszej': 3634,\n",
       " 'znalezienia': 4351,\n",
       " 'mających': 2533,\n",
       " 'walki': 1969,\n",
       " 'pozytywnych': 4458,\n",
       " 'powiedziała': 3552,\n",
       " 'Calvin': 4170,\n",
       " 'używał': 495,\n",
       " 'wyglądać': 720,\n",
       " 'starali': 1048,\n",
       " 'swobodnych': 3378,\n",
       " 'jezioro': 3347,\n",
       " 'zakładania': 338,\n",
       " 'Produkt': 3175,\n",
       " 'swoistej': 4085,\n",
       " 'Czuć': 3098,\n",
       " 'oryginalna': 1223,\n",
       " 'ekscytacji': 2095,\n",
       " 'zwierząt': 1007,\n",
       " 'koronki': 4555,\n",
       " 'ozdobny': 1565,\n",
       " 'którzy': 4185,\n",
       " 'publicznego': 4588,\n",
       " 'ulgą': 4083,\n",
       " 'PANA': 2730,\n",
       " 'Taki': 3203,\n",
       " 'Men': 4534,\n",
       " 'uwagi': 3417,\n",
       " 'chęci': 4865,\n",
       " 'godny': 1613,\n",
       " 'uznali': 1880,\n",
       " 'przeczesuje': 1522,\n",
       " 'dostała': 1160,\n",
       " 'gospodarczą': 1594,\n",
       " 'Rodzina': 2675,\n",
       " 'piersiami': 890,\n",
       " 'mogę': 1289,\n",
       " 'Stwierdził': 1094,\n",
       " 'innego': 2257,\n",
       " 'cechy': 85,\n",
       " 'najbliższymi': 2841,\n",
       " 'korzyści': 1940,\n",
       " 'zniechęcenia': 1757,\n",
       " 'cytrusów': 3,\n",
       " 'praniu': 3073,\n",
       " 'Jesteś': 1306,\n",
       " 'zaczęły': 709,\n",
       " 'dorodnym': 1097,\n",
       " 'wyróżniających': 40,\n",
       " 'Wspaniały': 2396,\n",
       " 'Kazio': 2625,\n",
       " 'wewnętrzne': 1424,\n",
       " 'wręczenia': 1063,\n",
       " 'przecudowny': 39,\n",
       " 'niedzielę': 2142,\n",
       " 'bujnym': 28,\n",
       " 'wesołe': 2957,\n",
       " 'zdecydowała': 2298,\n",
       " 'przeznaczony': 653,\n",
       " 'się': 1961,\n",
       " 'uwolnione': 4806,\n",
       " 'Ciekawe': 2664,\n",
       " 'zapasie': 2856,\n",
       " 'go': 1584,\n",
       " 'będą': 1959,\n",
       " 'przypasował': 1336,\n",
       " 'fatalnych': 4109,\n",
       " 'hiszpańskie': 2261,\n",
       " 'Niesamowicie': 2409,\n",
       " 'ofiarom': 2213,\n",
       " 'entuzjastyczne': 2811,\n",
       " 'niepowtarzalny': 1545,\n",
       " 'dodatkowo': 1329,\n",
       " 'wyjątkowo': 3400,\n",
       " 'prokuraturę': 3243,\n",
       " 'seksowna': 3960,\n",
       " 'antyutleniacze': 380,\n",
       " 'Zwraca': 4456,\n",
       " 'zginie': 844,\n",
       " 'poszukuję': 769,\n",
       " 'lubisz': 2472,\n",
       " 'podziwu': 10,\n",
       " 'Ośrodku': 1780,\n",
       " 'kiedykolwiek': 3604,\n",
       " 'nożną': 4782,\n",
       " 'nazywał': 2894,\n",
       " 'odpowiadał': 178,\n",
       " 'duszący': 1772,\n",
       " 'minimalizmu': 3094,\n",
       " '6': 3686,\n",
       " 'Ducha': 81,\n",
       " 'klasycznej': 1900,\n",
       " 'Paco': 1577,\n",
       " 'Armani': 832,\n",
       " 'Większość': 459,\n",
       " 'własnego': 853,\n",
       " 'radosny': 3171,\n",
       " 'aromatyczny': 2209,\n",
       " 'policji': 713,\n",
       " 'buja': 790,\n",
       " 'Piątka': 2444,\n",
       " 'głęboko': 4795,\n",
       " 'głęboki': 3769,\n",
       " 'młodego': 229,\n",
       " 'pełen': 1465,\n",
       " 'świeża': 3888,\n",
       " 'lubili': 208,\n",
       " 'wynagradza': 3600,\n",
       " 'rejon': 3391,\n",
       " 'wybór': 1540,\n",
       " 'wyjątkowej': 2030,\n",
       " 'przeciwnie': 3118,\n",
       " 'toaletowej': 3857,\n",
       " 'warty': 3671,\n",
       " 'Chojnic': 2735,\n",
       " 'tempo': 3020,\n",
       " 'sukni': 1435,\n",
       " 'łatwych': 4649,\n",
       " 'pachnę': 4843,\n",
       " 'Blue': 2430,\n",
       " 'klimat': 1924,\n",
       " 'podnosi': 410,\n",
       " 'ludzkości': 189,\n",
       " 'przesadnie': 2405,\n",
       " 'efektywną': 533,\n",
       " 'pewnością': 1997,\n",
       " 'Marka': 714,\n",
       " 'duma': 2045,\n",
       " 'zeznania': 204,\n",
       " 'Atrakcyjny': 1061,\n",
       " 'przyjacielskiej': 2216,\n",
       " 'Jesteśmy': 887,\n",
       " 'czyli': 4797,\n",
       " 'Prezentowany': 1334,\n",
       " 'pory': 1106,\n",
       " 'koszulkę': 3147,\n",
       " 'facet': 2551,\n",
       " 'Administracja': 3259,\n",
       " 'świerzy': 3329,\n",
       " 'groźne': 718,\n",
       " 'wszechstronny': 1709,\n",
       " 'zszargane': 1366,\n",
       " 'Poza': 4352,\n",
       " 'twarze': 4474,\n",
       " 'małpujemy': 3937,\n",
       " 'purpurowego': 1779,\n",
       " 'załączone': 1281,\n",
       " 'odbierało': 2605,\n",
       " 'sportowymi': 1792,\n",
       " 'wąchać': 1415,\n",
       " 'dziewczyn': 4454,\n",
       " 'jakiś': 4994,\n",
       " 'wszystkie': 4821,\n",
       " 'Pięknie': 3754,\n",
       " 'Opinia': 3915,\n",
       " 'modeluje': 807,\n",
       " 'oszust': 1507,\n",
       " 'słodkiego': 191,\n",
       " 'kryją': 3028,\n",
       " 'spotykany': 562,\n",
       " 'bluzeczką': 1464,\n",
       " 'gaia': 2223,\n",
       " 'wypadek': 471,\n",
       " 'dobrem': 4961,\n",
       " 'Gabbana': 2852,\n",
       " 'mnóstwem': 660,\n",
       " 'zwiększając': 765,\n",
       " 'Boję': 4477,\n",
       " 'totalnie': 3682,\n",
       " 'poranku': 767,\n",
       " 'urodzinowym': 3466,\n",
       " 'Przeniosła': 2465,\n",
       " 'Ciekawa': 2665,\n",
       " '38': 4629,\n",
       " 'klientem': 444,\n",
       " 'kobiecej': 3971,\n",
       " 'Ogromny': 2517,\n",
       " 'Zdenerwowani': 1382,\n",
       " 'sukienki': 30,\n",
       " 'światowym': 449,\n",
       " 'eksmitowanych': 450,\n",
       " 'tuż': 4963,\n",
       " 'Cesar': 2949,\n",
       " 'Buzka': 635,\n",
       " 'Czasem': 2163,\n",
       " 'rozmiarach': 1172,\n",
       " 'denerwował': 4208,\n",
       " 'winy': 2928,\n",
       " 'wkładki': 4464,\n",
       " 'uwiera': 430,\n",
       " 'odrzucający': 2362,\n",
       " 'dają': 3264,\n",
       " 'Nadaje': 4052,\n",
       " 'balsam': 3377,\n",
       " 'trwałość': 2245,\n",
       " 'nietypowy': 3272,\n",
       " 'przyjemne': 1049,\n",
       " 'zaniechania': 4242,\n",
       " 'Krzyża': 1006,\n",
       " 'więcej': 4676,\n",
       " 'kupie': 3437,\n",
       " 'przypominający': 1676,\n",
       " 'czuję': 1647,\n",
       " 'pojemności': 3664,\n",
       " 'zawsze': 417,\n",
       " 'drażni': 4029,\n",
       " 'Zupełnie': 1794,\n",
       " 'zalety': 991,\n",
       " 'kasjerkę': 4120,\n",
       " 'fascynacją': 3096,\n",
       " 'nasza': 4984,\n",
       " 'Zachęcam': 3480,\n",
       " 'pobudzający': 3918,\n",
       " 'ktorą': 587,\n",
       " 'luksusem': 2968,\n",
       " 'wysoka': 2105,\n",
       " 'KAŻDEGO': 4966,\n",
       " 'zawiedzie': 875,\n",
       " 'lekkości': 1624,\n",
       " 'łagodny': 2554,\n",
       " 'obiedzie': 612,\n",
       " 'gatki': 4622,\n",
       " 'przysłowiowy': 2996,\n",
       " 'reżymowym': 3568,\n",
       " 'marzy': 4326,\n",
       " 'przeżycie': 3909,\n",
       " 'spoko': 1557,\n",
       " 'noszeniu': 2905,\n",
       " 'ksiądz': 4972,\n",
       " 'przeciętnego': 262,\n",
       " 'ramiączko': 1797,\n",
       " 'biustonoszach': 654,\n",
       " 'Robią': 1283,\n",
       " 'stoi': 631,\n",
       " 'Triumph': 2827,\n",
       " 'słonecznej': 3490,\n",
       " 'rycinie': 493,\n",
       " 'młodzieżą': 466,\n",
       " 'wyrywanie': 3726,\n",
       " 'aromat': 3107,\n",
       " 'okazjonalnie': 3736,\n",
       " 'muzeum': 2783,\n",
       " 'wybierasz': 4869,\n",
       " 'zamówiła': 2171,\n",
       " 'proszą': 977,\n",
       " 'perfumą': 1138,\n",
       " 'wygodna': 4383,\n",
       " 'powiększa': 3569,\n",
       " 'dziewczęcy': 3584,\n",
       " 'oferowana': 4491,\n",
       " 'Zachowują': 812,\n",
       " 'zwłaszcza': 3120,\n",
       " 'niewielki': 834,\n",
       " 'chwili': 1472,\n",
       " 'Hugo': 1958,\n",
       " 'sztuczny': 289,\n",
       " 'liści': 1216,\n",
       " 'chmurki': 4073,\n",
       " 'Zaczynał': 1378,\n",
       " 'imprezie': 2689,\n",
       " 'dziennikarzy': 2734,\n",
       " 'papużki': 3424,\n",
       " 'irlandzkiego': 4874,\n",
       " 'przepełniony': 2643,\n",
       " 'stary': 4876,\n",
       " 'religijni': 580,\n",
       " 'Piotr': 3586,\n",
       " 'policja': 712,\n",
       " 'Wojewódzkiej': 3578,\n",
       " 'oklaski': 1364,\n",
       " 'gustuję': 3826,\n",
       " 'tworząc': 37,\n",
       " 'Chodź': 1652,\n",
       " '7': 2398,\n",
       " 'wyeksponuje': 1386,\n",
       " 'świeccy': 4227,\n",
       " 'paru': 1946,\n",
       " 'Długotrwały': 2044,\n",
       " 'głowy': 1240,\n",
       " 'Drugim': 1349,\n",
       " 'tłumie': 665,\n",
       " 'otoczeniu': 2926,\n",
       " 'Rewelacyjna': 3406,\n",
       " 'pełnowymiarowa': 3095,\n",
       " 'cud': 2768,\n",
       " 'krajowych': 1892,\n",
       " 'związkami': 3415,\n",
       " 'Mnie': 2508,\n",
       " 'tam': 1839,\n",
       " 'ojciec': 3447,\n",
       " 'niespodziewanym': 3997,\n",
       " 'godna': 1615,\n",
       " 'obiekt': 270,\n",
       " 'przesłodzonym': 1396,\n",
       " 'obrad': 2986,\n",
       " 'jak': 2738,\n",
       " 'placówka': 3209,\n",
       " 'Solidnie': 4179,\n",
       " 'powiedzieć': 2670,\n",
       " 'wyjściem': 2194,\n",
       " 'pozwoliła': 255,\n",
       " 'myląca': 3112,\n",
       " 'zdobień': 2869,\n",
       " 'wiarygodności': 1524,\n",
       " 'bluzkę': 4139,\n",
       " 'dróg': 282,\n",
       " 'wizerunkiem': 865,\n",
       " 'bez': 3534,\n",
       " 'popełnieniu': 1902,\n",
       " 'bał': 3328,\n",
       " 'niemiłosiernie': 1058,\n",
       " 'rosyjskie': 3941,\n",
       " 'poszukiwań': 3343,\n",
       " 'Frontery': 421,\n",
       " 'łagodna': 2553,\n",
       " 'tragiczne': 3438,\n",
       " 'wystąpień': 3722,\n",
       " 'nowoczesna': 3697,\n",
       " 'sympatykom': 530,\n",
       " 'pozostają': 4866,\n",
       " 'zakładając': 3370,\n",
       " 'goździkowy': 4886,\n",
       " 'taniej': 4298,\n",
       " 'godnym': 771,\n",
       " 'marka': 1438,\n",
       " 'rana': 2594,\n",
       " 'inaczej': 411,\n",
       " 'lider': 150,\n",
       " 'wreszcie': 4492,\n",
       " 'łokcia': 3117,\n",
       " 'przeciwniczek': 1352,\n",
       " 'wesoły': 2958,\n",
       " 'kremowy': 1347,\n",
       " 'kroju': 1620,\n",
       " 'zestawienie': 2452,\n",
       " 'zanim': 266,\n",
       " 'trawą': 124,\n",
       " 'pierwszy': 2538,\n",
       " 'studniówkę': 4151,\n",
       " 'grubość': 3899,\n",
       " 'przed': 905,\n",
       " 'zakryty': 3613,\n",
       " 'miseczek': 386,\n",
       " 'wkrótce': 2900,\n",
       " 'Flakon': 4568,\n",
       " 'modny': 2710,\n",
       " 'Natomiast': 3293,\n",
       " 'przede': 2570,\n",
       " 'dziewcząt': 1495,\n",
       " 'ideału': 4164,\n",
       " 'projektowi': 4312,\n",
       " 'bliskiej': 4762,\n",
       " 'Orląt': 2824,\n",
       " 'gładkie': 2767,\n",
       " 'mógł': 3200,\n",
       " 'ładną': 2760,\n",
       " 'wiem': 2124,\n",
       " 'takie': 4837,\n",
       " 'dłużej': 35,\n",
       " 'O': 4457,\n",
       " 'przytłacza': 4976,\n",
       " 'ukochany': 4387,\n",
       " 'przykład': 336,\n",
       " 'odpowiadać': 177,\n",
       " 'poniej': 4485,\n",
       " 'zakupić': 1942,\n",
       " 'leżą': 26,\n",
       " 'odcienie': 4715,\n",
       " 'seksownego': 3789,\n",
       " 'spodobają': 1947,\n",
       " 'Zamówiła': 1741,\n",
       " 'szalonej': 1872,\n",
       " 'znajomy': 3036,\n",
       " 'mężczyznom': 2942,\n",
       " 'sprawić': 1493,\n",
       " 'odporność': 2873,\n",
       " 'Dlaczego': 2299,\n",
       " 'nasze': 4985,\n",
       " 'Kusi': 967,\n",
       " 'powiększając': 1864,\n",
       " 'znaków': 2387,\n",
       " 'aplikacji': 1075,\n",
       " 'zostawiając': 565,\n",
       " 'zmniejsza': 1209,\n",
       " 'wynika': 3702,\n",
       " 'nieprzyzwoitość': 305,\n",
       " 'moczą': 4307,\n",
       " 'poeta': 292,\n",
       " 'Zachodowi': 2101,\n",
       " 'urwie': 1340,\n",
       " 'głośno': 3738,\n",
       " 'urok': 4036,\n",
       " 'przykrą': 3384,\n",
       " 'futbolu': 3251,\n",
       " 'przestępczością': 4366,\n",
       " 'zwrócił': 3126,\n",
       " 'Cena': 2833,\n",
       " 'odczucia': 3456,\n",
       " 'ewoluuje': 3310,\n",
       " 'biustonoszu': 2341,\n",
       " 'ciągle': 2347,\n",
       " 'powstańcza': 47,\n",
       " 'konserwatywnie': 321,\n",
       " 'mydło': 3374,\n",
       " 'odpowiednio': 3557,\n",
       " 'motyw': 4253,\n",
       " 'faworyt': 1422,\n",
       " 'zainteresowanie': 3483,\n",
       " 'czymś': 940,\n",
       " 'dwoje': 2222,\n",
       " 'kreacje': 766,\n",
       " 'korzystnej': 3992,\n",
       " 'fajnego': 2621,\n",
       " 'zakupy': 2143,\n",
       " 'by': 4897,\n",
       " 'rżniętych': 2114,\n",
       " 'dotyk': 939,\n",
       " 'nosze': 2382,\n",
       " 'wypuści': 36,\n",
       " 'rozciąga': 892,\n",
       " 'Push': 2289,\n",
       " 'chodzi': 3179,\n",
       " 'związanych': 3178,\n",
       " 'propozycja': 1570,\n",
       " 'kultowym': 3157,\n",
       " 'włosów': 3502,\n",
       " 'przeciętnej': 45,\n",
       " 'kultowych': 2794,\n",
       " 'co': 3455,\n",
       " 'Efektem': 2135,\n",
       " 'ks': 970,\n",
       " 'zachowywać': 2413,\n",
       " 'Cukierkowy': 1326,\n",
       " 'estetyczny': 3564,\n",
       " 'wbijają': 2960,\n",
       " 'gotówki': 1203,\n",
       " 'przyjął': 1327,\n",
       " 'odnaleźć': 4020,\n",
       " 'koronka': 4556,\n",
       " 'specjalne': 3592,\n",
       " 'Sukienka': 4232,\n",
       " 'zdecydowanych': 353,\n",
       " 'lubimy': 1405,\n",
       " 'rodzinnego': 683,\n",
       " 'piękne': 2771,\n",
       " 'stanie': 589,\n",
       " 'wicestarosta': 876,\n",
       " 'przez': 3532,\n",
       " 'Pań': 701,\n",
       " 'wypróbować': 107,\n",
       " 'nocną': 889,\n",
       " 'unosząc': 1533,\n",
       " 'gen': 1278,\n",
       " 'norma': 4444,\n",
       " 'Fajny': 1372,\n",
       " 'wygląda': 519,\n",
       " 'wyeksponowanego': 1509,\n",
       " 'tradycjami': 2392,\n",
       " 'energią': 1754,\n",
       " 'wartość': 83,\n",
       " 'pewną': 4394,\n",
       " 'Lecz': 2976,\n",
       " 'innych': 4451,\n",
       " 'cztery': 4262,\n",
       " 'również': 2358,\n",
       " 'odwodziła': 1029,\n",
       " 'zawartości': 3996,\n",
       " 'samego': 3359,\n",
       " 'uwydatnia': 4286,\n",
       " 'ślicznym': 3324,\n",
       " 'pyszniła': 506,\n",
       " 'podkreślone': 652,\n",
       " 'maly': 3003,\n",
       " 'Carmen': 3100,\n",
       " 'wazonik': 4001,\n",
       " 'Ten': 3266,\n",
       " 'kolejny': 4895,\n",
       " 'bezpiecznie': 3162,\n",
       " 'harmonijnego': 1291,\n",
       " 'Zapachem': 3515,\n",
       " 'tajemniczym': 3416,\n",
       " 'terrorystycznym': 3658,\n",
       " 'wygodne': 4384,\n",
       " 'pokazać': 3085,\n",
       " 'policjantowi': 1686,\n",
       " 'najstarsze': 1119,\n",
       " 'finału': 4959,\n",
       " 'wielkiej': 2485,\n",
       " 'nutką': 2582,\n",
       " 'śmiertelny': 3487,\n",
       " 'przywiązać': 2263,\n",
       " 'piękno': 2770,\n",
       " 'dekolt': 1250,\n",
       " 'drogowych': 4333,\n",
       " 'Dobrze': 453,\n",
       " 'zmysłowe': 2879,\n",
       " 'całego': 3746,\n",
       " 'przykuwa': 3316,\n",
       " 'sprawili': 2725,\n",
       " 'atrakcyjny': 3694,\n",
       " 'lato': 4698,\n",
       " 'jacyś': 2248,\n",
       " 'Ramiączka': 3484,\n",
       " 'latach': 3693,\n",
       " 'kosztują': 122,\n",
       " 'perfumowana': 2909,\n",
       " 'gigantyczna': 4754,\n",
       " 'u': 1992,\n",
       " 'ciepło': 634,\n",
       " 'natomiast': 53,\n",
       " 'stapia': 1781,\n",
       " 'okazało': 3101,\n",
       " 'letni': 3896,\n",
       " 'odbierają': 158,\n",
       " 'testu': 48,\n",
       " 'ufności': 3988,\n",
       " 'uznaną': 4513,\n",
       " 'Koronkowe': 4753,\n",
       " 'porządnych': 1765,\n",
       " 'mężczyznę': 1513,\n",
       " 'upłynęło': 1205,\n",
       " 'uwiódł': 1020,\n",
       " 'głupią': 1031,\n",
       " 'trasie': 3045,\n",
       " 'gruby': 4801,\n",
       " 'użyć': 4484,\n",
       " 'je': 3718,\n",
       " 'drogeryjnych': 407,\n",
       " 'korzystania': 2361,\n",
       " 'pojemnika': 3999,\n",
       " 'Niektóre': 2806,\n",
       " 'pisarz': 1838,\n",
       " 'myślach': 4922,\n",
       " 'prawdopodobieństwo': 2357,\n",
       " 'brzydkiego': 2727,\n",
       " 'drapieżnych': 3491,\n",
       " 'przyjemnością': 3869,\n",
       " 'koleżanki': 764,\n",
       " 'dzieci': 3609,\n",
       " 'ciąg': 2823,\n",
       " 'gdy': 2514,\n",
       " 'pani': 329,\n",
       " 'Zróżnicowana': 111,\n",
       " 'tirów': 1631,\n",
       " 'łąką': 439,\n",
       " 'komponuje': 1482,\n",
       " 'wygląd': 1680,\n",
       " 'luzaka': 4308,\n",
       " 'postawił': 2858,\n",
       " 'wychodzą': 74,\n",
       " 'akcentem': 1254,\n",
       " 'Sylwetka': 1605,\n",
       " 'irytacji': 2172,\n",
       " 'minusów': 3979,\n",
       " 'Męska': 4587,\n",
       " 'przetestować': 2959,\n",
       " 'Polki': 542,\n",
       " 'miłe': 1218,\n",
       " 'owocowy': 4710,\n",
       " 'Lacosta': 4149,\n",
       " 'wydawać': 4142,\n",
       " 'mała': 3474,\n",
       " 'dni': 1251,\n",
       " 'lekką': 809,\n",
       " 'drzewną': 478,\n",
       " 'w': 3093,\n",
       " 'państwu': 1414,\n",
       " 'działają': 1921,\n",
       " 'pazur': 256,\n",
       " 'Molise': 1373,\n",
       " 'dziś': 3551,\n",
       " 'moja': 735,\n",
       " 'interesu': 2755,\n",
       " 'dresu': 2534,\n",
       " 'wyłącznie': 3866,\n",
       " 'eseisty': 2516,\n",
       " 'biznesowe': 4695,\n",
       " 'wszystko': 3210,\n",
       " 'męskiej': 3933,\n",
       " 'Przerzuciła': 3196,\n",
       " 'swoich': 1017,\n",
       " 'kojaży': 2597,\n",
       " 'różni': 1722,\n",
       " 'stabilnych': 4661,\n",
       " 'przyciągają': 3232,\n",
       " 'serii': 4342,\n",
       " 'obrazów': 3668,\n",
       " 'pomoże': 1925,\n",
       " 'skuszę': 2117,\n",
       " 'opływa': 2130,\n",
       " 'Haft': 1973,\n",
       " 'Najlepsza': 4331,\n",
       " 'uszanuję': 1193,\n",
       " 'stabilny': 2478,\n",
       " 'lekarze': 63,\n",
       " 'sporej': 4936,\n",
       " 'DLA': 1790,\n",
       " 'pełne': 819,\n",
       " 'zadbaną': 4921,\n",
       " 'ulubieńców': 2650,\n",
       " 'oprawionych': 244,\n",
       " 'ubezpieczeniowego': 4278,\n",
       " 'zaś': 3903,\n",
       " 'dolara': 1628,\n",
       " 'Mała': 3530,\n",
       " 'nucie': 3357,\n",
       " 'sukcesu': 2350,\n",
       " 'ostre': 968,\n",
       " 'Nakładki': 4258,\n",
       " 'węchem': 4914,\n",
       " 'obcisłej': 4329,\n",
       " 'sukienek': 3861,\n",
       " 'zjazdowi': 1717,\n",
       " 'skromniejsze': 4096,\n",
       " 'Pasuje': 2661,\n",
       " 'seksapil': 642,\n",
       " 'butelki': 1871,\n",
       " 'artystyczne': 3598,\n",
       " '30ml': 315,\n",
       " 'Kolejną': 159,\n",
       " 'gatunków': 3257,\n",
       " 'środkowo': 3750,\n",
       " 'pachną': 4844,\n",
       " 'Ich': 1760,\n",
       " 'LUPO': 4987,\n",
       " 'precyzyjnie': 1413,\n",
       " 'powitali': 4877,\n",
       " 'zwolenniczek': 1162,\n",
       " 'mgiełką': 3834,\n",
       " 'zaskoczył': 4803,\n",
       " 'miękki': 2780,\n",
       " 'prowadzonej': 1064,\n",
       " 'Jego': 4024,\n",
       " 'zachęcał': 4898,\n",
       " 'pampersów': 3082,\n",
       " 'każe': 4526,\n",
       " 'wpływem': 463,\n",
       " 'ulubionych': 630,\n",
       " 'wyjazdu': 4360,\n",
       " 'realizmu': 582,\n",
       " 'przypomina': 3538,\n",
       " 'Szczególnie': 759,\n",
       " 'silnych': 4893,\n",
       " 'Buzek': 2703,\n",
       " 'Przyjemny': 1952,\n",
       " 'moze': 1693,\n",
       " 'przereklamowanym': 2266,\n",
       " 'męski': 1287,\n",
       " 'kawowej': 2629,\n",
       " 'zasługuje': 3414,\n",
       " 'adekwatna': 51,\n",
       " 'Zachowała': 176,\n",
       " 'przecenianie': 2989,\n",
       " 'mankament': 686,\n",
       " 'ubiorze': 3559,\n",
       " 'zawyżają': 2346,\n",
       " 'listę': 4878,\n",
       " 'Wydaje': 2839,\n",
       " 'przepięknie': 1111,\n",
       " 'wzgledu': 3655,\n",
       " 'Dzień': 443,\n",
       " 'doznaną': 4619,\n",
       " 'The': 2268,\n",
       " 'węchu': 1021,\n",
       " 'charakterystyczny': 1008,\n",
       " 'kolorze': 61,\n",
       " 'znosi': 3467,\n",
       " 'markowe': 3486,\n",
       " 'Muszę': 728,\n",
       " 'boss': 1153,\n",
       " 'dalekosiężne': 25,\n",
       " 'krople': 3352,\n",
       " 'ostrożności': 3014,\n",
       " 'NIE': 4678,\n",
       " 'założenie': 4103,\n",
       " 'fasonu': 1499,\n",
       " 'we': 4154,\n",
       " 'psiknięcie': 1569,\n",
       " 'całość': 1359,\n",
       " 'walka': 1968,\n",
       " 'męskość': 201,\n",
       " 'członkiem': 2303,\n",
       " 'stylem': 1833,\n",
       " 'niezła': 2001,\n",
       " 'pomógł': 4730,\n",
       " 'tych': 2283,\n",
       " 'Million': 1272,\n",
       " 'dziesięć': 4988,\n",
       " 'Chociaż': 692,\n",
       " 'kształcie': 877,\n",
       " 'małej': 4297,\n",
       " 'przedmurza': 3788,\n",
       " 'zauważył': 131,\n",
       " 'pożądaniem': 1043,\n",
       " 'specjalny': 3591,\n",
       " 'zabawy': 2373,\n",
       " 'miniaturkę': 247,\n",
       " 'firmie': 3894,\n",
       " 'kwestii': 3605,\n",
       " 'zajął': 3630,\n",
       " 'ruchu': 3883,\n",
       " 'przewiezieniu': 2695,\n",
       " 'zwanych': 3791,\n",
       " 'błoto': 3253,\n",
       " 'ponadto': 4,\n",
       " 'koronkowe': 1591,\n",
       " 'wielowymiarowe': 1296,\n",
       " 'kilo': 4849,\n",
       " 'Pomysł': 1575,\n",
       " 'wydaje': 2457,\n",
       " 'wyróżniający': 3326,\n",
       " 'ma': 638,\n",
       " 'ramiączek': 1926,\n",
       " 'miłością': 4202,\n",
       " 'spytało': 789,\n",
       " 'atrakcyjne': 3695,\n",
       " 'Przedsiębiorcę': 684,\n",
       " 'dojrzałą': 4106,\n",
       " 'lekkim': 420,\n",
       " 'zastrzeżeń': 192,\n",
       " 'dostępny': 4523,\n",
       " 'Wyrzekli': 4081,\n",
       " 'wyposażony': 4908,\n",
       " 'zdecydował': 4167,\n",
       " 'Ogólny': 4479,\n",
       " 'klasyczna': 2565,\n",
       " 'wydała': 4527,\n",
       " 'PUA': 4605,\n",
       " 'młodej': 291,\n",
       " 'jakościowo': 2332,\n",
       " 'ubranych': 1855,\n",
       " 'dostaje': 4967,\n",
       " 'kondycji': 1837,\n",
       " 'kolorową': 284,\n",
       " 'Ktoś': 1253,\n",
       " 'rozmiary': 2522,\n",
       " 'ostatecznego': 960,\n",
       " 'tj': 2108,\n",
       " 'pociąga': 2075,\n",
       " 'żywić': 433,\n",
       " 'Zanieczyszczenia': 1299,\n",
       " 'cios': 4261,\n",
       " 'Jedno': 1694,\n",
       " 'kokarda': 918,\n",
       " 'podbił': 1129,\n",
       " 'design': 2955,\n",
       " 'chyba': 3198,\n",
       " 'pamiętają': 3173,\n",
       " 'Sporo': 4981,\n",
       " 'Wyzwala': 4086,\n",
       " 'ułożenia': 821,\n",
       " 'kwiatową': 217,\n",
       " 'kwiatowym': 563,\n",
       " 'kobiecych': 1917,\n",
       " 'składu': 1930,\n",
       " 'inna': 1816,\n",
       " 'flakonik': 119,\n",
       " 'Miło': 114,\n",
       " 'koleżankę': 762,\n",
       " 'oferty': 2451,\n",
       " 'Doszedł': 3758,\n",
       " 'stracił': 2813,\n",
       " 'zawiódł': 4957,\n",
       " 'polecam': 4475,\n",
       " 'tasiemką': 3284,\n",
       " 'odległości': 2680,\n",
       " 'warta': 3670,\n",
       " 'gdzie': 978,\n",
       " 'wyczuć': 1873,\n",
       " 'zaborze': 2029,\n",
       " 'zainteresuje': 98,\n",
       " 'przyjęła': 371,\n",
       " '2': 4393,\n",
       " 'porą': 1107,\n",
       " 'dostojny': 1066,\n",
       " 'odkryła': 1221,\n",
       " 'obowiązkowe': 4809,\n",
       " 'natarczywą': 72,\n",
       " 'niepostrzeżenie': 4102,\n",
       " 'nagle': 1714,\n",
       " 'kojarzyła': 127,\n",
       " 'doprowadza': 4090,\n",
       " 'kieliszku': 2922,\n",
       " 'Matowe': 2041,\n",
       " 'boski': 80,\n",
       " 'lepszy': 4398,\n",
       " 'robotniczych': 1856,\n",
       " 'nowsza': 4845,\n",
       " 'otrzymała': 989,\n",
       " 'zdecydowaną': 3659,\n",
       " 'małych': 3403,\n",
       " 'średniej': 1598,\n",
       " 'całymi': 534,\n",
       " 'przyciągającym': 4691,\n",
       " 'pachnący': 4567,\n",
       " 'wielki': 3638,\n",
       " 'najmniejszego': 2428,\n",
       " 'zwykle': 2202,\n",
       " 'tego': 366,\n",
       " 'żle': 4395,\n",
       " 'świeżości': 4222,\n",
       " 'Cool': 4703,\n",
       " 'męskie': 4690,\n",
       " 'twórca': 4832,\n",
       " 'najmłodszych': 1970,\n",
       " 'Noir': 2785,\n",
       " 'Chciała': 3442,\n",
       " 'seksownych': 2476,\n",
       " 'gustach': 1144,\n",
       " 'Często': 4482,\n",
       " 'porządnie': 314,\n",
       " 'line': 3968,\n",
       " 'owocowo': 4709,\n",
       " 'czy': 4141,\n",
       " 'Dino': 2947,\n",
       " 'miseczki': 2875,\n",
       " 'romantyczne': 2241,\n",
       " 'wykonania': 584,\n",
       " 'radosnym': 678,\n",
       " 'obywatela': 2166,\n",
       " 'uroczy': 4504,\n",
       " 'różu': 886,\n",
       " 'Sylwestra': 1401,\n",
       " 'prawdziwego': 3436,\n",
       " 'wkładać': 1608,\n",
       " 'one': 3654,\n",
       " 'sejsmicznej': 174,\n",
       " 'tyle': 1486,\n",
       " 'Niedawno': 3984,\n",
       " 'parę': 1945,\n",
       " 'powalająca': 2436,\n",
       " 'świeżość': 4032,\n",
       " 'zawiedziona': 3860,\n",
       " 'Mocny': 2544,\n",
       " 'niebanalny': 3680,\n",
       " 'skrzywdzonego': 1679,\n",
       " 'pochodzą': 1905,\n",
       " 'Intrygujący': 4403,\n",
       " 'Pan': 702,\n",
       " 'wieczorowe': 1862,\n",
       " 'utrzymują': 619,\n",
       " 'Idealny': 1749,\n",
       " 'wyobrażenia': 2950,\n",
       " 'niepewności': 3019,\n",
       " 'uporać': 2080,\n",
       " 'żądania': 467,\n",
       " 'zacina': 3241,\n",
       " 'suknię': 1053,\n",
       " 'poniżej': 4775,\n",
       " 'ubóstwa': 3961,\n",
       " 'moralnym': 4931,\n",
       " 'złośliwy': 4071,\n",
       " 'panieński': 3910,\n",
       " 'pewna': 4389,\n",
       " 'młodą': 1674,\n",
       " 'reprezentują': 3562,\n",
       " 'końcu': 894,\n",
       " 'setką': 1427,\n",
       " 'nas': 1409,\n",
       " 'działania': 2233,\n",
       " 'ceniąca': 4594,\n",
       " 'odczuciu': 3457,\n",
       " 'materiału': 175,\n",
       " 'dnia': 4965,\n",
       " 'Johnsona': 4427,\n",
       " 'używany': 4128,\n",
       " 'Dwie': 1380,\n",
       " 'gama': 4620,\n",
       " 'wymienionych': 334,\n",
       " 'męskich': 1720,\n",
       " 'swój': 2473,\n",
       " 'kobiecego': 4040,\n",
       " 'pracy': 2281,\n",
       " 'obydwu': 3397,\n",
       " 'odbywały': 1629,\n",
       " 'dalej': 213,\n",
       " 'chwilę': 1473,\n",
       " 'dlatego': 4859,\n",
       " 'stąpających': 1338,\n",
       " 'urodzeń': 3218,\n",
       " 'tuszuje': 2804,\n",
       " 'Spodziewał': 919,\n",
       " 'baaardzo': 1716,\n",
       " 'nóż': 2746,\n",
       " 'smutku': 1603,\n",
       " 'Wreszcie': 4718,\n",
       " 'ręcznie': 945,\n",
       " 'dyskretny': 2938,\n",
       " 'większość': 2440,\n",
       " 'błękitnej': 1130,\n",
       " 'Przyda': 4131,\n",
       " 'zwrot': 4944,\n",
       " 'dojrzałego': 489,\n",
       " 'kropli': 3350,\n",
       " 'stawianych': 2848,\n",
       " 'pozytywnymi': 1831,\n",
       " 'lotnisku': 2006,\n",
       " 'usiąść': 235,\n",
       " 'wielkie': 1315,\n",
       " ...}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words2ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence as seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_and_transform_data_to_phrases(labels, parents, tokens, words2ids):\n",
    "\n",
    "    \n",
    "\n",
    "    transform_label = {'-1':0, '0':1, '1':2}\n",
    "    \n",
    "    l = open(labels, \"r\")\n",
    "    labels = [[transform_label[y] for y in x.split()] for x in l.readlines()] \n",
    "    l.close()\n",
    "\n",
    "    p = open(parents,\"r\")\n",
    "    parents = [[int(y) for y in x.split()] for x in p.readlines()]\n",
    "    p.close()\n",
    "\n",
    "    t = open(tokens,\"r\")\n",
    "    tokens = [x.split() for x in t.readlines()]\n",
    "    t.close()\n",
    "    \n",
    "    k = 0\n",
    "    result = []\n",
    "    \n",
    "    for labels_i,parents_i,tokens_i in zip(labels,parents,tokens):\n",
    "        \n",
    "        k = k + 1\n",
    "         \n",
    "        s = []\n",
    "        for i in range(len(tokens_i)):\n",
    "            s.append([i,int(parents_i[i]),labels_i[i],tokens_i[i]])\n",
    "\n",
    "\n",
    "        if len(s) == 1: #przypadek gdy fraza sklada sie z jednego tokena\n",
    "\n",
    "            result.append((\\\n",
    "                                  tokens[0],\n",
    "                                  np.array([words2ids.get(tokens[0], 1)]),\\\n",
    "                                  np.array(labels_i[0]) \\\n",
    "                              ))    \n",
    "                           \n",
    "        else: \n",
    "            \n",
    "            for i in range(len(s)): \n",
    "                children = []\n",
    "                for j in range(len(s)):\n",
    "                    if s[j][1] == i+1:\n",
    "                        children.append(s[j][0])\n",
    "                s[i].append(children)\n",
    "\n",
    "                \n",
    "            words = [x[0] for x in s]\n",
    "            children = [x[4] for x in s]\n",
    "            tokens = [x[3] for x in s]\n",
    "            labels_in_batch = [x[2] for x in s]\n",
    "        \n",
    "            phrases = [[k] for k in range(len(children))]\n",
    "            for i in range(len(children)):\n",
    "                for e in phrases[i]:\n",
    "                    phrases[i].extend(children[e])\n",
    "           \n",
    "            phrases = [ np.sort(x) for x in phrases]\n",
    "          \n",
    "            phrases = list(zip([np.array(tokens_i)[x] for x in phrases],\n",
    "                               [np.array([words2ids.get(t,1) for t in tokens_i])[x] for x in phrases],\n",
    "                               labels_i))\n",
    "\n",
    "            result.extend(phrases)\n",
    "           \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = load_and_transform_data_to_phrases(\"Dane/data_poleval/training-treebank/rev_labels.txt\", \"Dane/data_poleval/training-treebank/rev_parents.txt\",\"Dane/data_poleval/training-treebank/rev_sentence.txt\",words2ids)\n",
    "test_data = load_and_transform_data_to_phrases(\"Dane/data_poleval/gold_labels\", \"Dane/data_poleval/poleval_test/polevaltest_parents.txt\",\"Dane/data_poleval/poleval_test/polevaltest_sentence.txt\",words2ids) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array(['Słodkawy'],\n",
       "        dtype='<U8'), array([2731]), 1),\n",
       " (array(['Słodkawy', 'i', 'pełen', 'klasy', '.'],\n",
       "        dtype='<U8'), array([2731, 1746, 1465,  515,    1]), 1),\n",
       " (array(['pełen'],\n",
       "        dtype='<U8'), array([1465]), 2),\n",
       " (array(['pełen', 'klasy'],\n",
       "        dtype='<U8'), array([1465,  515]), 2),\n",
       " (array(['.'],\n",
       "        dtype='<U8'), array([1]), 1)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "(X_train, y_train), \\\n",
    "(X_test, y_test) = \\\n",
    "( [x[1] for x in train_data], np.array(pd.get_dummies(np.array([x[2] for x in train_data]))) ) , \\\n",
    "( [x[1] for x in test_data], np.array(pd.get_dummies(np.array([x[2] for x in test_data]))) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([2731]),\n",
       " array([2731, 1746, 1465,  515,    1]),\n",
       " array([1465]),\n",
       " array([1465,  515]),\n",
       " array([1])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "max_len = np.max([len(x[1]) for x in train_data+test_data])\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_len,value=0)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_len,value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0, 2731],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0, 2731, 1746, 1465,  515,    1],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0, 1465],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0, 1465,  515],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    1]], dtype=int32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9510, 40)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.02355415  0.7809674   0.19547844]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.07232019,  0.7263721 ,  0.20130771])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.mean(y_train,axis=0))\n",
    "np.mean(y_test,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Dense, LSTM, SimpleRNN, Bidirectional, Activation\n",
    "\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 40, 300)           1500000   \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 100)               40100     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 303       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 1,540,403\n",
      "Trainable params: 1,540,403\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "n_embeddings = embeddings.shape[0] # zawiera 1 na brakujace slowa i 1 na padding\n",
    "embedding_vecor_length = 300\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(n_embeddings, embedding_vecor_length, \n",
    "                    input_length=max_len, weights=[embeddings]))\n",
    "\n",
    "\n",
    "model.add(SimpleRNN(100))\n",
    "model.add(Dense(3,activation=\"softmax\"))\n",
    "#model.add(Activation(\"softmax\"))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', \n",
    "              metrics=['categorical_accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8083 samples, validate on 1427 samples\n",
      "Epoch 1/30\n",
      "8083/8083 [==============================] - 5s - loss: 0.5528 - categorical_accuracy: 0.7725 - val_loss: 0.5158 - val_categorical_accuracy: 0.7961\n",
      "Epoch 2/30\n",
      "8083/8083 [==============================] - 5s - loss: 0.4176 - categorical_accuracy: 0.8381 - val_loss: 0.4733 - val_categorical_accuracy: 0.8150\n",
      "Epoch 3/30\n",
      "8083/8083 [==============================] - 5s - loss: 0.3723 - categorical_accuracy: 0.8606 - val_loss: 0.4572 - val_categorical_accuracy: 0.8241\n",
      "Epoch 4/30\n",
      "8083/8083 [==============================] - 4s - loss: 0.3407 - categorical_accuracy: 0.8741 - val_loss: 0.4379 - val_categorical_accuracy: 0.8360\n",
      "Epoch 5/30\n",
      "8083/8083 [==============================] - 4s - loss: 0.3153 - categorical_accuracy: 0.8864 - val_loss: 0.4255 - val_categorical_accuracy: 0.8409\n",
      "Epoch 6/30\n",
      "8083/8083 [==============================] - 4s - loss: 0.2936 - categorical_accuracy: 0.8935 - val_loss: 0.4244 - val_categorical_accuracy: 0.8465\n",
      "Epoch 7/30\n",
      "8083/8083 [==============================] - 4s - loss: 0.2746 - categorical_accuracy: 0.9029 - val_loss: 0.4281 - val_categorical_accuracy: 0.8479\n",
      "Epoch 8/30\n",
      "8083/8083 [==============================] - 4s - loss: 0.2578 - categorical_accuracy: 0.9078 - val_loss: 0.4157 - val_categorical_accuracy: 0.8507\n",
      "Epoch 9/30\n",
      "8083/8083 [==============================] - 4s - loss: 0.2422 - categorical_accuracy: 0.9148 - val_loss: 0.4212 - val_categorical_accuracy: 0.8521\n",
      "Epoch 10/30\n",
      "8083/8083 [==============================] - 4s - loss: 0.2269 - categorical_accuracy: 0.9216 - val_loss: 0.4282 - val_categorical_accuracy: 0.8542\n",
      "Epoch 11/30\n",
      "8083/8083 [==============================] - 4s - loss: 0.2137 - categorical_accuracy: 0.9290 - val_loss: 0.4220 - val_categorical_accuracy: 0.8458\n",
      "Epoch 12/30\n",
      "8083/8083 [==============================] - 4s - loss: 0.2005 - categorical_accuracy: 0.9331 - val_loss: 0.4232 - val_categorical_accuracy: 0.8430\n",
      "0.780463641685\n",
      "0.777095304058\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(patience=3,monitor=\"val_loss\")\n",
    "take_best_model = ModelCheckpoint(\"wagi.h5py\", save_best_only=True)\n",
    "\n",
    "model.fit(X_train, y_train, validation_split=0.15, epochs=30, callbacks=[early_stopping,take_best_model], batch_size=32,)\n",
    "\n",
    "print(model.evaluate(X_test, y_test, verbose=0)[1])\n",
    "\n",
    "model.load_weights(\"wagi.h5py\")\n",
    "os.remove(\"wagi.h5py\")\n",
    "\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(model.evaluate(X_test, y_test, verbose=0)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przeanalizuj accuracy na treningowym i walidacyjnym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(n_embeddings, embedding_vecor_length, input_length=max_len, embeddings_initializer=my_init))\n",
    "\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(3))\n",
    "model.add(Activation(\"softmax\"))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_categorical_accuracy', patience=3, verbose=0, mode='auto', min_delta = 0)\n",
    "\n",
    "model.fit(X_train, y_train, validation_split=0.15, epochs=30, batch_size=10, callbacks=[early_stopping])\n",
    "\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"TEST accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(n_embeddings, embedding_vecor_length, input_length=max_len, embeddings_initializer=my_init))\n",
    "\n",
    "model.add(Bidirectional(LSTM(100)))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['categorical_accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_categorical_accuracy', patience=1, verbose=0, mode='auto', min_delta = 0)\n",
    "\n",
    "model.fit(X_train, y_train, validation_split=0.15, epochs=20, batch_size=10, callbacks=[early_stopping])\n",
    "\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"TEST accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Modelowanie szeregów czasowych\n",
    "\n",
    "### Ostatnio modny trend w biznesie - zastosowanie sieci rekurencyjnych do modelowania szeregów czasowych (ogólnie danych zawierających wymiar czasowy). I jest to trend, który wynika z dobrych wyników tego podejścia.\n",
    "\n",
    "\n",
    "Przykłada na podstawie:\n",
    "\n",
    "https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "dataframe = pandas.read_csv('Dane/international-airline-passengers.csv', usecols=[1], engine='python', skipfooter=3)\n",
    "plt.plot(dataframe)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numpy.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = dataframe.values\n",
    "dataset = dataset.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize the dataset\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(dataset)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split into train and test sets\n",
    "train_size = int(len(dataset) * 0.67)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "print(len(train), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1):\n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-look_back-1):\n",
    "\t\ta = dataset[i:(i+look_back), 0]\n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + look_back, 0])\n",
    "\treturn numpy.array(dataX), numpy.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "look_back = 3\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reshape input to be [samples, time steps, features]\n",
    "trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainX[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(1, look_back)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(trainX, trainY, epochs=100, batch_size=1, verbose=2,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make predictions\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "# invert predictions\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform([testY])\n",
    "# calculate root mean squared error\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# shift train predictions for plotting\n",
    "trainPredictPlot = numpy.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = numpy.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = numpy.empty_like(dataset)\n",
    "testPredictPlot[:, :] = numpy.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
    "# plot baseline and predictions\n",
    "plt.plot(scaler.inverse_transform(dataset))\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THEANO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import theano.tensor as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = T.scalar()\n",
    "y = T.scalar()\n",
    "\n",
    "z = x + y\n",
    "\n",
    "f = theano.function(inputs=[x,y], outputs=z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(5.0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elemwise{add,no_inplace} [id A] ''   0\n",
      " |<TensorType(float64, scalar)> [id B]\n",
      " |<TensorType(float64, scalar)> [id C]\n"
     ]
    }
   ],
   "source": [
    "theano.printing.debugprint(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(<TensorType(float64, scalar)> + <TensorType(float64, scalar)>)'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theano.pp(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = T.scalar(\"x\",dtype=\"int32\")\n",
    "y = 2*x\n",
    "\n",
    "f = theano.function(inputs=[x], outputs=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elemwise{mul,no_inplace} [id A] ''   0\n",
      " |TensorConstant{2} [id B]\n",
      " |x [id C]\n"
     ]
    }
   ],
   "source": [
    "theano.printing.debugprint(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = T.scalar(\"x\",dtype=\"int32\")\n",
    "y = 2*x\n",
    "\n",
    "f = theano.function(inputs=[x], outputs=[y,y**2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(6, dtype=int32), array(36, dtype=int32)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZadNIE:  obliczyć 2x - y - 2x. wypisz graf obliczeń"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elemwise{neg,no_inplace} [id A] ''   0\n",
      " |y [id B]\n"
     ]
    }
   ],
   "source": [
    "x = T.scalar()\n",
    "y = T.scalar(\"y\")\n",
    "\n",
    "z = 2*x - y/(0.5+0.5) - 2*x\n",
    "\n",
    "f = theano.function(inputs=[x,y], outputs=z)\n",
    "\n",
    "theano.printing.debugprint(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CGemv{inplace} [id A] ''   3\n",
      " |AllocEmpty{dtype='float64'} [id B] ''   2\n",
      " | |Shape_i{0} [id C] ''   1\n",
      " |   |<TensorType(float64, matrix)> [id D]\n",
      " |TensorConstant{1.0} [id E]\n",
      " |<TensorType(float64, matrix)> [id D]\n",
      " |Elemwise{add,no_inplace} [id F] ''   0\n",
      " | |<TensorType(float64, vector)> [id G]\n",
      " | |<TensorType(float64, vector)> [id H]\n",
      " |TensorConstant{0.0} [id I]\n"
     ]
    }
   ],
   "source": [
    "u = T.vector()\n",
    "v = T.vector()\n",
    "m = T.matrix()\n",
    "\n",
    "w = u + v\n",
    "\n",
    "y = T.dot(m,w)\n",
    "\n",
    "f = theano.function(inputs=[u,v,m], outputs=y)\n",
    "\n",
    "theano.printing.debugprint(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorType(int64, scalar)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = theano.shared(7)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(7)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.get_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(4)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.set_value(4)\n",
    "a.get_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "14.0\n",
      "28.0\n"
     ]
    }
   ],
   "source": [
    "licznik = theano.shared(0)\n",
    "x = T.scalar()\n",
    "f = theano.function(inputs=[x],outputs=x*2, \n",
    "                    updates=[(licznik,licznik+1)])\n",
    "for i in range(20):\n",
    "    if i % 7 == 0:\n",
    "        print(f(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(3)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "licznik.get_value()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pochodne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = T.scalar()\n",
    "y = x**2\n",
    "g = T.grad(y,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'((fill((<TensorType(float64, scalar)> ** TensorConstant{2}), TensorConstant{1.0}) * TensorConstant{2}) * (<TensorType(float64, scalar)> ** (TensorConstant{2} - TensorConstant{1})))'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theano.pp(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = theano.function([x],g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(TensorConstant{2.0} * <TensorType(float64, scalar)>)'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theano.pp(f.maker.fgraph.outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = T.scalar(\"x\")\n",
    "y = T.scalar(\"y\")\n",
    "z = x**2 + y**3\n",
    "g = T.grad(z,(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Elemwise{Composite{(i0 * sqr(i1))}}(TensorConstant{3.0}, y)'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = theano.function([x,y],g)\n",
    "theano.pp(f.maker.fgraph.outputs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = T.scalar(\"x\")\n",
    "y = T.scalar(\"y\")\n",
    "z = x**2 + y**3\n",
    "gx, gy = T.grad(z,(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'((fill(((x ** TensorConstant{2}) + (y ** TensorConstant{3})), TensorConstant{1.0}) * TensorConstant{2}) * (x ** (TensorConstant{2} - TensorConstant{1})))'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theano.pp(gx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fun(x):\n",
    "    return(2*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = T.vector()\n",
    "\n",
    "results, _ = theano.scan(fn=fun, sequences = x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.,  4.,  6.])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = theano.function([x],results)\n",
    "f(np.array([1,2,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fun(x,y):\n",
    "    return(x*y)\n",
    "\n",
    "x = T.vector()\n",
    "y = T.matrix()\n",
    "\n",
    "res, _ = theano.scan(fn=fun, sequences = [x,y])\n",
    "\n",
    "f = theano.function([x,y],res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.,   4.],\n",
       "       [  9.,  12.]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f([2,3],np.array([[1,2],[3,4]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.,  4.]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fun(x,y):\n",
    "    return(x*y)\n",
    "\n",
    "x = T.vector()\n",
    "y = T.matrix()\n",
    "\n",
    "res, _ = theano.scan(fn=fun, sequences = [x,y],n_steps=1)\n",
    "\n",
    "f = theano.function([x,y],res)\n",
    "\n",
    "f([2,3],np.array([[1,2],[3,4]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    4,    16,   256, 65536,     0], dtype=int32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fun(x):\n",
    "    return(x*x)\n",
    "\n",
    "res, _ = theano.scan(fn=fun, outputs_info=T.cast(2,\"int32\"), n_steps=5)\n",
    "\n",
    "f = theano.function([],res)\n",
    "\n",
    "f()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x[t] = 2*x[t-1] + 2 (zał: t[-1]=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   27,   137,   687,  3437, 17187])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fun(x):\n",
    "    return(5*x + 2)\n",
    "\n",
    "x0 = theano.shared(5)\n",
    "\n",
    "res, _ = theano.scan(fn=fun, outputs_info=x0, n_steps=5)\n",
    "\n",
    "f = theano.function([],res)\n",
    "\n",
    "f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorType(int64, scalar)>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0.type()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x[t] = x[t-1] + v[t]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.,  5.,  8.])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def fun(v_t, x_tm1):\n",
    "    return(x_tm1 + v_t)\n",
    "\n",
    "v = T.vector()\n",
    "x, _ = theano.scan(fn = fun, \n",
    "                   sequences=[v],\n",
    "                   outputs_info=theano.shared(2.0))\n",
    "\n",
    "f = theano.function([v],x)\n",
    "\n",
    "f([1,2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x[t] = y[t-1] + u[t]\n",
    "\n",
    "y[t] = x[t-1] + v[t]\n",
    "\n",
    "z[t] = x[t] + y[t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([  4.,   5.,  11.]),\n",
       " array([  3.,   8.,  12.]),\n",
       " array([  7.,  13.,  23.])]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = T.vector()\n",
    "v = T.vector()\n",
    "\n",
    "def fun(u_t, v_t, x_tm1, y_tm1):\n",
    "    \n",
    "    x_t = y_tm1 + u_t\n",
    "    y_t = x_tm1 + v_t\n",
    "    \n",
    "    return(x_t, y_t, x_t+y_t)\n",
    "\n",
    "(x,y,z), _ = theano.scan(fn=fun, \n",
    "                       sequences=[u,v], \n",
    "                       outputs_info=[theano.shared(2.0),\n",
    "                                     theano.shared(3.0),\n",
    "                                     None])\n",
    "\n",
    "\n",
    "f = theano.function([u,v],[x,y,z])\n",
    "\n",
    "f([1,2,3],[1,4,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  4.,  9.])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = T.scalar()\n",
    "v = T.vector()\n",
    "\n",
    "def fun(x,p):\n",
    "    return(x**p)\n",
    "\n",
    "res, _ = theano.scan(fn=fun,sequences=[v],non_sequences=[a])\n",
    "\n",
    "f = theano.function([v,a],outputs=res)\n",
    "\n",
    "f([1,2,3],2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x[t] = x[t-1] + v[t] + p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  6.,  10.,  15.])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = T.scalar()\n",
    "v = T.vector()\n",
    "\n",
    "def fun(v_t,x_tm1,p):\n",
    "    return(x_tm1 + v_t + p)\n",
    "\n",
    "res, _ = theano.scan(fn=fun,\n",
    "                     sequences=[v],\n",
    "                     outputs_info = theano.shared(3.0),\n",
    "                     non_sequences=[a])\n",
    "\n",
    "f = theano.function([v,a],outputs=res)\n",
    "\n",
    "f([1,2,3],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 2.,  4.,  6.]), array([ 3.,  6.,  9.])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(6.0)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = T.vector()\n",
    "skumulowana_suma = theano.shared(0.0)\n",
    "\n",
    "def fun(x):\n",
    "    return((2*x, 3*x), {skumulowana_suma:skumulowana_suma+x} )\n",
    "\n",
    "res, upd = theano.scan(fn=fun, sequences=[x])\n",
    "\n",
    "f = theano.function([x],outputs=res,updates=upd)\n",
    "\n",
    "print(f([1,2,3]))\n",
    "\n",
    "skumulowana_suma.get_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theano.ifelse.ifelse(T.ge(0,1),w1,w2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
