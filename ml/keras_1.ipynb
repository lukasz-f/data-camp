{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Podstawy KERAS\n",
    "\n",
    "### Podstawy pracy z obrazkami\n",
    "\n",
    "Zbiory: 50 000 kolorowych obrazków treningowych (_train) 10 000 testowych (_test)\n",
    "o rozdzielczości 32 x 32, oznaczonych 10 kategoriami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Etykiety, które chcemy przewidywać naszą siecią neuronową, są cyframi, oznaczającymi klasę:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obrazek możemy wyświetlić w następujący sposób, korzystając z matplotlib i metody imshow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112cac2e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reprezentacja etykiet (wyjścia) w sieciach neuronowych\n",
    "\n",
    "Sieci neuronowe wymagają innej reprezentacji i obsługi etykiet niż cyfry 0-9. Służy temu tzw kodowanie \"one-hot\".\n",
    "Dla danej klasy podajemy 1 dla \"jej\" neuronu (\"gorąca jedynka\"), 0 – dla wszystkich pozostałych.\n",
    "Konwersja do kodowania one-hot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "num_classes = 10\n",
    "y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podejrzyjmy jak wygląda reprezentacja one-hot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reprezentacja obrazów (wejścia) w sieciach neuronowych\n",
    "\n",
    "Dane wejściowe muszą zostać \"spłaszczone\" do pojedynczego wektora.\n",
    "\n",
    "Zestaw danych treningowych jest zapisany jako 3-wymiarowa macierz obrazów, dla każdego koloru mamy szerokość * wysokość obrazka. W przypadku wielowarstwowej sieci neuronowej musimy zmniejszyć obrazy do wektora pikseli. W tym przypadku, obrazy o rozmiarze 32 x 32 będą miały wartość wejściową 1024 pikseli * 3 = 3072"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podając obrazki na wejście sieci typu Dense/perceptron musimy je spłaszczyć do jednowymiarowego wektora (uwaga! od tej pory używamy X_train zamiast x_train):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_pixels = x_train.shape[1] * x_train.shape[2] * x_train.shape[3]\n",
    "X_train = x_train.reshape(x_train.shape[0], num_pixels).astype('float32')\n",
    "X_test = x_test.reshape(x_test.shape[0], num_pixels).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sprawdzmy wynik tej operacji:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3072,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modele w kerasie najwygodniej tworzyć korzystając z funkcjonalnego API:\n",
    "https://keras.io/models/model/\n",
    "\n",
    "Typy warstw zaimplementowanych w keras:\n",
    "https://keras.io/layers/core/\n",
    "\n",
    "Poniższy przykład tworzy 2-warstwową sieć typu Dense/perceptron oraz uruchamia proces uczenia.\n",
    "\n",
    "UWAGA! czas wykonania jednej epoki może zająć kilka do kilkunastu minut!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "50000/50000 [==============================] - 344s - loss: 14.5059 - acc: 0.1000   \n",
      "Epoch 2/3\n",
      "50000/50000 [==============================] - 363s - loss: 14.5063 - acc: 0.1000   \n",
      "Epoch 3/3\n",
      "50000/50000 [==============================] - 350s - loss: 14.5063 - acc: 0.1000   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x131cf2ba8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# Wymiarowosc wejscia sieci musi zgadzac sie z x_train.shape\n",
    "inputs = Input(shape=(num_pixels,))\n",
    "\n",
    "# a layer instance is callable on a tensor, and returns a tensor\n",
    "x = Dense(num_pixels, activation='relu')(inputs)\n",
    "#x = Dense(num_pixels, activation='relu')(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# tworzenie modelu z wejsciem inputs i wyjsciem predictions\n",
    "# uwaga: w keras 1.x zmien nazwy: inputs->input oraz outputs->output\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=3)  # zaczynamy trening! tutaj ustawiamy liczbe epok\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Możemy ocenić jakość wytrenowanej sieci na zbiorze testowym, używając funkcji evaluate. Opis API tutaj: https://keras.io/models/model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9984/10000 [============================>.] - ETA: 0s[14.50628567199707, 0.10000000000000001]\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ćwiczenia:\n",
    "\n",
    "1. Dodaj warstwę Dropout przed warstwę z aktywacją \"softmax\", ustaw parametr dropout na 0.5, wytrenuj sieć i przetestuj na zbiorze testowym. Jak zmieniły się wyniki?\n",
    "\n",
    "2. Przetestuj inny wybrany algorytm optymalizacyjny (https://keras.io/optimizers/) z tą samą liczbą epok. Wytrenuj sieć i przetestuj na zbiorze testowym. Jak zmieniły się wyniki? \n",
    "\n",
    "3. Zmień liczbę epok na kilkukrotnie wyższą (10?), wytrenuj sieć i przetestuj na zbiorze testowym. Jak zmieniły się wyniki?\n",
    "\n",
    "4. Wykonaj wizualizację modelu (https://keras.io/visualization/)\n",
    "\n",
    "5. Stwórz model sieci złożony z następujących warstw:\n",
    "  - Conv2D, 32 filtry (5, 5) - wejściowa\n",
    "  - MaxPooling2D, rozmiar (2, 2)\n",
    "  - Dropout 0.25\n",
    "  - Dense\n",
    "  - Dropout 0.25\n",
    "  - Dense\n",
    "  Wszędzie za wyjątkiem ostatniej warstwy stosuj aktywację relu - tutaj zastosuj softmax.\n",
    "  Wytrenuj sieć i przetestuj na zbiorze testowym. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cw 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "50000/50000 [==============================] - 399s - loss: 14.5052 - acc: 0.1001   \n",
      "Epoch 2/3\n",
      "50000/50000 [==============================] - 448s - loss: 14.5063 - acc: 0.1000   \n",
      "Epoch 3/3\n",
      "50000/50000 [==============================] - 433s - loss: 14.5063 - acc: 0.1000   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11e1bb278>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.models import Model\n",
    "\n",
    "# Wymiarowosc wejscia sieci musi zgadzac sie z x_train.shape\n",
    "inputs = Input(shape=(num_pixels,))\n",
    "\n",
    "# a layer instance is callable on a tensor, and returns a tensor\n",
    "x = Dense(num_pixels, activation='relu')(inputs)\n",
    "z = Dropout(0.5)(x)\n",
    "#x = Dense(num_pixels, activation='relu')(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(z)\n",
    "\n",
    "# tworzenie modelu z wejsciem inputs i wyjsciem predictions\n",
    "# uwaga: w keras 1.x zmien nazwy: inputs->input oraz outputs->output\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=3)  # zaczynamy trening! tutaj ustawiamy liczbe epok\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9984/10000 [============================>.] - ETA: 0s[14.506285664367676, 0.10000000000000001]\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# to check the pydot/graphviz installation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'Dot'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-fbb1b8fae547>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[0;34m(model, to_file, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;34m'LR'\u001b[0m \u001b[0mcreates\u001b[0m \u001b[0ma\u001b[0m \u001b[0mhorizontal\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \"\"\"\n\u001b[0;32m--> 131\u001b[0;31m     \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_to_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextension\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[0;34m(model, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0m_check_pydot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mdot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rankdir'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# pydot raises a generic Exception here,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# so no specific class can be caught.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         raise ImportError('Failed to import pydot. You must install pydot'\n\u001b[0m\u001b[1;32m     28\u001b[0m                           ' and graphviz for `pydotprint` to work.')\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work."
     ]
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cw 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
