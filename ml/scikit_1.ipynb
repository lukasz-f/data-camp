{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Scikit-learn: dane tekstowe\n",
    "\n",
    "Aby przeprowadzić machine learning na dokumentach tekstowych, najpierw musimy zmienić treść tekstu na numeryczne wektory cech.\n",
    "\n",
    "Reprezentacja bag-of-words\n",
    "Przypisać stałą liczbę całkowitą id do każdego słowa występującego w dowolnym dokumencie zestawu treningowego \n",
    "(na przykład przez utworzenie słownika ze słów na indeksy). \n",
    "Dla każdego dokumentu j, zliczyć w nim liczbę wystąpień każdego słowa k, zapisując ją w X[k,j]\n",
    "\n",
    "### Tokenizacja i zamiana tekstów na wektory\n",
    "\n",
    "Pierwszy krok w analizie kolekcji dokumentów to tokenizacja i filtrowanie stop-wordów (ocjonalnie). Zawarte są w komponencie typu Vectorizer (np CountVectorizer), który buduje słownik mapowania słów na indeksy i przekształca dokumenty w wektory frekwencyjne bag-of-words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(['dokument pierwszy.', 'To jest tekst drugiego dokumentu'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zapoznaj się z innymi sposobami wektoryzacji dostępnymi w scikit-learn:\n",
    "http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_extraction.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trenowanie modelu klasyfikatora i predykcja\n",
    "\n",
    "Dysponując cechami, funkcjami, możemy zacząć trenować klasyfikator, aby spróbować przewidzieć etykietę każdego dokumentu. Przykład dla klasyfikatora naiwnego Bayesa. Scikit-learn zawiera kilka wariantów tego klasyfikatora; Najbardziej odpowiedni do liczenia słów jest wariant MultinomialNB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_counts, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wywołanie metody fit() powoduje dopasowanie się modelu do danych treningowych oraz etykiet tych danych.\n",
    "Obiekt clf jest wytrenowanym modelem klasyfikatora który możemy używać do etykietowania nowych, niewidzianych obserwacji. Robimy to wywołując na nim funkcję predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_new = ['No hipsters write tweets', 'Machine learning is fun?']\n",
    "X_new_counts = count_vect.transform(docs_new)\n",
    "predicted = clf.predict(X_new_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tworzenie pipelines (potoków?)\n",
    "\n",
    "Czasem warto dołożyć jeszcze kolejny krok przetwarzania, pomiędzy wektoryzacją a klasyfikatorem. Na przykład transformację TF-IDF, selekcję cech lub redukcję wymiarowości.\n",
    "\n",
    "Aby uczynić sekwencję transformacji: wektorizer => transformator => klasyfikator łatwiejszą do pracy, scikit-learn udostępnia klasę Pipeline, która zachowuje się jak klasyfikator, jest jednak złożona z większej liczby elementów:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf', MultinomialNB()),\n",
    " ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na obiekcie tego typu działają metody fit i predict, typowe dla prostych klasyfikatorów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = text_clf.fit(X_train, Y_train)\n",
    "Y_pred = text_clf.predict(X_test) # przewidywanie etykiet danych testowych (Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ewaluacja modeli\n",
    "\n",
    "Scikit-learn zapewnia narzędzia do analizy wyników:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(Y_true, Y_pred))  # szczegolowa analiza, wszystkie miary\n",
    "print(metrics.confusion_matrix(Y_true, Y_pred))   # macierz konfuzji / confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "df = pd.read_csv('Tweets.csv')\n",
    "df = df[df['airline_sentiment'] != 'neutral']\n",
    "\n",
    "len(df)\n",
    "X = df['text']\n",
    "y = df['airline_sentiment']\n",
    "\n",
    "X_train = X[:7000]\n",
    "X_validate = X[7000:9000]\n",
    "X_test = X[9000:]\n",
    "\n",
    "\n",
    "y_train = y[:7000]\n",
    "y_validate = y[7000:9000]\n",
    "y_test = y[9000:]\n",
    "\n",
    "\n",
    "#podmiana na 0/1:\n",
    "y = y.map({'negative': 0, 'positive': 1}).values\n",
    "\n",
    "def print_significant_features(pipeline=None, n=20):\n",
    "    feature_names = pipeline.get_params()['vect'].get_feature_names()\n",
    "    coefs = []\n",
    "    try:\n",
    "        coefs = pipeline.get_params()['clf'].coef_\n",
    "    except:\n",
    "        coefs.append(pipeline.get_params()['clf'].feature_importances_)\n",
    "    print(\"Total features: {}\".format(len(coefs[0])))\n",
    "    coefs_with_fns = sorted(zip(coefs[0], feature_names))\n",
    "    top = zip(coefs_with_fns[:n], coefs_with_fns[:-(n + 1):-1])\n",
    "    for (coef_2, fn_2) in top:\n",
    "        print( coef_2, str(fn_2) )\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "text_clf = Pipeline([('vect', TfidfVectorizer(stop_words='english')),\n",
    "                      ('clf', RandomForestClassifier()),\n",
    " ])\n",
    "\n",
    "text_clf.fit(X_train, y_train)\n",
    "\n",
    "print_significant_features(text_clf)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Zadania\n",
    "\n",
    "1) wczytaj plik tweets.csv (twitter airline sentiment z kaggle)\n",
    "   podpowiedź: można użyć pandas, pd.read_csv(...)\n",
    "   \n",
    "Zakładamy, że kolumna 'airline_sentiment' zawiera 3 etykietowy sentyment, a 'text' zawartość tekstową tweeta.\n",
    "\n",
    "2) usuń ze zbioru wszystkie neutralne tweety ('airline_sentiment' = 0)\n",
    "\n",
    "3) podziel zbiór  na treningowy (pierwsze 80% obu zbiorów) i 20% testowy (ostatnie 20%)\n",
    "   chcemy uzyskać zbiory X i Y, treningowy i testowy, czyli: Y_train, Y_test, X_train, X_test\n",
    "   \n",
    "4) stwórz pipeline wektoryzujący dane, możesz wypróbować również TF-IDF i inne sposoby.\n",
    "\n",
    "5) do pipeline dodaj jeden z poznanych na zajęciach klasyfikatorów - wybór należy do Ciebie!\n",
    "\n",
    "6) wytrenuj model na danych treningowych (X_train i Y_train), na danych testowych (X_test i Y_test) dokonaj jego ewaluacji. Policz wyniki ewaluacji jako precyzję, recall, F1.\n",
    "\n",
    "7) Wypróbuj modele klasyfikacyjne: Naive Bayes, MaxEnt, SVM, RandomForest. Zapisz wyniki ewaluacji na zbiorze testowym.\n",
    "\n",
    "8) Spróbuj podnieść F1 na zbiorze testowym poprzez:\n",
    "   - tuning przestrzeni hiperparametrów wybranych klasyfikatorów (nie używając w tym celu zbioru testowego!)\n",
    "   - eksperymenty z różnymi obiektami Vectorizer i różnymi parametrami\n",
    "   - normalizację przestrzeni cech (sklearn.preprocessing normalizer i normalize) dodaną do pieline\n",
    "\n",
    "Wyniki udostępnij prowadzącemu o 15:50. Osoba o najwyższym F1 dostaje po przesłaniu swojego kodu, dodatkowy bonus punktowy do egzaminu zaliczającego przedmiot :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "df = pd.read_csv('Tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df[df['airline_sentiment'] != 'neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df['text']\n",
    "y = df['airline_sentiment']\n",
    "\n",
    "X_train = X[:7000]\n",
    "X_validate = X[7000:9000]\n",
    "X_test = X[9000:]\n",
    "\n",
    "\n",
    "y_train = y[:7000]\n",
    "y_validate = y[7000:9000]\n",
    "y_test = y[9000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "text_clf = Pipeline([('vect', TfidfVectorizer(stop_words='english')),\n",
    "                      ('clf', RandomForestClassifier()),\n",
    " ])\n",
    "\n",
    "text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred = text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test, Y_pred))  # szczegolowa analiza, wszystkie miary\n",
    "print(metrics.confusion_matrix(y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "art = tfidf.fit_transform(articles)\n",
    "art"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
