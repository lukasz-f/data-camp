{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Materiały: \n",
    "\n",
    "https://github.com/norbertryciak/bootcamp_DS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proces rozwiązywania problemów z zastosowaniem uczenia maszynowego"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/b/b9/CRISP-DM_Process_Diagram.png/897px-CRISP-DM_Process_Diagram.png\" width=\"400\">\n",
    "Źródło: https://upload.wikimedia.org/wikipedia/commons/thumb/b/b9/CRISP-DM_Process_Diagram.png/897px-CRISP-DM_Process_Diagram.png\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " <br>\n",
    "\n",
    "* ML to zarówno nauka jak i sztuka\n",
    "\n",
    "* Nie istnieje metoda \"najlepsza\" - każdy problem wymaga indywidualnego podejścia \n",
    "\n",
    "* Rozwiązanie problemu ML = reprezentacja danych + algorytm   - w codziennej praktyce pierwszy czynnik często niedoceniany. Przetwarzanie danych jest równie ważna jak same algorytmy, a nawet często dane są ważniejsze od algorytmu - często większy wpływ na wyniki ma postać danych (ich przygotowanie/przetworzenie) niż wybór konkretnego algorytm\n",
    "\n",
    "* Bardzo ważne jest zdefiniowanie celu jaki chcemy osiągnąć i rozumienie jak dane są związane z tym celem\n",
    "\n",
    "\n",
    " <br>\n",
    " \n",
    " <br>\n",
    " \n",
    " <br>\n",
    " \n",
    " <br>\n",
    " \n",
    " <br>\n",
    " \n",
    " <br>\n",
    " \n",
    " <br>\n",
    " \n",
    " <br>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Dwa główne nurty uczenia maszynowego:\n",
    "* uczenie nadzorowane (*supervised learning*)\n",
    "* uczenie nienadzorowane (*unsupervised learning*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Uczenie nienadzorowane\n",
    "\n",
    "* analiza skupień (grupowanie, *clustering*)\n",
    "* ekstrakcja cech \n",
    "* redukcja wymiaru\n",
    "\n",
    " <br>\n",
    " \n",
    " <br>\n",
    " \n",
    " <br>\n",
    " \n",
    " <br>\n",
    " \n",
    " <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANALIZA SKUPIEŃ (grupowanie, *clustering*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Przykłady konkretnych zastosowań:\n",
    "    * segmentacja klientów (dopasowanie ofery (np. umowy na telefon) do klienta, generowanie rekomendacji w sklepie www, \n",
    "        * podobne preferencje zakupowe (np. jedzenie)\n",
    "        * podobne zachowania (np. stosunek do promocji)\n",
    "    * grupowanie produktów\n",
    "        * podobne parametry/właściwości\n",
    "    * grupowanie tekstów\n",
    "        * teksty podobne tematycznie\n",
    "    * grupowanie w analizie obrazów\n",
    "        * grupowanie obrazów o podobnych treściach\n",
    "        * grupowanie fragmentów obrazu\n",
    "    * biologia\n",
    "        \n",
    "<br>\n",
    "        \n",
    "2 . Grupowanie jak element procesu:\n",
    "       * systemy rekomendacyjne\n",
    "       * personalizacja treści\n",
    "       * analiza obrazów\n",
    "       \n",
    "\n",
    " <br>\n",
    " \n",
    " <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plan dnia\n",
    "\n",
    "1. Algorytm k-średnich\n",
    "\n",
    "2. Grupowanie hierarchiczne\n",
    "\n",
    "3. DBSCAN\n",
    "\n",
    "\n",
    " <br>\n",
    " \n",
    " <br>\n",
    " \n",
    " <br>\n",
    " \n",
    " <br>\n",
    " \n",
    " <br>\n",
    " \n",
    " <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definicja skupienia (klastra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.sthda.com/sthda/RDoc/images/dbscan-idea.png\" width=\"800\">\n",
    "Źródło: http://www.sthda.com/sthda/RDoc/images/dbscan-idea.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## W praktyce jest to szalenie istotna kwestia!\n",
    "\n",
    "W zależności od tego co chcemy otrzymać jako skupienie, musimy podać odpowiedniemu algorytmowi dane w odpowiedniej postaci!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dlatego ocena jakości grupowania jest bardzo trudna :( :( :(\n",
    "\n",
    "\n",
    " <br>\n",
    " \n",
    " <br>\n",
    " \n",
    " <br>\n",
    " \n",
    " <br>\n",
    " \n",
    " <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorytm k-średnich"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demo:\n",
    "\n",
    "https://www.naftaliharris.com/blog/visualizing-k-means-clustering/\n",
    "\n",
    "W jakich przypadkach algorytm działą dobrze (\"założenia\"):\n",
    "- dane \"wyspowe\"\n",
    "- jednorodne klastry\n",
    "- równe liczności klastrów\n",
    "\n",
    "https://www.youtube.com/watch?v=5I3Ei69I40s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skąd algorytm wie kiedy się zatrzymać?\n",
    "\n",
    "Dopóki środki przestaną się ruszać? - to działa tylko na trywialnych przykładach obrazkowych. Na rzeczywistych dużych danych na zatrzymanie możemy sobie trochę poczekać...\n",
    "\n",
    "Algorytm K-średnich dąży do minimalizacji zmienności wewnątrzgrupowej (*inertia*):\n",
    "\n",
    "##Inercja = $\\sum\\limits_{i=1}^K \\sum\\limits_{x \\in C_i} ||x-\\mu_i||^2 = \\sum\\limits_{i=1}^K n_i\\cdot Var(C_i)$\n",
    "\n",
    "\n",
    "Algorytm iteruje dopóki zmiana tej wielkości między kolejnymi krokami nie będzie mniejsza niż zadany próg.\n",
    "\n",
    "###$\\frac{Inertia(n)-Inertia(n+1)}{Inertia(n)} < t$\n",
    "\n",
    "Nie musi to oznaczać, że nic się już nie zmieniło, tak jak jest to w prostych przykładach\n",
    "\n",
    "Uwaga: powyżej mamy inercję całkowitą - dla całych danych. Gdy będzie mowa o inercji klastra, to oznacza ona jego wariancję."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.random as rnd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "points = np.concatenate([rnd.multivariate_normal((0,0),np.array([[1,0],[0,1]]),20),\n",
    "                    rnd.multivariate_normal((5,2),np.array([[1,0],[0,1]]),20),\n",
    "                    rnd.multivariate_normal((2,7),np.array([[1,0],[0,1]]),20)],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(points[:,0],points[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans \n",
    "\n",
    "model = KMeans(n_clusters=3,n_jobs=5)\n",
    "\n",
    "model.fit(points)\n",
    "\n",
    "labels = model.predict(points)\n",
    "\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(points[:,0],points[:,1],c=np.array([\"red\",\"green\",\"blue\"])[np.array(labels)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(points[:,0],points[:,1],c=np.array([\"red\",\"green\",\"blue\"])[np.array(labels)],alpha=0.3)\n",
    "plt.scatter(model.cluster_centers_[:,0],model.cluster_centers_[:,1],marker=\"D\",c=[\"blue\",\"green\",\"red\"],s=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = KMeans(n_clusters=3,verbose=1)\n",
    "model.fit(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ćwiczenie: wygenerować poniższe dane i dopasować model z trzema klastrami "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "points = np.concatenate([rnd.multivariate_normal((0,0),np.array([[1,0],[0,1]]),20),\n",
    "                    rnd.multivariate_normal((5,2),np.array([[1,0],[0,1]]),20),\n",
    "                    rnd.multivariate_normal((2,20),np.array([[4,0],[0,4]]),30)],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(points[:,0],points[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = KMeans(n_clusters=3)\n",
    "model.fit(points)\n",
    "labels = model.predict(points)\n",
    "\n",
    "plt.scatter(points[:,0],points[:,1],c=np.array([\"red\",\"blue\",\"green\"])[labels])\n",
    "plt.scatter(model.cluster_centers_[:,0],model.cluster_centers_[:,1],s=60,c=\"yellow\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wiemy już jak działą algorytm. Teraz będziemy analizować jak działą dla różnych danych. Na razie rozpatrujemy sytuacje, w których wiemy ile mamy klastrów"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformacje danych - dane, które podajemy algorytmomwi mają ogromne znaczenie!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformacja zmiennych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generujemy dane:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnd.seed(1)\n",
    "n = 30\n",
    "points = np.concatenate([rnd.multivariate_normal((4,15),np.array([[1,0],[0,30]]),n),\n",
    "                    rnd.multivariate_normal((10,20),np.array([[1,0],[0,30]]),n)],axis=0)\n",
    "labels = np.repeat([0,1],n)\n",
    "\n",
    "plt.scatter(points[:,0],points[:,1],c = np.array([\"red\",\"green\"])[labels])\n",
    "plt.xlim(0,30)\n",
    "plt.ylim(0,30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zadanie: dopasować model (z dowma klastrami), pokolorować grupy i zaznaczyć średnie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = KMeans(n_clusters=2)\n",
    "groups = model.fit_predict(points)\n",
    "\n",
    "plt.scatter(points[:,0],points[:,1],c = np.array([\"red\",\"green\"])[groups])\n",
    "plt.scatter(model.cluster_centers_[:,0],model.cluster_centers_[:,1],marker=\"D\",s=60,c=\"yellow\")\n",
    "\n",
    "plt.xlim(0,30)\n",
    "plt.ylim(0,30)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Widzimy, że pogrupowało się po y..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gdy różnica na osi y jest znacząco większa niż rożnica na osi x (y >>x)- patrząc na odegłość euklidesową w takiej sytuacji zachodzi:\n",
    "\n",
    "$\\sqrt{(x_1-x_2)^2 + (y_1-y_2)^2} \\approx \\sqrt{(y_1-y_2)^2})$\n",
    "\n",
    "Czyli grupowanie opiera się na zmiennej (zmiennych) dominującej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler() \n",
    "points = scaler.fit_transform(points) #SREDNIA 0 I SD 1\n",
    "\n",
    "plt.scatter(points[:,0],points[:,1],c = np.array([\"red\",\"green\"])[labels])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = KMeans(n_clusters=2)\n",
    "groups = model.fit_predict(points) # pierwszy raz się pojawia FIT_PREDICT - ZWRÓCIĆ UWAGĘ\n",
    "\n",
    "plt.scatter(points[:,0],points[:,1],c = np.array([\"red\",\"green\"])[groups])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tworzenie pipeline'a (tego na zajęciach już nie poruszaliśmy):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "sc = StandardScaler()\n",
    "km = KMeans(2)\n",
    "\n",
    "scaled_kmeans = make_pipeline(sc,km)\n",
    "\n",
    "labels = scaled_kmeans.fit_predict(points)\n",
    "\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformacja obserwacji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generujemy dane:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnd.seed(123)\n",
    "points = np.concatenate([rnd.multivariate_normal((2,3),np.array([[1,0],[0,1]]),50),\n",
    "                        rnd.multivariate_normal((10,0),np.array([[30,0],[0,0.5]]),50),\n",
    "                        rnd.multivariate_normal((0,-8),np.array([[0.3,0],[0,30]]),50)], axis = 0)\n",
    "\n",
    "plt.scatter(points[:,0],points[:,1])\n",
    "\n",
    "plt.hlines(0,-15,15)\n",
    "\n",
    "plt.vlines(0,-15,15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie: dopasować model i zwizualizować."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = KMeans(n_clusters=3)\n",
    "groups = model.fit_predict(points)\n",
    "\n",
    "plt.scatter(points[:,0],points[:,1],c = np.array([\"red\",\"green\",\"blue\"])[groups])\n",
    "plt.hlines(0,-15,15)\n",
    "plt.vlines(0,-15,15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "normalizer = Normalizer()\n",
    "points2 = normalizer.fit_transform(points)\n",
    "\n",
    "\n",
    "plt.scatter(points2[:,0],points2[:,1])\n",
    "plt.hlines(0,-1,1)\n",
    "plt.vlines(0,-1,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = KMeans(n_clusters=3)\n",
    "groups = model.fit_predict(points2)\n",
    "\n",
    "plt.scatter(points2[:,0],points2[:,1],c = np.array([\"red\",\"green\",\"blue\"])[groups])\n",
    "#plt.hlines(0,-15,15)\n",
    "#plt.vlines(0,-15,15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przykłady zastosowań normalizacji?\n",
    "    - ogólnie sytuacje, gdy nie interesują nas wartości bezwzględne, ale proporcje (np. gdy grupujemy dokumenty chcąc uzyskać w klastrach dokumenty o podobnej zawartości, a dokumenty są różnej długości)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ćwiczenie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data =pd.read_csv(\"fish.csv\", sep=\";\",decimal=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-855a8469e345>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# \"\"\"BE CLOSE TO YOUR DATA\"\"\" -> mamy rybę z zerową wagą\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data.describe()\n",
    "# \"\"\"BE CLOSE TO YOUR DATA\"\"\" -> mamy rybę z zerową wagą"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mamy zadane grupy - species - będziemy ich używać do oceny grupowania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for i in data.Species.unique():\n",
    "#    plt.scatter(data.loc[data.Species==i,\"Height\"],data.loc[data.Species==i,\"Length2\"],label=i)\n",
    "#plt.xlim(0,50)\n",
    "#plt.legend()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data[data.Weight>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = KMeans(n_clusters=7).fit(data.drop('Species',axis=1))\n",
    "pd.crosstab(data.Species,model.predict(data.drop('Species',axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tego na zajęciach nie robiliśmy. Miara V-score mierzy w pewien sposób jak klastry rozkładają się względem zadanych etykiet.\n",
    "\n",
    "https://clusteval.sdu.dk/1/clustering_quality_measures/15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.cluster import v_measure_score\n",
    "\n",
    "v_measure_score(data.Species,model.predict(data.drop('Species',axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie przekształcić dane, żeby model był w miarę dobry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "species = data.Species\n",
    "data = data.drop('Species',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "data.hist(figsize=(15,10),xlabelsize=10,layout=(2,3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data2 = pd.DataFrame(scaler.fit_transform(data))\n",
    "data2.describe()\n",
    "\n",
    "plt.figure()\n",
    "data2.hist(figsize=(15,10),xlabelsize=10,layout=(2,3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(scaler,kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "groups = pipeline.fit_predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.crosstab(species,groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "v_measure_score(species,groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wyznaczanie liczby klastrów \n",
    "\n",
    "## Dokładna ocena wyniku grupowania jest bardzo trudna i praktycznie niemożliwa. Na szczęście w praktyce bardzo dokładna ocena z reguły nie jest potrzebna (w myśl zasady *good enough*). Uwaga: klastrowanie nigdy nie będzie idealne!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I krok. \n",
    "* Uwzględnienie wiedzy apriori (wiedzy dziedzinowej, wiedzy eksperciej).\n",
    "    * intuicja, doświadczenie, \"wiedza ekspercka\" (np. grupujemy tematycznie książki, które mamy w ofercie: czy 2 klasstry mają sens? czy 10000 klastór ma sens?)\n",
    "    * założenia biznesowe (jeżeli grupujemy klientów celem dopasowania odpowiedniej oferty, to grup będzie tyle ile róznych ofert jesteśmy w stanie zaproponować; zależność dwukierunkowa - realia mogą narzucać liczbę grup, lub model może sugerować liczbę ofert) \n",
    "    * Z reguły będziemy w stanie określić przedział dla sensownych wartości\n",
    "\n",
    "II krok.\n",
    "* Ocena na oko\n",
    "    * ocena nie jest dokładna, ale bardzo wartościowa\n",
    "    * trzeba uważać, bo dużej próbki nie będziemy oceniać i nasza ocena jest obarczona BARDZO DUŻĄ niepewnością (statystyka!)\n",
    "    * trochę przewrotnie często jest to często najlepsza i wystarczająca metoda oceny\n",
    "\n",
    "III krok. \n",
    "* Obliczanie miar jakości podziału - obliczanie numerycznych mierników jakości grupowania. \n",
    "    * Ciężko dobrać miarę, trudno zinterpretować, wcale nie musi się pokrywać z optymalnym rozwiązaniem z perspektywy problemu biznesowego...\n",
    "\n",
    "\n",
    "IV krok.\n",
    "* Ocena na podstawie jakości całego procesu, w którego to grupowanie jest elementem \n",
    "    * czasochłonna i często trudna do zrealizowania z powodu realiów. Ale tak naprawdę najlepsza..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tworzymy dane:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "colors = np.array(sns.color_palette(\"Set2\", 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "points = np.concatenate([rnd.multivariate_normal((0,0),np.array([[1,0],[0,1]]),20),\n",
    "                    rnd.multivariate_normal((5,2),np.array([[1,0],[0,1]]),20),\n",
    "                    rnd.multivariate_normal((2,7),np.array([[1,0],[0,1]]),20)],axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie - Zobrazować środki klastrow w zależności od liczby klastrów. Następnie zrobić wykres inercji od liczby klastrów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ks = range(1, 7)\n",
    "inertias = []\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "for k in ks:\n",
    "    \n",
    "    model = KMeans(n_clusters=k)\n",
    "\n",
    "    model.fit(points)\n",
    "    labels = model.labels_\n",
    "    \n",
    "    inertias.append(model.inertia_)\n",
    "    \n",
    "    plt.subplot(2,3,k)\n",
    "    plt.scatter(points[:,0],points[:,1],c=colors[labels],alpha=0.3)\n",
    "    plt.scatter(model.cluster_centers_[:,0],model.cluster_centers_[:,1],marker=\"D\",c=colors,s=50)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot ks vs inertias\n",
    "\n",
    "plt.plot(ks, inertias, '-o')\n",
    "plt.xlabel('number of clusters, k')\n",
    "plt.ylabel('inertia')\n",
    "plt.xticks(ks)\n",
    "plt.xlim(0.8,6.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jak wybrać optymalne K? - Reguła łokcia\n",
    "\n",
    "\n",
    " <br>\n",
    " \n",
    " <br>\n",
    " \n",
    " <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Miara silhouette_score\n",
    "\n",
    "Najpierw objaśnienie graficzne na tablicy, potem wzór, potem rysunki\n",
    "\n",
    "https://en.wikipedia.org/wiki/Silhouette_(clustering)\n",
    "\n",
    "Wielkość dla jednego punktu:\n",
    "\n",
    "#$s(i) = \\frac{b(i)  - a(i)}{max\\{a(i),b(i)\\}}$\n",
    "\n",
    "$a(i)$ - średnia odległość punktów od punku i w danym klastrze\n",
    "\n",
    "$b(i)$ - średnia odległość punktów z najbliższego klastra od punku i\n",
    "\n",
    "Wartości z [-1,1]. Im większa wartość tym lepiej.\n",
    "\n",
    "Ocena ostateczna: średnia globalna z s(i) wszystkich punktów.\n",
    "\n",
    "http://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ks = range(2, 7)\n",
    "silhouette = []\n",
    "\n",
    "for k in ks:\n",
    "    \n",
    "    model = KMeans(n_clusters=k)\n",
    "    \n",
    "    model.fit(points)\n",
    "    \n",
    "    silhouette.append(silhouette_score(points,model.predict(points)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot ks vs silhouette\n",
    "\n",
    "plt.plot(ks, silhouette, '-o')\n",
    "plt.xlabel('number of clusters, k')\n",
    "plt.ylabel('silhouette')\n",
    "plt.xticks(ks)\n",
    "plt.xlim(0.8,6.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie - Spróbować wyznaczyć liczbę klastrów dla poniższych danych\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "points, l = make_blobs(1000,centers=100,cluster_std=0.1)\n",
    "\n",
    "plt.scatter(points[:,0],points[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inertia = []\n",
    "for i in range(10,100):\n",
    "    km = KMeans(i)\n",
    "    inertia.append(km.fit(points).inertia_)\n",
    "    \n",
    "plt.plot(range(10,150),inertia)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ks = range(10, 100)\n",
    "silhouette = []\n",
    "\n",
    "for k in ks:\n",
    "    \n",
    "    model = KMeans(n_clusters=k)\n",
    "    \n",
    "    model.fit(points)\n",
    "    \n",
    "    silhouette.append(silhouette_score(points,model.predict(points)))\n",
    "    \n",
    "# Plot ks vs silhouette\n",
    "\n",
    "plt.plot(ks, silhouette, '-o')\n",
    "plt.xlabel('number of clusters, k')\n",
    "plt.ylabel('silhouette')\n",
    "plt.xticks(ks[::5])\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ćwiczenie - wyznaczyć liczbę klastrów na danych fish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data =pd.read_csv(\"fish.csv\", sep=\";\",decimal=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data = data[data.Weight>0]\n",
    "data.iloc[:,0:-1] = StandardScaler().fit_transform(data.iloc[:,0:-1])\n",
    "inertia = []\n",
    "sil = []\n",
    "\n",
    "for k in range(2,11):\n",
    "    km = KMeans(k)\n",
    "    m = km.fit(data.iloc[:,0:-1])\n",
    "    inertia.append(m.inertia_)\n",
    "    sil.append(silhouette_score(data.iloc[:,0:-1],m.predict(data.iloc[:,0:-1])))\n",
    "\n",
    "plt.plot(range(2,11),inertia)\n",
    "plt.show()\n",
    "plt.plot(range(2,11),sil)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Zadanie: porównać sytuację, gdy wyrzucamy lub nie rybę z zerową wagą\n",
    "\n",
    "\n",
    " <br>\n",
    " \n",
    " \n",
    " <br>\n",
    " \n",
    " <br>\n",
    " \n",
    " <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Na zakończenie k-średnich jeszcze ćwiczenia na transformacje. Cel - przekształcić zmienne ciagłymi transformacjami - tzn- robimy żadnych ifów, tylko przekształacamy zmienne konkretnym wyrażeniem matematycznym (jedną zmienną albo obie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wygenerować dane, dopasować model i zwizualizować wynik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x1 = rnd.multivariate_normal((0,0),[[1000,0],[0,5]],1000)\n",
    "x1 = x1[x1[:,0]>0,:]\n",
    "\n",
    "x2 = rnd.multivariate_normal((50,10),[[1,0],[0,1]],1000)\n",
    "\n",
    "x = np.vstack([x1,x2])\n",
    "\n",
    "plt.scatter(x[:,0],x[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(2)\n",
    "kmeans.fit_predict(x)\n",
    "\n",
    "plt.scatter(x[:,0],x[:,1],c=np.array([\"red\",\"blue\"])[kmeans.labels_])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "x2 = sc.fit_transform(x)\n",
    "\n",
    "l = kmeans.fit_predict(x2)\n",
    "plt.scatter(x2[:,0],x2[:,1],c=np.array([\"red\",\"blue\"])[l])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x2 = x.copy()\n",
    "x2[:,1] = 10*x2[:,1]\n",
    "l = kmeans.fit_predict(x2)\n",
    "plt.scatter(x2[:,0],x2[:,1],c=np.array([\"red\",\"blue\"])[l])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x2 = x.copy()\n",
    "x2[:,0] = 3*np.log(1.1*x2[:,0])\n",
    "l = kmeans.fit_predict(x2)\n",
    "centers = kmeans.fit(x2).cluster_centers_\n",
    "plt.scatter(x2[:,0],x2[:,1],c=np.array([\"red\",\"blue\"])[l])\n",
    "plt.scatter(centers[:,0],centers[:,1],marker=\"D\",c=\"yellow\",s=70)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Co zrobiliśmy? Celowo \"przypisaliśmy większą wagę\" jednej zmiennej."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ćwiczenie 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x1 = rnd.multivariate_normal((20,0),[[1000,0],[0,5]],1000)\n",
    "x1 = x1[x1[:,0]>20,:]\n",
    "\n",
    "\n",
    "x2 = rnd.multivariate_normal((0,0),[[0.1,0],[0,1]],1000)\n",
    "\n",
    "x3 = rnd.multivariate_normal((10,0),[[1,0],[0,1]],1000)\n",
    "\n",
    "x = np.vstack([x1,x2,x3])\n",
    "plt.scatter(x[:,0],x[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(3)\n",
    "kmeans.fit_predict(x)\n",
    "\n",
    "plt.scatter(x[:,0],x[:,1],c=np.array([\"red\",\"blue\",\"green\"])[kmeans.labels_])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x2 = x.copy()\n",
    "x2[:,0] = 2*np.log(2+x2[:,0])\n",
    "\n",
    "l = kmeans.fit_predict(x2)\n",
    "plt.scatter(x2[:,0],x2[:,1],c=np.array([\"red\",\"blue\",\"green\"])[l])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bardzo częsta sytuacja w życiu - skośny rozkład.\n",
    " - zarobki: chcemy grupować względem danych demograficznych. Z perpspetkty grupowanie względem danych socjo-demograficznych, rożnica między zarobkami 2000 a 4000, to nie to samo co 10 000 a 12 000\n",
    " - ilość kupionego produktu: Z perpektywy grupowania klientów względem potrzeb/preferencji zakupowych, różnica między 0 a 3 to nie to samo co między 20 a 23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Klastrowanie hierarchiczne\n",
    "\n",
    "https://joernhees.de/blog/2015/08/26/scipy-hierarchical-clustering-and-dendrogram-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ćwiczenie obrazujące"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import linkage, dendrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dane = np.array([[1,1],[2,1],[4.1,1],[7,1],[2,3],[3,4]])\n",
    "plt.scatter(dane[:,0],dane[:,1])\n",
    "plt.xlim(0.5,8)\n",
    "plt.ylim(0.5,8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = linkage(dane)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dendrogram(d)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = linkage(dane,\"complete\")\n",
    "plt.scatter(dane[:,0],dane[:,1])\n",
    "plt.show()\n",
    "dendrogram(d)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metoda Ward - odległość jest równa wzrostowi sumy kwadratów odległości w w yniku połączenia danych dwóch klastrów (uwaga: są różne równoważne definicje tej miary). Metoda Ward minimalizuje wzrost wariancji (inercji).\n",
    "\n",
    "$d(i,j) = SS_{i\\cup j} - (SS_i + SS_j)$\n",
    "\n",
    "$SS(C) = \\sum\\limits_{x\\in C} (x - \\mu_C)^2$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = linkage(dane,\"ward\")\n",
    "plt.scatter(dane[:,0],dane[:,1])\n",
    "plt.show()\n",
    "dendrogram(d)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = linkage(dane,\"average\")\n",
    "plt.scatter(dane[:,0],dane[:,1])\n",
    "plt.show()\n",
    "dendrogram(d)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie pokazowe na przećwiczenie miar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnd.seed(123)\n",
    "points = np.concatenate([rnd.multivariate_normal((0,0),np.array([[0.1,0],[0,10]]),30),\n",
    "                    rnd.multivariate_normal((6,5),np.array([[10,0],[0,0.1]]),30),\n",
    "                    rnd.multivariate_normal((8,-2),np.array([[1,0],[0,1]]),30)],axis=0)\n",
    "labels = np.repeat(range(3),30)\n",
    "\n",
    "import seaborn as sns\n",
    "colors = sns.color_palette(\"Set2\", 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(points[:,0],points[:,1],c=np.array(colors)[labels])\n",
    "plt.ylim(-10,10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(50,10))\n",
    "plt.subplot(1,2,1)\n",
    "plt.scatter(points[:,0],points[:,1],c=np.array(colors)[labels],s=50)\n",
    "plt.ylim(-10,10)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "l = linkage(points,method=\"ward\")\n",
    "dendrogram(l,labels=labels,leaf_rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(50,10))\n",
    "plt.subplot(1,2,1)\n",
    "plt.scatter(points[:,0],points[:,1],c=np.array(colors)[labels],s=50)\n",
    "plt.ylim(-10,10)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "l = linkage(points,method=\"average\")\n",
    "dendrogram(l,labels=labels,leaf_rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(50,10))\n",
    "plt.subplot(1,2,1)\n",
    "plt.scatter(points[:,0],points[:,1],c=np.array(colors)[labels],s=50)\n",
    "plt.ylim(-10,10)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "l = linkage(points,method=\"single\")\n",
    "dendrogram(l,labels=labels,leaf_rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(50,10))\n",
    "plt.subplot(1,2,1)\n",
    "plt.scatter(points[:,0],points[:,1],c=np.array(colors)[labels],s=50)\n",
    "plt.ylim(-10,10)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "l = linkage(points,method=\"complete\")\n",
    "dendrogram(l,labels=labels,leaf_rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.vstack([np.tile(range(20),2),np.repeat(np.array([1,4]),20)]).T\n",
    "\n",
    "plt.scatter(x[:,0],x[:,1])\n",
    "plt.ylim(-1,20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = linkage(x,\"ward\")\n",
    "dendrogram(m)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = linkage(x,\"single\")\n",
    "dendrogram(m)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grupowanie ziaren zbóż"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samples = np.loadtxt(\"../Dane/seeds_dataset.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samples = pd.DataFrame(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samples.columns = [\"area\", \"perimeter\", \"compactness\", \"kernel_length\", \"kernel_width\", \"asymmetry\", \n",
    "                   \"kernel_groove_length\", \"variety\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samples.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler #, scale\n",
    "\n",
    "sc = StandardScaler()\n",
    "samples2 = pd.DataFrame(sc.fit_transform(samples.iloc[:,0:-1]),columns=samples.columns[:-1])\n",
    "samples2[\"variety\"] = samples.variety\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samples2.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Najpierw zrobić na surowych danych, a potem na przeskalowanych - przeanalizować zachowanie różnych łączeń"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samples3 = np.array(samples.sample(n=50))\n",
    "\n",
    "mergings = linkage(samples3[:,0:7],method=\"complete\")\n",
    "\n",
    "dendrogram(mergings,\n",
    "           labels=samples3[:,7].astype(int),\n",
    "           leaf_rotation=0,\n",
    "           leaf_font_size=8,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wyznaczanie liczby klastrów"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bierzemy ponownie dane z przykładu wprowadzającego - ale zmieniamy punkt (4,1) na (6,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dane = np.array([[1,1],[2,1],[6,1],[7,1],[2,3],[3,4]])\n",
    "plt.scatter(dane[:,0],dane[:,1])\n",
    "plt.xlim(0.5,8)\n",
    "plt.ylim(0.5,8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###1. Na podstawie dendrogramu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mergings = linkage(dane,method=\"single\")\n",
    "dendrogram(mergings)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intuicja - obcinamy tam, gdzie skok już jest \"duży\" lub na oko oceniamy ile sensownych klastrów tu widzimy\n",
    "\n",
    "### Jak mamy duży zbiór, to można wylosować próbkę, na której można wizualnie ocenić próg obcięcia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import fcluster\n",
    "\n",
    "?fcluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fcluster(mergings,t=1,criterion=\"distance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Gdy wiemy ile chcemy mieć klastrów:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fcluster(mergings,3,\"maxclust\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Istnieją też inne metody. W praktyce niezbyt użyteczne... ale można zawsze można sobie o nich poczytać"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie wyznaczyć liczbę clustrów dla zbioru ziaren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samples2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mergings = linkage(samples2.iloc[:,:-1],\"ward\")\n",
    "\n",
    "labels = fcluster(mergings,15,criterion=\"distance\")\n",
    "\n",
    "dendrogram(mergings)\n",
    "plt.show()\n",
    "\n",
    "ct = pd.crosstab(labels,samples.variety)\n",
    "\n",
    "# Display ct\n",
    "print(ct)\n",
    "\n",
    "from sklearn.metrics.cluster import v_measure_score\n",
    "\n",
    "v_measure_score(labels, samples.variety)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Zadanie: pogrupować hierarchicznie kraje na podstawie oddanych przez nie głosów w eurowizji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dane = pd.read_csv(\"../Dane/eurowizja.csv\")\n",
    "dane.set_index(dane.columns[0],inplace=True)\n",
    "\n",
    "# lub gdy chcemy sobie wczytac pliki matlabowe:\n",
    "\n",
    "from scipy.io import loadmat\n",
    "dane = loadmat(\"../Dane/eu_song_2014.mat\")[\"x\"][0][0][0]\n",
    "k1 = loadmat(\"../Dane/eu_song_2014.mat\")[\"x\"][0][0][1][0][0]\n",
    "k2 = loadmat(\"../Dane/eu_song_2014.mat\")[\"x\"][0][0][5]\n",
    "dane = pd.DataFrame(dane,columns=k2)\n",
    "dane.set_index(k1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dane.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mergings = linkage(dane,metric=\"euclidean\",method=\"average\")\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "dendrogram(mergings, \n",
    "           labels = dane.index, \n",
    "           leaf_rotation=45,\n",
    "           leaf_font_size=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "# Dbscan "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.mathworks.com/matlabcentral/mlc-downloads/downloads/submissions/53842/versions/4/screenshot.png\" width=\"400\">\n",
    "Źródło: https://www.mathworks.com/matlabcentral/mlc-downloads/downloads/submissions/53842/versions/4/screenshot.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kluczowy fakt: obserwacje znajdujące się w jednym klastrze mogą być bardzo \"różne\" - daleki od siebie\n",
    "\n",
    "### Druga ważna cecha - nie przyporządkowuje do klastrów wszystkich obserwacji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.naftaliharris.com/blog/visualizing-dbscan-clustering/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnd.seed(123)\n",
    "points = np.concatenate([rnd.multivariate_normal((2,3),np.array([[1,0],[0,1]]),50),\n",
    "                        rnd.multivariate_normal((10,0),np.array([[30,0],[0,0.5]]),50),\n",
    "                        rnd.multivariate_normal((0,-8),np.array([[0.3,0],[0,30]]),50)], axis = 0)\n",
    "\n",
    "plt.scatter(points[:,0],points[:,1])\n",
    "\n",
    "plt.hlines(0,-15,15)\n",
    "\n",
    "plt.vlines(0,-15,15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Wskazówki odnoście wyboru parametrów - wyznaczanie epsilona z danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "x = euclidean_distances(points,points)\n",
    "\n",
    "plt.hist(x[np.tril_indices(x.shape[0])],normed=True)#,cumulative=True\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ocena na oka dla różnych k najblizszych sasiadów\n",
    "k=5\n",
    "y = np.sort(x,axis=1)[:,1:]\n",
    "y[::10,:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = DBSCAN(1.7,3)\n",
    "labels = model.fit_predict(points)\n",
    "plt.scatter(points[:,0],points[:,1],c=labels+1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ćwiczenia na dobór parametrów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnd.seed(12345)\n",
    "data = np.concatenate([rnd.multivariate_normal((0,0),np.array([[1,0],[0,1]]),100),\n",
    "                    rnd.multivariate_normal((5,0),np.array([[1,0],[0,1]]),20),\n",
    "                    rnd.multivariate_normal((10,0),np.array([[1,0],[0,1]]),100)],axis=0)\n",
    "plt.scatter(data[:,0],data[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dbs = DBSCAN(2,80)\n",
    "dbs.fit_predict(data)\n",
    "print(dbs.labels_)\n",
    "colors  = np.array([\"red\",\"green\",\"blue\",\"grey\",\"purple\",\"yellow\"])\n",
    "for i in np.unique(dbs.labels_):\n",
    "    plt.scatter(data[dbs.labels_==i,0],data[dbs.labels_==i,1],c=colors[i],label= i)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.linspace(0,10*np.pi,31)\n",
    "y = np.cos(x/10)+rnd.normal(0,0.01,len(x))\n",
    "\n",
    "x = np.tile(x,2)\n",
    "y = np.concatenate([y, y+1.2])\n",
    "\n",
    "data = np.column_stack([x,y])\n",
    "plt.scatter(data[:,0],data[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dbs = DBSCAN(1.1,2)\n",
    "dbs.fit_predict(data)\n",
    "\n",
    "plt.scatter(data[:,0],data[:,1],c=np.array([\"red\",\"blue\",\"green\"])[dbs.labels_])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnd.seed(123)\n",
    "data = np.concatenate([rnd.uniform((0,0),(10,20),(200,2)),\n",
    "                    rnd.uniform((40,0),(70,40),(200,2)),\n",
    "                    rnd.uniform((10,0),(40,20),(30,2))],axis=0)\n",
    "plt.scatter(data[:,0],data[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "colors = sns.color_palette(\"Set2\", 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dbs = DBSCAN(5,60)\n",
    "dbs.fit_predict(data)\n",
    "\n",
    "for i in np.unique(dbs.labels_):\n",
    "    plt.scatter(data[dbs.labels_==i,0],data[dbs.labels_==i,1],c=colors[i],label= i)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data[dbs.labels_!=0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dbs = DBSCAN(5,10)\n",
    "dbs.fit_predict(data)\n",
    "\n",
    "for i in np.unique(dbs.labels_):\n",
    "    plt.scatter(data[dbs.labels_==i,0],data[dbs.labels_==i,1],c=colors[i],label= i)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie: zapuścić dbscana na danych Eurowizji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dane = pd.read_csv(\"../Dane/eurowizja.csv\")\n",
    "dane.set_index(dane.columns[0],inplace=True)\n",
    "\n",
    "m = DBSCAN(12,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l = m.fit_predict(dane)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(max(l)+1):\n",
    "    print(dane.iloc[i==l,:].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Analiza skupień na danych przestrzennych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na podstawie:\n",
    "\n",
    "http://geoffboeing.com/2014/08/clustering-to-reduce-spatial-data-set-size/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dane = pd.read_csv(\"../Dane/2014-summer-travels-master/data/summer-travel-gps-full.csv\")\n",
    "dane.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(dane.iloc[:,1],dane.iloc[:,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cel: zrobienie ładnej wizualizacji - wykrycie, gdzie nasz podróżnik przebywał długo (zlokalizować te miejsca na podstawie, danych GPS i przedstawić jako JEDEN PUNKT, uwzględnić w wizualizacji czas przebywania w danym miejscu) i jak się przemieszczał"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cl = DBSCAN(1,50) # przefiltorwanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = cl.fit_predict(dane.iloc[:,0:2])\n",
    "dane[\"cluster\"] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x =dane.loc[:,[\"lat\",\"lon\",\"cluster\",\"city\"]].loc[dane.cluster != -1]\n",
    "x.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    x['n'] = len(x)\n",
    "    return x\n",
    "\n",
    "centers = dane.loc[:,[\"lat\",\"lon\",\"cluster\",\"city\"]].loc[dane.cluster != -1].groupby([\"city\"]).apply(f)\n",
    "centers = centers.groupby([\"cluster\",\"city\"]).agg({\"lat\":np.mean,\"lon\":np.mean,\"n\":np.median}).reset_index()\n",
    "\n",
    "plt.scatter(centers.lon,centers.lat,s=centers.n,c=\"green\",alpha=0.7)\n",
    "for i, row in centers.iterrows():\n",
    "    \n",
    "    if row.n < 70:\n",
    "        continue\n",
    "    plt.annotate(row['city'].decode(\"utf8\"),\n",
    "    xy=(row['lon'], row['lat']),\n",
    "    xytext=(row['lon'] + 0.5, row['lat'] - 1),\n",
    "     #size=10,   \n",
    "    bbox=dict(boxstyle='round', color='gray', fc='w', alpha=0.8),\n",
    "    #xycoords='data'\n",
    "    )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "#Podsumowanie algorytmów\n",
    "\n",
    "Kiedy jaki algorytm \n",
    "- k-means - jednorodne skupienia - spodziewamy sie jednorozdnych kul w danych. Gdy średnia arytmetyczna z obserwacji ma sens jako reprezentatn klastra\n",
    "- hierarchical - gdy hierarchia w skupieniach ma sens - gdy obcięcie dendrogramu ma sens niezależnie od wysokości\n",
    "- dbscan - dowolne kształty, ale spójne - nie interesuje nas bezpośrednie podobieństwo obiektów, ale czy są \"połączone ścieżką\"\n",
    "\n",
    "Natomiast, jeśli nie ma jakiś silnych przesłanek przemawiających za konkretnym algorytmem, to można badać wszystkie.\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Podsumowanie dnia\n",
    "\n",
    "## Najważniejsze rzeczy do zapamiętania z dzisiejszych warsztatów:\n",
    "\n",
    "* *be close to your data* - trzeba wiedzieć co siedzi w danych, rozumieć je - jak się mają do celu, który chcemy osiągnąć\n",
    "\n",
    "* świadomość celu jaki chcemy osiągnąć i rozumienie jak się nasze dane mają się do niego\n",
    "\n",
    "* *close engough* - nasz szef nigdy nie będzie oczekiwał, żebyśmy przeprowadzali pięcioletnie badania na miarę doktoratu - wynik ma być zadowalający i niezbyt odległy w czasie\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Praca domowa\n",
    "\n",
    "### Cel: Opracowanie metody rozpoznającej na jakim biegu jest samochód w danym momencie\n",
    "\n",
    "Termin: do końca czerwca. \n",
    "\n",
    "Jeśli ktoś chce poćwiczyć prezentowanie wyników (nawiasem mówiąc sposób przedstawiania wyników w branży DS jest naprawdę ważny - nawet dobre rozwiązanie, jeżeli nie zostanie dobrze zaprezentowane, to może nie zostać przez kogoś przyjęte...), to zachęcam do zrobienia raportu prezentującego rozwiązanie. Taki raport sprawdzę i podzielę się możliwie najbardziej konstruktywną opinią :) \n",
    "\n",
    "### Dane od http://mywheels.pl/pl/\n",
    "\n",
    "\n",
    "### Jeżeli ktoś zamierza upublicznić swoje analizy, to należy podać informację, że dane są od mywheels.pl!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "## Źródła:\n",
    "\n",
    "https://github.com/jakevdp/sklearn_pycon2015/blob/master/notebooks/04.2-Clustering-KMeans.ipynb\n",
    "\n",
    "http://totoharyanto.staff.ipb.ac.id/files/2012/10/Building-Machine-Learning-Systems-with-Python-Richert-Coelho.pdf\n",
    "\n",
    "http://scikit-learn.org/stable/modules/clustering.html#\n",
    "\n",
    "https://joernhees.de/blog/2015/08/26/scipy-hierarchical-clustering-and-dendrogram-tutorial/\n",
    "\n",
    "http://www.stat.cmu.edu/~ryantibs/datamining/lectures/06-clus3.pdf\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
